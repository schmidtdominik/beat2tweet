{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9485da5-3e40-42f1-873e-ccb244a74bc3",
   "metadata": {},
   "source": [
    "# Load musiccaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07bb0885-c2da-43e2-8df4-468ee5f97594",
   "metadata": {},
   "outputs": [],
   "source": [
    "from musiccaps import load_musiccaps\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8926e06-ef8c-40a7-8675-f4d1285d0afe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration google--MusicCaps-7925612b943f961b\n",
      "Found cached dataset csv (/home/dominik/.cache/huggingface/datasets/google___csv/google--MusicCaps-7925612b943f961b/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    }
   ],
   "source": [
    "ds = load_musiccaps(\n",
    "    './music_data',\n",
    "    sampling_rate=16000,\n",
    "    limit=None,\n",
    "    num_proc=8,\n",
    "    writer_batch_size=1000,\n",
    "    return_without_audio=True\n",
    ")\n",
    "embeddings = np.load('embeddings.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd545edf-5fb3-4f57-9505-9faed44c8d51",
   "metadata": {},
   "source": [
    "# Image captioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bdf0432-60e4-4e76-ab97-1fdfd9d3e384",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import VisionEncoderDecoderModel, ViTFeatureExtractor, AutoTokenizer\n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torchinfo\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4d70c2d-06cb-45a7-85e7-cc7789845d43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\").cuda()\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "\n",
    "encoder_forward = model.encoder.forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d183427c-b2e6-4253-8577-113e97d8ead9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batcher(bs):\n",
    "    for epoch in itertools.count(0, 1):\n",
    "        captions, embs = [], []\n",
    "        \n",
    "        for i in np.random.permutation(len(ds)):\n",
    "            i = int(i)\n",
    "            try:\n",
    "                cap = ds[i]['caption']\n",
    "                emb = embeddings[ds[i]['ytid']]\n",
    "            except Exception as e:\n",
    "                continue\n",
    "                \n",
    "            captions.append(cap)\n",
    "            embs.append(emb)\n",
    "            \n",
    "            if len(captions) == bs:\n",
    "                assert len(embs) == bs\n",
    "                captions_tok = tokenizer(captions, padding='longest', return_tensors='pt')['input_ids'].cuda()\n",
    "                embs = torch.from_numpy(np.stack(embs)).cuda()\n",
    "                yield captions, captions_tok, embs, epoch\n",
    "                captions, embs = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f3feada-cadf-4678-866a-108d8bf00a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class B2T(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(512, 768),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(768, 768),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(768, 768)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.main(x)\n",
    "    \n",
    "b2t = B2T().cuda()\n",
    "opt = torch.optim.Adam([*b2t.parameters()], lr=0.0001) # , *model.decoder.parameters()]\n",
    "\n",
    "opt = torch.optim.Adam([\n",
    "    {'params': b2t.parameters(), 'lr': 0.0001},\n",
    "    {'params': model.parameters(), 'lr': 0.000005}\n",
    "])\n",
    "\n",
    "losses = []\n",
    "bs = 32\n",
    "fake_pixel_values = torch.zeros((bs, 3, 224, 224)).cuda()\n",
    "batcher = create_batcher(bs)\n",
    "patch_enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fb9e1d5-a144-4b4d-9e17-ab20f3337bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patched_forward(*args, **kwargs):\n",
    "    result = encoder_forward(*args, **kwargs)\n",
    "    if not patch_enabled:\n",
    "        result.last_hidden_state = b2t(embs[0:1]).unsqueeze(1).repeat(1, 197, 1)\n",
    "    else:\n",
    "        result.last_hidden_state = b2t(embs).unsqueeze(1).repeat(1, 197, 1)\n",
    "        # torch.randn_like(result.last_hidden_state)*0.3\n",
    "    return result\n",
    "\n",
    "model.encoder.forward = patched_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdc2aaa-8423-40ac-9770-ca4387c2ff73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa2c3e12735544da9aad2174652a6295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a man is standing in front of a wooden table\n",
      "The low quality recording features an acoustic rhythm guitar and flat female vocal singing on top of it. There is a lot of reverb on vocals, which makes it sound too separate from the guitar. The guitar, in the second half of the loop, is played a bit sloppy.\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a drum set with a guitar and drums on it\n",
      "A low sounding male voice is rapping over a fast paced drums playing a reggaeton beat along with a bass. Something like a guitar is playing the melody along. This recording is of poor audio-quality. In the background a laughter can be noticed. This song may be playing in a bar.\n",
      "\n",
      "a beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up beat up\n",
      "The low quality recording features a, what it seems like, cover of a country song and it consists of flat male vocals singing over acoustic sitar guitar melody. It sounds very noisy, but also heartfelt and emotional.\n",
      "\n",
      "the music is playing in the middle of the song. The music is playing in the middle of the song. The music is playing in the middle of the song. The music is playing in the middle of the song. The music is playing in the middle of the song. The music is playing in the middle of the song. The music is playing in the middle of the song. The music is playing in the middle of the song. The music is playing in the middle of the song. The music is playing in the middle of the song. The music is playing in the middle of the song. The music is playing in the\n",
      "The acoustic drums are playing a groove with crash hits and a bass that sounds distorted while a female voice is singing. Then a male singer with an effect on his voice is almost screaming while an e-guitar is playing a melody. This song may be playing in a rock&roll bar.\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the music is playing on the speakers in the room. The music is playing on the speakers in the room. The music is playing on the speakers in the room. The music is playing on the speakers in the room. The music is playing on the speakers in the room. The music is playing on the speakers in the room. The music is playing on the speakers in the room. The music is playing on the speakers in the room. The music is playing on the speakers in the room. The music is playing on the speakers in the room. The music is playing on the speakers in the room. The music is playing on the\n",
      "The song is mostly instrumental with a faint male vocal. The song is medium tempo with a slick drumming rhythm , booming bass line, siren tones and a keyboard playing  arpeggiated tones. The song is followed by camera flash and click tones. The song is exciting with a lot of fanfare. The song is fading with the end credits superimposed with camera flash tones.\n",
      "\n",
      "a male in a white shirt is playing a music video game. He is playing a music video game. The music video game is played on the speakers. The music video game is played on the speakers. The music video game is played on the speakers. The music video game is played on the speakers. The music video game is played on the speakers. The music video game is played on the speakers. The music video game is played on the speakers. The music video game is played on the speakers. The music video game is played on the speakers. The music video game is played on the speakers. The music video game is played\n",
      "The low quality recording features a regional Mexican song that consists of a passionate male vocal singing over groovy trombone and short brass melody. It sounds passionate and emotional, even though the recording is noisy.\n",
      "\n",
      "a male voice is playing a music video. The video is played on a computer. The video is played on a microphone. The microphone is connected to a speaker. The speaker is playing a music video. The speaker is playing a music video. The speaker is playing a music video. The speaker is playing a music video. The speaker is playing a music video. The speaker is playing a music video. The speaker is playing a music video. The speaker is playing a music video. The speaker is playing a music video. The speaker is playing a music video. The speaker is playing a music video. The speaker is playing a music\n",
      "A digital drum is playing a simple groove with a digital bass. An e-piano is playing 2 chords to add some color to the song. A male voice is rapping with light adults in the background. In the background a female voice sample is coming in singing a little melody. This song may be playing in a car slowly riding down the streets.\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a male voice is playing a song that is in the middle of a drum beat. The song is in the middle of a drum beat. The song is in the middle of a drum beat. The song is in the middle of a drum beat. The song is in the middle of a drum beat. The song is in the middle of a drum beat. The song is in the middle of a drum beat. The song is in the middle of a drum beat. The song is in the middle of a drum beat. The song is in the middle of a drum beat. The song is in the middle of a drum beat.\n",
      "This is a live recording of an italian song that is primarily played on the accordions. We have a male vocalist with a mature voice, who sings in a tone that feels a little bit sombre. The music itself has a romantic feeling to it.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step in tqdm(itertools.count(0, 1)):\n",
    "    captions, captions_tok, embs, epoch = next(batcher)\n",
    "\n",
    "    patch_enabled = True\n",
    "    loss = model(fake_pixel_values, labels=captions_tok).loss\n",
    "    patch_enabled = False\n",
    "    \n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    if step % 20 == 0:\n",
    "        output_ids = model.generate(fake_pixel_values[0:1], max_length=128, num_beams=2)\n",
    "        print(tokenizer.batch_decode(output_ids, skip_special_tokens=True)[0].strip())\n",
    "        print(captions[0])\n",
    "        print()\n",
    "    \n",
    "    if step % 60 == 0:\n",
    "        plt.plot(losses)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26d61cec-92c8-4b95-b3b6-6d03df6c737e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patched_forward(*args, **kwargs):\n",
    "    for arg in args:\n",
    "        if not arg is None:\n",
    "            print(type(arg))\n",
    "    for k, v in kwargs.items():\n",
    "        if not v is None:\n",
    "            print(k, type(v))\n",
    "    print('---- RETURN VAL ---')\n",
    "    result = f(*args, **kwargs)\n",
    "    print(type(result))\n",
    "    for k in result:\n",
    "        print(k, getattr(result, k).shape)\n",
    "    print('\\n'*3)\n",
    "    result.last_hidden_state[:] = torch.randn_like(result.last_hidden_state)*0.3\n",
    "    return result\n",
    "\n",
    "model.encoder.forward = patched_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "8b9730dc-3d80-4bfd-b5d8-4f01a41f9bd3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpixel_values\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbool_masked_pos\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBoolTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mhead_mask\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minterpolate_pos_encoding\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreturn_dict\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseModelOutputWithPooling\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "The [`ViTModel`] forward method, overrides the `__call__` special method.\n",
       "\n",
       "<Tip>\n",
       "\n",
       "Although the recipe for forward pass needs to be defined within this function, one should call the [`Module`]\n",
       "instance afterwards instead of this since the former takes care of running the pre and post processing steps while\n",
       "the latter silently ignores them.\n",
       "\n",
       "</Tip>\n",
       "\n",
       "Args:\n",
       "    pixel_values (`torch.FloatTensor` of shape `(batch_size, num_channels, height, width)`):\n",
       "        Pixel values. Pixel values can be obtained using [`AutoImageProcessor`]. See [`ViTImageProcessor.__call__`]\n",
       "        for details.\n",
       "\n",
       "    head_mask (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`, *optional*):\n",
       "        Mask to nullify selected heads of the self-attention modules. Mask values selected in `[0, 1]`:\n",
       "\n",
       "        - 1 indicates the head is **not masked**,\n",
       "        - 0 indicates the head is **masked**.\n",
       "\n",
       "    output_attentions (`bool`, *optional*):\n",
       "        Whether or not to return the attentions tensors of all attention layers. See `attentions` under returned\n",
       "        tensors for more detail.\n",
       "    output_hidden_states (`bool`, *optional*):\n",
       "        Whether or not to return the hidden states of all layers. See `hidden_states` under returned tensors for\n",
       "        more detail.\n",
       "    interpolate_pos_encoding (`bool`, *optional*):\n",
       "        Whether to interpolate the pre-trained position encodings.\n",
       "    return_dict (`bool`, *optional*):\n",
       "        Whether or not to return a [`~utils.ModelOutput`] instead of a plain tuple.\n",
       "\n",
       "Returns:\n",
       "    [`transformers.modeling_outputs.BaseModelOutputWithPooling`] or `tuple(torch.FloatTensor)`: A [`transformers.modeling_outputs.BaseModelOutputWithPooling`] or a tuple of\n",
       "    `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`) comprising various\n",
       "    elements depending on the configuration ([`ViTConfig`]) and inputs.\n",
       "\n",
       "    - **last_hidden_state** (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`) -- Sequence of hidden-states at the output of the last layer of the model.\n",
       "    - **pooler_output** (`torch.FloatTensor` of shape `(batch_size, hidden_size)`) -- Last layer hidden-state of the first token of the sequence (classification token) after further processing\n",
       "      through the layers used for the auxiliary pretraining task. E.g. for BERT-family of models, this returns\n",
       "      the classification token after processing through a linear layer and a tanh activation function. The linear\n",
       "      layer weights are trained from the next sentence prediction (classification) objective during pretraining.\n",
       "    - **hidden_states** (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`) -- Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model has an embedding layer, +\n",
       "      one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.\n",
       "\n",
       "      Hidden-states of the model at the output of each layer plus the optional initial embedding outputs.\n",
       "    - **attentions** (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_attentions=True`) -- Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads, sequence_length,\n",
       "      sequence_length)`.\n",
       "\n",
       "      Attentions weights after the attention softmax, used to compute the weighted average in the self-attention\n",
       "      heads.\n",
       "\n",
       "Example:\n",
       "\n",
       "```python\n",
       ">>> from transformers import AutoImageProcessor, ViTModel\n",
       ">>> import torch\n",
       ">>> from datasets import load_dataset\n",
       "\n",
       ">>> dataset = load_dataset(\"huggingface/cats-image\")\n",
       ">>> image = dataset[\"test\"][\"image\"][0]\n",
       "\n",
       ">>> image_processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
       ">>> model = ViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
       "\n",
       ">>> inputs = image_processor(image, return_tensors=\"pt\")\n",
       "\n",
       ">>> with torch.no_grad():\n",
       "...     outputs = model(**inputs)\n",
       "\n",
       ">>> last_hidden_states = outputs.last_hidden_state\n",
       ">>> list(last_hidden_states.shape)\n",
       "[1, 197, 768]\n",
       "```\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "    \u001b[0;34m@\u001b[0m\u001b[0madd_start_docstrings_to_model_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVIT_INPUTS_DOCSTRING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0madd_code_sample_docstrings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mcheckpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_CHECKPOINT_FOR_DOC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0moutput_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBaseModelOutputWithPooling\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mconfig_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_CONFIG_FOR_DOC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmodality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"vision\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mexpected_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_EXPECTED_OUTPUT_SHAPE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mpixel_values\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mbool_masked_pos\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBoolTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mhead_mask\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0minterpolate_pos_encoding\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mreturn_dict\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseModelOutputWithPooling\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0moutput_attentions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_attentions\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_attentions\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0moutput_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0moutput_hidden_states\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_hidden_states\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mpixel_values\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You have to specify pixel_values\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Prepare head mask if needed\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# 1.0 in head_mask indicate we keep the head\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# attention_probs has shape bsz x n_heads x N x N\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# TODO: maybe have a cleaner way to cast the input (from `ImageProcessor` side?)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mexpected_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprojection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mpixel_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexpected_dtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mpixel_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpixel_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0membedding_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mpixel_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool_masked_pos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool_masked_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolate_pos_encoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolate_pos_encoding\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mencoder_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mhead_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooled_output\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpooled_output\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mhead_outputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mBaseModelOutputWithPooling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mpooler_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpooled_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mattentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/envs/tp2/lib/python3.9/site-packages/transformers/models/vit/modeling_vit.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "2394b7c7-a99e-423e-aca9-ddd3fbbfdf5c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpixel_values\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBoolTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpast_key_values\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdecoder_inputs_embeds\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0muse_cache\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreturn_dict\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeq2SeqLMOutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "The [`VisionEncoderDecoderModel`] forward method, overrides the `__call__` special method.\n",
       "\n",
       "<Tip>\n",
       "\n",
       "Although the recipe for forward pass needs to be defined within this function, one should call the [`Module`]\n",
       "instance afterwards instead of this since the former takes care of running the pre and post processing steps while\n",
       "the latter silently ignores them.\n",
       "\n",
       "</Tip>\n",
       "\n",
       "Args:\n",
       "    pixel_values (`torch.FloatTensor` of shape `(batch_size, num_channels, height, width)`):\n",
       "        Pixel values. Pixel values can be obtained using an image processor (e.g. if you use ViT as the encoder,\n",
       "        you should use [`AutoImageProcessor`]). See [`ViTImageProcessor.__call__`] for details.\n",
       "    decoder_input_ids (`torch.LongTensor` of shape `(batch_size, target_sequence_length)`, *optional*):\n",
       "        Indices of decoder input sequence tokens in the vocabulary.\n",
       "\n",
       "        Indices can be obtained using [`PreTrainedTokenizer`]. See [`PreTrainedTokenizer.encode`] and\n",
       "        [`PreTrainedTokenizer.__call__`] for details.\n",
       "\n",
       "        [What are input IDs?](../glossary#input-ids)\n",
       "\n",
       "        If `past_key_values` is used, optionally only the last `decoder_input_ids` have to be input (see\n",
       "        `past_key_values`).\n",
       "\n",
       "        For training, `decoder_input_ids` are automatically created by the model by shifting the `labels` to the\n",
       "        right, replacing -100 by the `pad_token_id` and prepending them with the `decoder_start_token_id`.\n",
       "    decoder_attention_mask (`torch.BoolTensor` of shape `(batch_size, target_sequence_length)`, *optional*):\n",
       "        Default behavior: generate a tensor that ignores pad tokens in `decoder_input_ids`. Causal mask will also\n",
       "        be used by default.\n",
       "    encoder_outputs (`tuple(torch.FloatTensor)`, *optional*):\n",
       "        This tuple must consist of (`last_hidden_state`, *optional*: `hidden_states`, *optional*: `attentions`)\n",
       "        `last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`) is a tensor\n",
       "        of hidden-states at the output of the last layer of the encoder. Used in the cross-attention of the\n",
       "        decoder.\n",
       "    past_key_values (`tuple(tuple(torch.FloatTensor))` of length `config.n_layers` with each tuple having 4 tensors of shape `(batch_size, num_heads, sequence_length - 1, embed_size_per_head)`):\n",
       "        Contains precomputed key and value hidden states of the attention blocks. Can be used to speed up decoding.\n",
       "\n",
       "        If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids` (those that\n",
       "        don't have their past key value states given to this model) of shape `(batch_size, 1)` instead of all\n",
       "        `decoder_input_ids` of shape `(batch_size, sequence_length)`.\n",
       "    decoder_inputs_embeds (`torch.FloatTensor` of shape `(batch_size, target_sequence_length, hidden_size)`, *optional*):\n",
       "        Optionally, instead of passing `decoder_input_ids` you can choose to directly pass an embedded\n",
       "        representation. This is useful if you want more control over how to convert `decoder_input_ids` indices\n",
       "        into associated vectors than the model's internal embedding lookup matrix.\n",
       "    labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
       "        Labels for computing the masked language modeling loss for the decoder. Indices should be in `[-100, 0,\n",
       "        ..., config.vocab_size]` (see `input_ids` docstring) Tokens with indices set to `-100` are ignored\n",
       "        (masked), the loss is only computed for the tokens with labels in `[0, ..., config.vocab_size]`\n",
       "    use_cache (`bool`, *optional*):\n",
       "        If set to `True`, `past_key_values` key value states are returned and can be used to speed up decoding (see\n",
       "        `past_key_values`).\n",
       "    output_attentions (`bool`, *optional*):\n",
       "        Whether or not to return the attentions tensors of all attention layers. See `attentions` under returned\n",
       "        tensors for more detail.\n",
       "    output_hidden_states (`bool`, *optional*):\n",
       "        Whether or not to return the hidden states of all layers. See `hidden_states` under returned tensors for\n",
       "        more detail.\n",
       "    return_dict (`bool`, *optional*):\n",
       "        If set to `True`, the model will return a [`~utils.Seq2SeqLMOutput`] instead of a plain tuple.\n",
       "    kwargs (*optional*): Remaining dictionary of keyword arguments. Keyword arguments come in two flavors:\n",
       "\n",
       "        - Without a prefix which will be input as `**encoder_kwargs` for the encoder forward function.\n",
       "        - With a *decoder_* prefix which will be input as `**decoder_kwargs` for the decoder forward function.\n",
       "\n",
       "\n",
       "    Returns:\n",
       "        [`transformers.modeling_outputs.Seq2SeqLMOutput`] or `tuple(torch.FloatTensor)`: A [`transformers.modeling_outputs.Seq2SeqLMOutput`] or a tuple of\n",
       "        `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`) comprising various\n",
       "        elements depending on the configuration ([`VisionEncoderDecoderConfig`]) and inputs.\n",
       "\n",
       "        - **loss** (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels` is provided) -- Language modeling loss.\n",
       "        - **logits** (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.vocab_size)`) -- Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax).\n",
       "        - **past_key_values** (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`) -- Tuple of `tuple(torch.FloatTensor)` of length `config.n_layers`, with each tuple having 2 tensors of shape\n",
       "          `(batch_size, num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of shape\n",
       "          `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.\n",
       "\n",
       "          Contains pre-computed hidden-states (key and values in the self-attention blocks and in the cross-attention\n",
       "          blocks) that can be used (see `past_key_values` input) to speed up sequential decoding.\n",
       "        - **decoder_hidden_states** (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`) -- Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model has an embedding layer, +\n",
       "          one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.\n",
       "\n",
       "          Hidden-states of the decoder at the output of each layer plus the initial embedding outputs.\n",
       "        - **decoder_attentions** (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_attentions=True`) -- Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads, sequence_length,\n",
       "          sequence_length)`.\n",
       "\n",
       "          Attentions weights of the decoder, after the attention softmax, used to compute the weighted average in the\n",
       "          self-attention heads.\n",
       "        - **cross_attentions** (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_attentions=True`) -- Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads, sequence_length,\n",
       "          sequence_length)`.\n",
       "\n",
       "          Attentions weights of the decoder's cross-attention layer, after the attention softmax, used to compute the\n",
       "          weighted average in the cross-attention heads.\n",
       "        - **encoder_last_hidden_state** (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*) -- Sequence of hidden-states at the output of the last layer of the encoder of the model.\n",
       "        - **encoder_hidden_states** (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`) -- Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model has an embedding layer, +\n",
       "          one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.\n",
       "\n",
       "          Hidden-states of the encoder at the output of each layer plus the initial embedding outputs.\n",
       "        - **encoder_attentions** (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_attentions=True`) -- Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads, sequence_length,\n",
       "          sequence_length)`.\n",
       "\n",
       "          Attentions weights of the encoder, after the attention softmax, used to compute the weighted average in the\n",
       "          self-attention heads.\n",
       "  \n",
       "\n",
       "    Examples:\n",
       "\n",
       "    ```python\n",
       "    >>> from transformers import AutoProcessor, VisionEncoderDecoderModel\n",
       "    >>> import requests\n",
       "    >>> from PIL import Image\n",
       "    >>> import torch\n",
       "\n",
       "    >>> processor = AutoProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
       "    >>> model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
       "\n",
       "    >>> # load image from the IAM dataset\n",
       "    >>> url = \"https://fki.tic.heia-fr.ch/static/img/a01-122-02.jpg\"\n",
       "    >>> image = Image.open(requests.get(url, stream=True).raw).convert(\"RGB\")\n",
       "\n",
       "    >>> # training\n",
       "    >>> model.config.decoder_start_token_id = processor.tokenizer.cls_token_id\n",
       "    >>> model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
       "    >>> model.config.vocab_size = model.config.decoder.vocab_size\n",
       "\n",
       "    >>> pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n",
       "    >>> text = \"hello world\"\n",
       "    >>> labels = processor.tokenizer(text, return_tensors=\"pt\").input_ids\n",
       "    >>> outputs = model(pixel_values=pixel_values, labels=labels)\n",
       "    >>> loss = outputs.loss\n",
       "\n",
       "    >>> # inference (generation)\n",
       "    >>> generated_ids = model.generate(pixel_values)\n",
       "    >>> generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
       "    ```\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "    \u001b[0;34m@\u001b[0m\u001b[0madd_start_docstrings_to_model_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVISION_ENCODER_DECODER_INPUTS_DOCSTRING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mreplace_return_docstrings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSeq2SeqLMOutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_CONFIG_FOR_DOC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mpixel_values\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBoolTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mpast_key_values\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdecoder_inputs_embeds\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0muse_cache\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mreturn_dict\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeq2SeqLMOutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"\u001b[0m\n",
       "\u001b[0;34m        Returns:\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Examples:\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        ```python\u001b[0m\n",
       "\u001b[0;34m        >>> from transformers import AutoProcessor, VisionEncoderDecoderModel\u001b[0m\n",
       "\u001b[0;34m        >>> import requests\u001b[0m\n",
       "\u001b[0;34m        >>> from PIL import Image\u001b[0m\n",
       "\u001b[0;34m        >>> import torch\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        >>> processor = AutoProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\")\u001b[0m\n",
       "\u001b[0;34m        >>> model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-handwritten\")\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        >>> # load image from the IAM dataset\u001b[0m\n",
       "\u001b[0;34m        >>> url = \"https://fki.tic.heia-fr.ch/static/img/a01-122-02.jpg\"\u001b[0m\n",
       "\u001b[0;34m        >>> image = Image.open(requests.get(url, stream=True).raw).convert(\"RGB\")\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        >>> # training\u001b[0m\n",
       "\u001b[0;34m        >>> model.config.decoder_start_token_id = processor.tokenizer.cls_token_id\u001b[0m\n",
       "\u001b[0;34m        >>> model.config.pad_token_id = processor.tokenizer.pad_token_id\u001b[0m\n",
       "\u001b[0;34m        >>> model.config.vocab_size = model.config.decoder.vocab_size\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        >>> pixel_values = processor(image, return_tensors=\"pt\").pixel_values\u001b[0m\n",
       "\u001b[0;34m        >>> text = \"hello world\"\u001b[0m\n",
       "\u001b[0;34m        >>> labels = processor.tokenizer(text, return_tensors=\"pt\").input_ids\u001b[0m\n",
       "\u001b[0;34m        >>> outputs = model(pixel_values=pixel_values, labels=labels)\u001b[0m\n",
       "\u001b[0;34m        >>> loss = outputs.loss\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        >>> # inference (generation)\u001b[0m\n",
       "\u001b[0;34m        >>> generated_ids = model.generate(pixel_values)\u001b[0m\n",
       "\u001b[0;34m        >>> generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\u001b[0m\n",
       "\u001b[0;34m        ```\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mkwargs_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0margument\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0margument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"decoder_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mkwargs_decoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0margument\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"decoder_\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0margument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"decoder_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mencoder_outputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mpixel_values\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You have to specify pixel_values\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mencoder_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mpixel_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m**\u001b[0m\u001b[0mkwargs_encoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mencoder_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBaseModelOutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mencoder_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# optionally project encoder_hidden_states\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attention_hidden_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mencoder_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_to_dec_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# else:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mencoder_attention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdecoder_inputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mdecoder_input_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshift_tokens_right\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_token_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder_start_token_id\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Decode\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdecoder_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_inputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mpast_key_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m**\u001b[0m\u001b[0mkwargs_decoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Compute loss independent from decoder (as some shift the logits inside them)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdecoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mloss_fct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdecoder_outputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mreturn\u001b[0m \u001b[0mdecoder_outputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mSeq2SeqLMOutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mpast_key_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mdecoder_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mdecoder_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mcross_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mencoder_last_hidden_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mencoder_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/envs/tp2/lib/python3.9/site-packages/transformers/models/vision_encoder_decoder/modeling_vision_encoder_decoder.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.forward??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "514dd1c2-b360-4483-97c7-4da61bca8fea",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "return_dict <class 'bool'>\n",
      "---- RETURN VAL ---\n",
      "<class 'transformers.modeling_outputs.BaseModelOutputWithPooling'>\n",
      "last_hidden_state torch.Size([1, 197, 768])\n",
      "pooler_output torch.Size([1, 768])\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Seq2SeqLMOutput(loss=tensor(2.3366, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[[ -35.8679,  -26.7638,  -27.6791,  ...,  -47.7585,  -43.8306,\n",
       "           -32.5497],\n",
       "         [ -42.1690,  -32.1792,  -33.5180,  ...,  -53.5255,  -48.5961,\n",
       "           -37.6655],\n",
       "         [ -32.6727,  -30.1231,  -34.8829,  ...,  -42.8414,  -30.4824,\n",
       "           -30.9890],\n",
       "         ...,\n",
       "         [ -46.9919,  -44.8377,  -49.4250,  ...,  -55.7228,  -49.0115,\n",
       "           -45.0781],\n",
       "         [ -62.6528,  -61.6987,  -66.5732,  ...,  -79.3381,  -68.3395,\n",
       "           -59.0497],\n",
       "         [-125.0046, -122.8182, -127.5253,  ..., -142.7821, -135.1219,\n",
       "           -94.1819]]], device='cuda:0', grad_fn=<UnsafeViewBackward0>), past_key_values=((tensor([[[[-0.4639,  1.0217,  0.5178,  ..., -1.3494,  0.0604,  0.9517],\n",
       "          [-0.8643,  0.9492,  1.7128,  ..., -1.6513, -0.4688,  1.2078],\n",
       "          [-1.5492,  2.0069,  1.2288,  ..., -0.7368, -1.7374,  1.7684],\n",
       "          ...,\n",
       "          [-2.2556,  2.2525,  1.3288,  ..., -0.7211, -1.8382,  2.2704],\n",
       "          [-3.1566,  1.9203,  0.3840,  ..., -0.7096, -1.8810,  2.0603],\n",
       "          [-2.2085,  1.5743,  2.8767,  ..., -1.9283, -0.8342,  2.5784]],\n",
       "\n",
       "         [[-0.1709,  1.3958, -0.7572,  ...,  0.8681, -0.1085,  0.5793],\n",
       "          [-0.6734,  1.6048, -2.0867,  ...,  1.1256,  0.7438,  0.8776],\n",
       "          [-0.6826, -1.1386, -2.1555,  ..., -1.2235,  2.4112, -0.9106],\n",
       "          ...,\n",
       "          [ 0.5101, -0.6440, -1.4943,  ..., -1.1676,  2.5218, -2.1911],\n",
       "          [-3.2679, -0.6560,  2.0615,  ..., -1.8671,  3.6637,  1.1689],\n",
       "          [-0.2928, -2.2959, -0.7877,  ..., -1.6644,  1.7825,  1.3227]],\n",
       "\n",
       "         [[-0.6023,  0.1136,  0.7381,  ..., -0.0071, -2.5050, -0.1448],\n",
       "          [-0.5294,  0.6403,  0.5944,  ..., -0.1946, -1.6849,  0.5639],\n",
       "          [ 0.2801, -0.3446,  0.6339,  ..., -1.9807, -0.1341,  1.3065],\n",
       "          ...,\n",
       "          [ 0.4014, -0.0804,  0.6043,  ..., -2.0827,  1.0920,  1.5329],\n",
       "          [ 0.8178, -0.0686,  0.1494,  ..., -1.8214,  0.3489, -0.3452],\n",
       "          [ 0.3855, -0.3611,  0.0142,  ..., -2.8448,  3.0786,  2.9358]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.4222,  0.0616, -0.1848,  ..., -0.0974,  0.4861,  0.4959],\n",
       "          [ 0.2486,  0.3100, -0.0952,  ...,  0.0780,  0.1927,  0.4596],\n",
       "          [ 0.0621, -0.2378,  0.0138,  ...,  0.4158,  0.7536,  0.5775],\n",
       "          ...,\n",
       "          [ 0.1764, -0.0208,  0.0873,  ...,  0.8637,  0.4462,  0.6582],\n",
       "          [ 0.7419, -0.6762, -0.0127,  ...,  1.0659,  0.9892,  0.1607],\n",
       "          [ 0.3814,  0.9068,  0.0704,  ...,  0.2636,  0.2421, -0.6919]],\n",
       "\n",
       "         [[ 0.9829,  1.0664, -0.2753,  ...,  0.0853,  0.7661, -1.3274],\n",
       "          [ 0.9027,  0.8964, -0.2462,  ..., -0.3644,  1.0775, -1.0842],\n",
       "          [ 1.0328, -0.1387,  0.1453,  ..., -0.5498,  0.9003, -0.6484],\n",
       "          ...,\n",
       "          [ 0.7748, -0.8501, -0.3008,  ..., -0.6676,  0.2908,  0.0248],\n",
       "          [-0.4217, -0.2030, -0.5479,  ..., -0.8404,  0.9636,  0.6460],\n",
       "          [ 0.7618, -0.9330, -0.6736,  ..., -1.6479,  0.2907,  1.0127]],\n",
       "\n",
       "         [[ 0.8250, -0.1326,  0.2520,  ..., -0.6925, -0.0390,  1.1974],\n",
       "          [ 0.1323, -0.0119, -0.1868,  ..., -0.8618, -0.0680,  0.5035],\n",
       "          [-0.1263,  0.9682,  0.1751,  ...,  0.0700,  0.9173,  1.5292],\n",
       "          ...,\n",
       "          [-0.5006,  0.4279, -0.8383,  ...,  1.4743,  1.2508, -0.8302],\n",
       "          [ 0.0289,  0.0202,  1.4690,  ...,  0.3962,  1.0329,  0.5964],\n",
       "          [-0.8825,  0.6261,  0.5514,  ..., -0.7130, -0.1130,  0.6641]]]],\n",
       "       device='cuda:0', grad_fn=<PermuteBackward0>), tensor([[[[-0.0116,  0.0133, -0.0538,  ...,  0.0127,  0.0990,  0.0907],\n",
       "          [-0.0173,  0.0462, -0.0893,  ...,  0.0281,  0.2050,  0.0858],\n",
       "          [-0.1025, -0.1865,  0.0263,  ..., -0.1059, -0.0729, -0.0847],\n",
       "          ...,\n",
       "          [-0.0091, -0.0586, -0.0552,  ..., -0.0693, -0.0837,  0.1679],\n",
       "          [ 0.1970,  0.1516, -0.0356,  ..., -0.0436, -0.2108, -0.1274],\n",
       "          [ 0.0684,  0.0832,  0.2867,  ...,  0.2200, -0.2494, -0.2329]],\n",
       "\n",
       "         [[ 0.4531,  0.1616, -0.1039,  ..., -0.6283, -0.1871,  0.1476],\n",
       "          [ 0.3904,  0.0278,  0.1497,  ...,  0.0384,  0.3999, -0.0029],\n",
       "          [ 0.3040, -0.0567,  0.2907,  ..., -0.0153,  0.4408,  0.1848],\n",
       "          ...,\n",
       "          [ 0.5794, -0.0716, -0.4528,  ...,  0.0037,  0.5066,  0.1148],\n",
       "          [-0.2324, -0.1537,  0.0298,  ..., -0.1475, -0.1820, -0.0680],\n",
       "          [ 0.3200, -0.2112, -0.0987,  ..., -0.1551,  0.3486,  0.0079]],\n",
       "\n",
       "         [[-0.0189, -0.0522,  0.1322,  ..., -0.0537,  0.0645, -0.1144],\n",
       "          [-0.2031, -0.1509,  0.3074,  ..., -0.0499,  0.1557, -0.1257],\n",
       "          [-0.1392,  0.0239, -0.2544,  ..., -0.0349,  0.1054,  0.0122],\n",
       "          ...,\n",
       "          [ 0.2787,  0.3668,  0.5730,  ..., -0.0168,  0.0802, -0.2359],\n",
       "          [ 0.3179, -0.3128,  0.0209,  ...,  0.0506,  0.1402,  0.1437],\n",
       "          [-0.1689, -0.0395, -0.1370,  ..., -0.1166, -0.0083, -0.1704]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0466, -0.1552,  0.0751,  ..., -0.0830, -0.0483,  0.0384],\n",
       "          [-0.2655,  0.0708,  0.1249,  ...,  0.1390, -0.0240,  0.1049],\n",
       "          [-0.1982, -0.0088,  0.0996,  ..., -0.1435, -0.0298, -0.0388],\n",
       "          ...,\n",
       "          [-0.1228, -0.1899, -0.0529,  ..., -0.3667,  0.0277, -0.2626],\n",
       "          [ 0.0610,  0.1023, -0.0867,  ...,  0.3852,  0.2137, -0.0334],\n",
       "          [-0.0040,  0.5192, -0.1001,  ..., -0.1984, -0.1062, -0.3372]],\n",
       "\n",
       "         [[ 0.0463, -0.1344, -0.0974,  ...,  0.0155,  0.2473,  0.0619],\n",
       "          [-0.3434, -0.1193,  0.1018,  ..., -0.2534,  0.3936,  0.2524],\n",
       "          [-0.2981, -0.2441, -0.1768,  ..., -0.1245, -0.1830, -0.1067],\n",
       "          ...,\n",
       "          [ 0.1191,  0.1075, -0.0399,  ..., -0.0995, -0.1250,  0.0656],\n",
       "          [ 0.0988, -0.1641, -0.4581,  ...,  0.1152, -0.1215, -0.4268],\n",
       "          [-0.1038,  0.1295, -0.2949,  ..., -0.3168,  0.0486, -0.1971]],\n",
       "\n",
       "         [[ 0.1030, -0.4049, -0.0683,  ...,  0.0936, -0.2765,  0.1108],\n",
       "          [ 0.2123, -0.2173, -0.2996,  ...,  0.4282, -0.1852,  0.3884],\n",
       "          [-0.0156, -0.1790,  0.0197,  ...,  0.1377,  0.1793,  0.0707],\n",
       "          ...,\n",
       "          [ 0.1065, -0.0729,  0.3501,  ...,  0.0782,  0.2541,  0.1387],\n",
       "          [-0.0016,  0.2365, -0.1191,  ...,  0.0786, -0.1600,  0.2580],\n",
       "          [ 0.1129, -0.1474,  0.0665,  ...,  0.2391,  0.0589,  0.1002]]]],\n",
       "       device='cuda:0', grad_fn=<PermuteBackward0>)), (tensor([[[[ 0.0264,  1.6070, -1.3598,  ...,  1.0285, -0.7336,  1.3647],\n",
       "          [ 0.5799,  0.9280, -0.5876,  ..., -0.4643, -0.9049, -0.1461],\n",
       "          [ 0.6168,  1.1800, -0.8385,  ..., -0.0534, -1.6730,  0.0263],\n",
       "          ...,\n",
       "          [-1.2529,  0.3951,  1.0617,  ...,  0.7415, -1.5227, -0.6784],\n",
       "          [-1.0871,  0.9250,  1.2833,  ...,  0.5607, -0.3060, -0.6851],\n",
       "          [-1.5044, -0.4108,  2.8460,  ...,  1.3354, -2.0532, -1.7012]],\n",
       "\n",
       "         [[-1.1833, -0.9784, -0.1507,  ..., -0.4343,  0.6817, -0.4813],\n",
       "          [-0.3535,  0.3769, -0.2104,  ..., -0.6011, -0.2199, -0.1313],\n",
       "          [-0.7930,  1.1303, -0.7943,  ..., -0.8589, -0.3079,  0.2013],\n",
       "          ...,\n",
       "          [ 0.4594,  1.4230, -2.1283,  ..., -0.1442, -0.8521, -0.9140],\n",
       "          [-0.4307,  1.9260, -2.1981,  ...,  0.2702, -1.8982, -0.6463],\n",
       "          [-0.7730,  0.0725, -2.3191,  ...,  0.9225, -2.3243,  0.1465]],\n",
       "\n",
       "         [[ 0.1367, -0.0176, -0.0344,  ..., -0.9486,  0.1594, -0.0186],\n",
       "          [-0.1735,  0.0824, -0.0261,  ..., -0.6443, -0.2416,  0.1461],\n",
       "          [ 0.1143,  0.0660, -0.0446,  ..., -0.7896,  0.0592,  0.1514],\n",
       "          ...,\n",
       "          [-0.1066, -0.0762,  0.1305,  ..., -0.4486,  0.1023,  0.0630],\n",
       "          [-0.4509,  0.0520,  0.0628,  ..., -0.5313,  0.0274,  0.3564],\n",
       "          [-0.4270, -0.0294, -0.3297,  ..., -0.4022, -0.0728,  0.3086]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.2418, -0.1362, -0.5449,  ..., -0.3621,  0.3883, -0.6006],\n",
       "          [-0.9853,  1.0303,  1.3352,  ...,  0.3267, -1.9134,  0.8039],\n",
       "          [ 0.3806, -0.1967,  1.1572,  ..., -0.7151, -0.3842,  0.7042],\n",
       "          ...,\n",
       "          [ 2.0098, -1.6095,  1.5421,  ...,  0.7165,  0.1206, -0.9411],\n",
       "          [ 0.9453,  0.7150,  1.1043,  ...,  1.4112,  1.6639,  0.1390],\n",
       "          [ 1.5487, -1.9690,  1.6582,  ..., -0.1922, -0.3365, -0.6021]],\n",
       "\n",
       "         [[-0.8930, -2.5253,  0.2164,  ...,  1.6279,  1.4559, -1.4507],\n",
       "          [ 0.1382,  0.5931, -0.4466,  ..., -0.6541,  0.3486,  0.3197],\n",
       "          [ 0.1332,  0.3251, -0.6549,  ..., -0.5474,  0.4562, -0.0709],\n",
       "          ...,\n",
       "          [-0.3312,  0.2928, -0.7062,  ..., -0.8046,  1.1975,  0.6997],\n",
       "          [-0.6501,  0.8902, -0.7281,  ..., -0.2511,  0.9270,  0.7117],\n",
       "          [-0.4880,  0.2267, -0.7143,  ...,  0.0120,  1.2673,  0.5069]],\n",
       "\n",
       "         [[ 0.6973,  1.6856,  0.4155,  ..., -1.0832, -0.0126,  0.1515],\n",
       "          [-0.1326,  1.1586,  0.0764,  ..., -0.5080,  0.2095, -0.1227],\n",
       "          [ 0.9098,  1.2976,  0.6704,  ...,  0.8165, -0.6834,  1.1670],\n",
       "          ...,\n",
       "          [ 0.9386,  2.4669,  0.3321,  ..., -0.7600, -0.5702, -0.4497],\n",
       "          [ 0.9809,  0.7265,  0.2406,  ...,  1.0990,  0.0773, -0.2622],\n",
       "          [ 0.0704,  2.0301,  1.0358,  ...,  1.5591, -0.6616, -0.6271]]]],\n",
       "       device='cuda:0', grad_fn=<PermuteBackward0>), tensor([[[[ 2.5648e-01,  1.8042e-01,  7.4260e-02,  ..., -2.8533e-02,\n",
       "           -1.7049e-01, -2.2196e-01],\n",
       "          [ 1.7258e-01, -6.3773e-02,  1.6278e-01,  ...,  1.3137e-02,\n",
       "            1.4308e-02, -7.3419e-02],\n",
       "          [-2.2358e-01,  2.5937e-01, -3.4108e-01,  ...,  4.1551e-01,\n",
       "           -4.0694e-01,  3.5291e-01],\n",
       "          ...,\n",
       "          [ 1.6804e-01,  2.3295e-01,  2.4170e-01,  ..., -2.1760e-01,\n",
       "           -2.2068e-01,  3.0314e-01],\n",
       "          [-3.0431e-01,  1.2327e-02,  6.1776e-01,  ..., -1.9051e-01,\n",
       "           -1.6081e-01, -4.6769e-01],\n",
       "          [ 3.8817e-01, -2.7174e-01,  1.1641e-01,  ..., -5.5302e-01,\n",
       "           -1.4844e-01, -7.1275e-01]],\n",
       "\n",
       "         [[ 8.7724e-02,  1.0590e-02,  3.3847e-02,  ..., -1.3090e-01,\n",
       "           -7.0346e-02,  1.0617e-01],\n",
       "          [ 2.1453e-01,  1.0732e-01,  1.2551e-01,  ...,  6.4013e-02,\n",
       "            1.4904e-01, -2.0000e-01],\n",
       "          [-6.6709e-02,  2.0006e-03,  1.6584e-01,  ...,  6.4318e-02,\n",
       "            2.5180e-01,  8.1402e-01],\n",
       "          ...,\n",
       "          [ 8.9405e-01,  8.6779e-02, -7.9537e-03,  ..., -9.6191e-01,\n",
       "           -1.7539e-02, -1.0715e-02],\n",
       "          [-4.9468e-02,  9.2011e-01, -6.7381e-02,  ...,  5.2180e-01,\n",
       "           -1.8519e-01,  2.8750e-01],\n",
       "          [ 8.4201e-01,  2.9632e-01,  2.8910e-01,  ...,  4.3946e-01,\n",
       "            6.2146e-01, -3.1281e-01]],\n",
       "\n",
       "         [[-1.2948e-01, -5.4070e-02,  1.8643e-01,  ..., -5.0071e-01,\n",
       "            2.4738e-02, -9.5170e-02],\n",
       "          [ 1.8113e-01, -1.0272e-01,  2.2109e-01,  ..., -3.5989e-01,\n",
       "           -5.0203e-02, -1.3107e-01],\n",
       "          [ 4.6299e-01,  6.6027e-03, -6.3111e-02,  ..., -6.5337e-01,\n",
       "           -8.1596e-02,  3.3318e-01],\n",
       "          ...,\n",
       "          [ 2.4127e-01,  3.1313e-01,  1.8944e-01,  ...,  5.4602e-01,\n",
       "            2.5952e-01, -1.7358e-01],\n",
       "          [ 7.3931e-02, -1.1542e-02, -3.5419e-01,  ...,  5.4639e-01,\n",
       "            2.8685e-01, -1.4808e-02],\n",
       "          [ 9.4727e-02,  2.6694e-01,  5.3107e-01,  ...,  6.3430e-01,\n",
       "           -6.3883e-02, -3.0911e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.2535e-03,  3.0946e-01, -1.5115e-02,  ..., -1.3393e-01,\n",
       "           -8.9087e-01, -1.0315e-01],\n",
       "          [-1.9617e-01, -8.6230e-01,  1.0564e-01,  ..., -4.4739e-01,\n",
       "           -4.0937e-01, -1.6588e-01],\n",
       "          [-3.2402e-01,  1.9108e-01,  2.4344e-01,  ..., -2.6970e-02,\n",
       "           -2.2377e-01, -9.3684e-02],\n",
       "          ...,\n",
       "          [-4.0293e-02, -4.6469e-01,  1.4626e-02,  ..., -7.5400e-02,\n",
       "           -1.7213e-01, -1.9927e-01],\n",
       "          [-7.7598e-01,  9.6259e-02,  2.5940e-01,  ...,  4.7957e-01,\n",
       "           -3.9567e-02, -4.9545e-01],\n",
       "          [ 1.5511e-02,  7.0599e-02, -1.2845e-01,  ...,  2.7811e-01,\n",
       "           -1.2594e-01, -4.3473e-01]],\n",
       "\n",
       "         [[ 2.1805e-01, -1.2601e-01,  9.6698e-03,  ...,  3.4453e-01,\n",
       "           -2.7822e+00, -2.7843e-01],\n",
       "          [ 2.4150e-01, -9.3690e-02,  7.9056e-01,  ..., -1.9297e-01,\n",
       "            3.6339e-01, -4.1727e-01],\n",
       "          [-2.1065e-01,  1.4282e-02,  6.7793e-02,  ..., -2.1820e-01,\n",
       "           -1.2495e-02, -3.5364e-01],\n",
       "          ...,\n",
       "          [ 2.4128e-01,  6.0968e-01, -1.8046e-01,  ..., -9.3071e-02,\n",
       "           -1.1879e-01, -1.6017e-01],\n",
       "          [ 3.9324e-01,  1.1017e-01, -4.1523e-02,  ..., -1.0274e-01,\n",
       "           -4.0915e-01,  2.9267e-01],\n",
       "          [ 4.5006e-01,  2.5402e-01,  1.3110e-01,  ...,  1.3367e-01,\n",
       "           -1.8600e-01, -2.2297e-01]],\n",
       "\n",
       "         [[ 1.5106e-01, -8.9231e-02,  5.4383e-02,  ..., -1.4270e-01,\n",
       "            2.7497e-01, -1.8535e-01],\n",
       "          [ 1.3056e-01, -2.6533e-02,  4.4511e-01,  ..., -1.1697e-01,\n",
       "            2.9667e-01, -2.0837e-01],\n",
       "          [-6.1207e-02, -9.5059e-02, -1.2494e-01,  ..., -2.1687e-01,\n",
       "            1.2216e-01,  6.3034e-02],\n",
       "          ...,\n",
       "          [-6.4190e-02,  2.3823e-01, -1.2938e-01,  ..., -3.0316e-02,\n",
       "           -1.3452e-01,  1.5983e-01],\n",
       "          [-5.0427e-02,  3.8609e-01,  1.5445e-01,  ..., -1.2500e-01,\n",
       "           -3.7161e-02, -9.3546e-02],\n",
       "          [ 3.9119e-01, -1.6262e-01,  7.8414e-02,  ...,  5.7470e-02,\n",
       "           -7.5112e-02, -1.8433e-01]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[-1.5028e-01, -1.2573e+00,  3.8984e-01,  ..., -6.5062e-01,\n",
       "            2.3107e-03,  1.0066e-01],\n",
       "          [ 3.2048e-01, -1.9416e+00,  1.1034e-01,  ..., -7.2924e-02,\n",
       "           -1.9806e-01, -1.7304e-01],\n",
       "          [ 1.8474e-01, -8.5224e-01, -4.9338e-01,  ..., -4.3706e-01,\n",
       "           -4.8154e-01, -5.6099e-01],\n",
       "          ...,\n",
       "          [-2.3635e-01, -7.5673e-02,  7.3575e-01,  ...,  1.6449e+00,\n",
       "            2.5364e-01,  5.8964e-02],\n",
       "          [-4.7844e-01, -2.0116e+00, -2.3463e-01,  ..., -2.6495e-01,\n",
       "            5.2161e-01,  1.6082e+00],\n",
       "          [-1.1308e-01, -1.1554e+00, -7.1182e-01,  ...,  9.9116e-01,\n",
       "            2.6742e-01,  1.7426e+00]],\n",
       "\n",
       "         [[-5.2495e-01,  4.8920e-01, -3.4092e-01,  ...,  1.0757e+00,\n",
       "           -6.0921e-01, -5.4653e-01],\n",
       "          [-1.3025e+00, -8.5876e-01, -7.1716e-01,  ..., -1.8806e-01,\n",
       "            4.3098e-01, -4.8368e-01],\n",
       "          [-6.1140e-01, -6.7692e-01,  1.6490e-01,  ..., -2.5253e-01,\n",
       "            4.9560e-01,  4.8844e-01],\n",
       "          ...,\n",
       "          [-3.6770e-02,  1.1126e+00, -1.5627e+00,  ...,  9.8144e-02,\n",
       "            1.0359e+00, -1.1237e-01],\n",
       "          [-1.3439e-01,  4.7272e-01, -1.8711e+00,  ..., -6.2682e-01,\n",
       "            6.7622e-01, -7.3442e-01],\n",
       "          [-7.3128e-01, -4.1476e-01, -1.6784e+00,  ...,  2.2011e-01,\n",
       "            7.4970e-01, -1.1074e+00]],\n",
       "\n",
       "         [[ 1.0294e+00,  2.9702e+00,  3.2573e+00,  ...,  6.8333e-01,\n",
       "            1.5467e+00, -1.0296e+00],\n",
       "          [-2.7730e+00,  8.3254e-01, -2.5434e+00,  ..., -1.8021e+00,\n",
       "            3.0752e+00,  2.4495e-02],\n",
       "          [-2.7469e+00, -5.1561e-01, -2.7319e+00,  ..., -3.2412e+00,\n",
       "            3.1357e+00,  4.2090e-01],\n",
       "          ...,\n",
       "          [-3.8323e+00, -3.0154e+00, -2.9731e+00,  ..., -2.8199e+00,\n",
       "            1.1238e+00,  1.0780e+00],\n",
       "          [-2.6334e+00, -3.8440e+00, -2.7107e+00,  ..., -2.2228e+00,\n",
       "            1.0278e+00,  2.2505e+00],\n",
       "          [-9.3880e-01, -3.7145e+00, -3.0877e+00,  ..., -3.8706e+00,\n",
       "            2.4650e+00,  8.4938e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.2173e+00, -2.3900e+00, -2.3826e+00,  ...,  9.8032e-01,\n",
       "            3.1857e-01,  2.5068e+00],\n",
       "          [-2.0807e+00,  1.8556e+00,  5.9296e-01,  ...,  3.5252e-02,\n",
       "           -1.5874e+00, -2.8508e-01],\n",
       "          [-2.3445e+00,  1.5207e+00,  7.9669e-01,  ...,  1.9894e-01,\n",
       "           -1.7064e+00, -1.6657e-01],\n",
       "          ...,\n",
       "          [-2.7147e+00,  4.4860e+00,  2.6488e+00,  ..., -1.8987e+00,\n",
       "           -3.3619e+00, -2.4925e+00],\n",
       "          [-3.1593e+00,  3.6590e+00,  2.0052e+00,  ..., -1.8279e+00,\n",
       "           -3.3981e+00, -3.0485e+00],\n",
       "          [-3.4492e+00,  4.5089e+00,  3.3710e+00,  ..., -7.5270e-01,\n",
       "           -2.2396e+00, -2.1703e+00]],\n",
       "\n",
       "         [[ 1.4356e+00,  4.8466e-01,  8.6465e-01,  ...,  9.9528e-03,\n",
       "           -6.8405e-01, -3.6284e-01],\n",
       "          [ 1.2910e+00,  4.7464e-01,  7.1452e-01,  ...,  5.2484e-01,\n",
       "           -2.9043e-01, -1.0093e+00],\n",
       "          [ 1.2049e+00,  3.5862e-01,  8.5139e-01,  ...,  9.6753e-02,\n",
       "           -8.0453e-01, -8.8311e-01],\n",
       "          ...,\n",
       "          [ 1.2520e+00,  2.0976e-01,  4.9444e-01,  ..., -4.5051e-01,\n",
       "           -1.5545e+00, -4.7004e-01],\n",
       "          [ 1.6363e+00,  5.9717e-02,  2.6171e-01,  ...,  1.4817e-01,\n",
       "           -2.6526e-01,  3.1770e-01],\n",
       "          [ 1.8311e+00, -1.0690e-03,  4.3851e-01,  ...,  4.2467e-01,\n",
       "           -1.6757e+00, -4.7380e-01]],\n",
       "\n",
       "         [[-2.8021e-01,  1.1031e-01, -6.9883e-01,  ...,  3.4148e-01,\n",
       "            3.4657e-01,  3.4493e-01],\n",
       "          [-8.4474e-01, -1.3965e-02, -4.6235e-01,  ...,  3.6767e-01,\n",
       "            4.7452e-01,  5.3764e-01],\n",
       "          [ 9.6175e-02,  1.8447e-01, -7.3913e-01,  ...,  1.0569e-01,\n",
       "            2.2062e-01,  4.3851e-01],\n",
       "          ...,\n",
       "          [ 1.4750e+00, -3.8273e-01, -3.8838e-01,  ...,  1.0873e-01,\n",
       "            5.2054e-01,  6.0020e-01],\n",
       "          [-1.0047e+00, -3.8809e-01, -3.1732e-01,  ...,  3.1362e-01,\n",
       "            6.2896e-01,  3.8098e-01],\n",
       "          [ 3.4324e-01, -2.0902e-01, -6.8091e-01,  ..., -6.4022e-02,\n",
       "            7.4529e-01,  2.1407e-01]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[-4.5773e-02,  1.5312e-02, -1.7873e-01,  ..., -9.5605e-02,\n",
       "            1.3617e-02, -6.4353e-01],\n",
       "          [ 3.0430e-01,  7.5265e-01, -6.2020e-01,  ..., -6.4600e-02,\n",
       "            1.4013e-01, -2.1759e-01],\n",
       "          [ 2.6531e-01,  2.7049e-01, -3.3175e-02,  ..., -1.0278e-02,\n",
       "            1.1628e-01,  2.7244e-01],\n",
       "          ...,\n",
       "          [ 9.2925e-03,  1.7527e-01, -1.8353e-01,  ...,  3.0274e-02,\n",
       "           -3.0006e-01,  3.4235e-01],\n",
       "          [-6.8181e-02, -1.2293e+00,  5.2933e-01,  ..., -3.8426e-01,\n",
       "            9.1415e-01,  3.9187e-01],\n",
       "          [ 9.0316e-01, -3.2168e-01,  3.2674e-01,  ...,  6.1106e-01,\n",
       "           -7.1257e-01, -2.1477e-01]],\n",
       "\n",
       "         [[ 5.9584e-03, -1.2852e-02,  2.3768e-02,  ...,  3.5301e-02,\n",
       "            2.2559e-02,  6.5780e-04],\n",
       "          [ 6.5509e-02,  2.5582e-01,  1.3689e-01,  ...,  1.4659e-01,\n",
       "           -5.9529e-02,  1.7478e-01],\n",
       "          [-5.1708e-02, -3.1805e-02,  1.1132e-01,  ...,  1.7759e-01,\n",
       "            2.7625e-01, -3.1351e-04],\n",
       "          ...,\n",
       "          [-1.2871e-01,  2.4950e-01, -2.0210e-01,  ...,  1.6748e-01,\n",
       "            1.0383e-01,  6.8394e-02],\n",
       "          [ 3.2066e-02,  3.3434e-01,  8.5797e-02,  ...,  2.0788e-01,\n",
       "            7.3799e-01, -4.3131e-01],\n",
       "          [-4.5602e-02, -4.3923e-01,  3.3035e-02,  ..., -3.0616e-01,\n",
       "            6.7190e-01, -4.4627e-01]],\n",
       "\n",
       "         [[ 9.1561e-02, -9.2142e-01, -5.4217e-03,  ...,  2.0044e-02,\n",
       "            2.1656e-02, -4.6488e-02],\n",
       "          [-1.2416e-03, -8.1114e-01,  1.4386e-02,  ...,  8.2425e-02,\n",
       "            4.5030e-03, -8.7687e-02],\n",
       "          [-1.8596e-01, -1.0593e+00, -1.8351e-02,  ...,  4.8312e-01,\n",
       "            2.8864e-02,  4.3763e-01],\n",
       "          ...,\n",
       "          [-5.1369e-01, -6.5822e-01, -5.4002e-01,  ..., -5.3425e-01,\n",
       "            4.6756e-02, -9.3715e-02],\n",
       "          [ 5.9994e-01, -1.7033e+00, -2.6492e-01,  ...,  2.7891e-01,\n",
       "           -6.4484e-02,  2.5962e-01],\n",
       "          [ 5.6732e-01, -1.1766e+00, -5.0773e-02,  ...,  5.3240e-01,\n",
       "           -5.8008e-01, -2.6174e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-5.9628e-02, -1.0636e-01,  1.5100e+00,  ..., -4.7289e-02,\n",
       "            1.9479e-01,  9.6400e-02],\n",
       "          [-1.3491e-02, -1.3643e-01,  1.7242e+00,  ...,  2.4679e-02,\n",
       "            7.1097e-02,  2.7233e-01],\n",
       "          [ 7.1882e-01,  4.5446e-01,  1.9988e+00,  ..., -1.2642e-01,\n",
       "            3.9528e-02, -3.3705e-02],\n",
       "          ...,\n",
       "          [-5.2185e-01,  3.1272e-01,  2.2864e+00,  ...,  1.0126e-01,\n",
       "           -3.5675e-01,  3.2413e-02],\n",
       "          [ 9.3450e-02, -3.4622e-01,  1.0696e+00,  ..., -1.6573e-01,\n",
       "           -7.2882e-02, -5.0589e-02],\n",
       "          [-2.4618e-01, -2.5642e-01,  1.9631e+00,  ..., -3.4110e-01,\n",
       "            1.4968e-01, -4.9283e-01]],\n",
       "\n",
       "         [[-8.4839e-02,  7.2570e-02, -1.5279e-01,  ..., -4.0045e-02,\n",
       "            9.5255e-02,  2.4219e-01],\n",
       "          [-8.5648e-01,  1.0369e+00,  4.0873e-01,  ..., -1.6662e-01,\n",
       "            7.2142e-02, -9.9685e-02],\n",
       "          [ 5.2418e-02,  6.5557e-02,  1.1180e-01,  ...,  2.8867e-01,\n",
       "           -2.5199e-01, -2.1195e-01],\n",
       "          ...,\n",
       "          [-5.0020e-01,  7.1284e-02,  6.1340e-01,  ...,  1.0013e+00,\n",
       "           -1.5522e-01, -6.3086e-01],\n",
       "          [ 4.6245e-01, -2.7737e-02,  5.4812e-01,  ...,  1.8846e-01,\n",
       "           -3.8442e-02, -2.2834e-02],\n",
       "          [-6.4406e-02,  6.5020e-01, -6.7211e-01,  ..., -6.3385e-02,\n",
       "            6.1224e-01,  1.0848e+00]],\n",
       "\n",
       "         [[-1.7838e-02,  7.4970e-02,  8.9196e-02,  ...,  1.3366e-02,\n",
       "            2.6077e-01, -2.0640e-02],\n",
       "          [-4.0540e-01, -5.5924e-02, -1.9258e-01,  ..., -1.9606e-01,\n",
       "           -1.0364e+00,  2.5853e-01],\n",
       "          [ 6.7627e-03, -2.9922e-01, -2.1357e-02,  ..., -1.3588e-01,\n",
       "           -1.5130e+00, -5.0325e-02],\n",
       "          ...,\n",
       "          [-1.4101e-01,  1.6672e-01,  6.9276e-02,  ...,  3.5731e-01,\n",
       "           -1.4280e+00, -2.1629e-01],\n",
       "          [ 2.3542e-01, -2.1355e-01, -6.9453e-01,  ..., -1.9706e-01,\n",
       "           -1.6304e+00, -8.9069e-01],\n",
       "          [-2.3135e-01, -3.0080e-01, -1.9450e-01,  ...,  4.1743e-01,\n",
       "           -1.4891e+00,  2.3966e-02]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[-0.0445, -0.1732,  0.1433,  ..., -0.8417,  0.5741, -0.9736],\n",
       "          [-1.1265, -0.8775, -0.0712,  ...,  0.6601, -0.4741, -0.6545],\n",
       "          [-0.4411,  0.7619, -1.4127,  ..., -0.1589, -1.3424,  1.7820],\n",
       "          ...,\n",
       "          [-0.2345, -0.2382, -0.0502,  ...,  1.1105, -0.3038,  0.8963],\n",
       "          [-0.9513, -0.2728,  0.4664,  ...,  0.6708, -0.5036,  2.3770],\n",
       "          [ 0.2713,  0.2616,  3.1454,  ..., -1.3161,  0.4158, -1.9686]],\n",
       "\n",
       "         [[ 0.7936,  0.1896, -0.0368,  ..., -0.1664, -1.0298, -0.1360],\n",
       "          [-0.7983, -1.3380, -1.2100,  ..., -0.2251,  3.2815,  2.0676],\n",
       "          [-0.6055, -1.1426, -0.8645,  ...,  0.5416,  5.1064,  1.4226],\n",
       "          ...,\n",
       "          [ 1.2395,  0.1238, -0.4556,  ..., -0.0304,  4.9970,  1.5094],\n",
       "          [ 1.2057,  1.1528, -0.4268,  ...,  0.1199,  4.4609,  0.9988],\n",
       "          [-1.4474,  0.0316, -0.4298,  ...,  1.0934,  2.9182, -0.9202]],\n",
       "\n",
       "         [[ 0.4372, -0.3605, -0.4240,  ...,  0.2929,  1.2889,  0.2960],\n",
       "          [-0.3895, -5.4025, -0.1113,  ..., -3.0232, -3.6669, -6.2828],\n",
       "          [-0.1608, -5.5462, -1.2650,  ..., -2.1021, -3.6281, -5.5311],\n",
       "          ...,\n",
       "          [-4.3580, -4.4129, -2.3035,  ..., -0.6905, -2.9552, -2.9318],\n",
       "          [-4.6971, -3.5403, -2.5549,  ..., -3.1455, -3.8185, -2.9296],\n",
       "          [-6.0150, -3.1827, -2.3115,  ..., -2.4671, -4.8162, -1.9092]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.1671,  1.7286,  0.4651,  ...,  0.1690,  0.3875, -1.3718],\n",
       "          [ 0.6924, -6.6042, -0.1578,  ..., -1.6872, -1.0313,  6.0350],\n",
       "          [-0.4899, -6.2238,  0.9068,  ..., -1.5398, -0.6905,  5.1511],\n",
       "          ...,\n",
       "          [ 0.5997, -5.0424, -0.4115,  ..., -3.3534, -3.8700,  6.5053],\n",
       "          [ 1.3103, -4.4278, -1.6812,  ..., -1.7889, -4.1748,  5.3079],\n",
       "          [ 0.0141, -5.2118, -1.4192,  ..., -2.2584, -1.9013,  5.8625]],\n",
       "\n",
       "         [[ 0.0731,  0.0137,  0.0860,  ..., -0.0897, -0.0516, -0.1223],\n",
       "          [-0.0769, -0.6908,  0.8271,  ...,  0.0351, -0.6309, -0.3521],\n",
       "          [-0.0395, -1.4319, -0.3336,  ...,  0.7169, -0.5604, -1.1322],\n",
       "          ...,\n",
       "          [-0.2395, -0.8231, -0.4184,  ...,  0.1113, -0.0143,  0.0979],\n",
       "          [ 0.2475, -0.3188, -1.0765,  ...,  0.0303, -0.0856, -0.0477],\n",
       "          [-0.0096,  0.3228, -0.0336,  ..., -0.3775,  0.1945,  0.5208]],\n",
       "\n",
       "         [[ 0.5052, -0.0414,  1.7121,  ..., -0.0885, -0.2402, -0.8461],\n",
       "          [ 1.5529,  1.1378, -4.0282,  ...,  0.0297,  0.4491,  3.6040],\n",
       "          [ 2.0955,  1.0104, -3.1706,  ...,  0.4620,  1.5717,  2.7603],\n",
       "          ...,\n",
       "          [-0.0932,  0.7036, -2.1452,  ..., -0.8211,  0.9730,  4.2033],\n",
       "          [ 0.8084, -0.4517, -1.8466,  ...,  0.0212,  0.0430,  4.5149],\n",
       "          [ 1.0315, -0.1052, -2.4650,  ..., -0.3019,  0.3305,  4.8601]]]],\n",
       "       device='cuda:0', grad_fn=<PermuteBackward0>), tensor([[[[ 3.3733e-02,  6.6012e-02,  1.6378e-02,  ...,  1.3302e-02,\n",
       "            4.8453e-02,  4.4001e-02],\n",
       "          [ 1.5891e-01,  3.1930e-01, -3.4281e-02,  ..., -2.4023e-01,\n",
       "            3.5412e-01, -2.4972e-02],\n",
       "          [-3.0374e-01, -4.7954e-01, -1.6503e-01,  ...,  8.7491e-02,\n",
       "           -8.3495e-02, -6.2058e-01],\n",
       "          ...,\n",
       "          [-3.6239e-01, -4.5833e-01, -7.1702e-01,  ...,  3.8925e-03,\n",
       "           -5.0935e-01,  2.0162e+00],\n",
       "          [ 1.6983e-01,  2.1001e-01, -2.8838e-03,  ...,  4.6965e-01,\n",
       "           -7.9713e-01,  4.2167e-01],\n",
       "          [ 6.5809e-01,  1.4029e-01, -4.7291e-01,  ...,  4.9714e-01,\n",
       "           -4.2475e-01,  9.1861e-01]],\n",
       "\n",
       "         [[-5.5499e-02, -1.1553e-02,  2.5362e-02,  ..., -5.0444e-02,\n",
       "           -4.4869e-02, -4.4578e-02],\n",
       "          [-4.0359e-01, -1.4406e-01, -2.1452e-01,  ..., -1.4276e-01,\n",
       "           -1.8613e-01,  1.4247e-01],\n",
       "          [ 2.7743e-01, -4.1466e-01,  2.2531e-01,  ...,  8.7252e-03,\n",
       "            2.0588e-01, -1.2202e-01],\n",
       "          ...,\n",
       "          [ 3.7603e-01,  2.3680e-01, -7.8820e-01,  ..., -1.1786e-02,\n",
       "           -5.1706e-01, -6.8942e-01],\n",
       "          [ 1.1261e-01, -4.7503e-01, -1.0802e+00,  ...,  1.8876e-01,\n",
       "            6.5399e-01, -2.0537e-01],\n",
       "          [ 3.4017e-01,  8.9463e-01, -8.5010e-01,  ...,  3.5150e-01,\n",
       "           -1.6857e-01, -6.8763e-01]],\n",
       "\n",
       "         [[ 1.7374e-02, -1.1135e-01, -4.8204e-02,  ..., -2.0336e-02,\n",
       "            5.0044e-02, -1.1479e-01],\n",
       "          [-2.7060e-01, -2.2818e-01,  4.0767e-02,  ..., -3.3700e-02,\n",
       "           -3.6734e-01,  1.8535e-01],\n",
       "          [-1.5032e-01, -6.2369e-02,  1.3662e+00,  ...,  2.4094e-01,\n",
       "            1.3030e-01, -1.3609e-01],\n",
       "          ...,\n",
       "          [ 4.9658e-01,  6.4447e-01, -4.2880e-01,  ..., -2.9902e-01,\n",
       "            6.9756e-01,  4.6350e-01],\n",
       "          [ 2.8800e-01,  1.3811e-01, -3.0088e-03,  ...,  2.2692e-01,\n",
       "           -3.4284e-01,  2.5572e-02],\n",
       "          [ 7.1157e-01,  1.3887e-01, -1.0990e+00,  ..., -3.9425e-01,\n",
       "           -1.2867e-01,  8.9076e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-4.3662e-03,  1.0092e-01, -1.6531e-02,  ..., -3.8738e-02,\n",
       "            3.1914e-02, -2.9104e-02],\n",
       "          [-2.3493e-01,  1.0163e-01, -9.4827e-02,  ..., -2.2074e-01,\n",
       "           -3.0056e-01,  6.5726e-02],\n",
       "          [ 4.3532e-02,  1.4715e-01, -6.1695e-02,  ...,  1.4896e-01,\n",
       "           -6.7345e-02,  1.0329e-01],\n",
       "          ...,\n",
       "          [ 2.8772e-02, -1.1140e-02,  1.8503e-01,  ..., -8.6666e-02,\n",
       "           -3.3609e-02, -1.3415e-01],\n",
       "          [ 1.0941e-01,  3.5161e-01, -2.4857e-01,  ..., -2.9885e-01,\n",
       "            2.1331e-01,  5.0402e-01],\n",
       "          [-1.5718e-03,  6.6608e-03,  7.5783e-01,  ...,  1.7732e-01,\n",
       "           -7.2552e-01, -1.1387e-01]],\n",
       "\n",
       "         [[-1.4882e-01, -1.1970e-01, -7.2217e-02,  ..., -2.1012e-01,\n",
       "           -5.3921e-02, -3.7135e-02],\n",
       "          [ 7.0431e-02,  8.3100e-02, -3.9138e-01,  ...,  6.9840e-01,\n",
       "            2.4757e-01,  4.7626e-02],\n",
       "          [ 7.5981e-02, -3.6651e-01,  2.7886e-02,  ...,  3.5553e-01,\n",
       "            8.2319e-01, -3.9667e-01],\n",
       "          ...,\n",
       "          [ 1.4828e+00,  1.8298e-01, -2.8312e-01,  ..., -7.9125e-01,\n",
       "           -1.7318e-01,  4.5868e-03],\n",
       "          [ 5.5531e-01,  4.7252e-01,  2.2221e-01,  ..., -3.4483e-01,\n",
       "            9.6402e-02,  8.8199e-02],\n",
       "          [ 7.2912e-01, -3.4486e-01, -2.3933e-02,  ...,  2.7319e-01,\n",
       "            1.0029e-01,  2.4822e-01]],\n",
       "\n",
       "         [[ 8.0465e-02, -2.5372e-02, -3.2156e-02,  ...,  1.2344e-02,\n",
       "           -7.1664e-02, -8.7208e-02],\n",
       "          [ 1.2070e-01,  1.9788e-01,  2.0074e-01,  ...,  1.3984e-01,\n",
       "            3.2800e-01, -1.1719e-01],\n",
       "          [ 1.3108e-01, -5.8355e-02, -1.4033e+00,  ..., -6.5388e-02,\n",
       "           -2.2900e-02,  2.7584e-01],\n",
       "          ...,\n",
       "          [ 2.4987e-01, -5.0051e-01,  3.7352e-02,  ..., -4.4063e-01,\n",
       "            8.4591e-02, -1.4338e-01],\n",
       "          [-4.2718e-01,  8.0369e-03,  8.7239e-01,  ..., -1.7318e-01,\n",
       "            2.7435e-01, -4.8682e-01],\n",
       "          [-4.6683e-02, -1.6957e-01, -8.6528e-02,  ..., -4.9601e-01,\n",
       "            3.4217e-01, -4.9665e-01]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[-7.5082e-01, -2.3918e-01,  3.2216e-01,  ..., -1.0383e+00,\n",
       "           -3.4044e-02, -2.8495e+00],\n",
       "          [ 2.2163e+00,  3.8017e-01, -2.7861e+00,  ..., -1.8368e+00,\n",
       "           -2.3042e+00,  9.1328e+00],\n",
       "          [ 2.4335e+00,  4.3201e-01, -1.8341e+00,  ..., -2.4225e+00,\n",
       "           -3.3043e+00,  8.3541e+00],\n",
       "          ...,\n",
       "          [ 2.6959e-01, -2.8727e+00,  9.0950e-01,  ...,  6.3065e-01,\n",
       "           -2.6118e+00,  6.8908e+00],\n",
       "          [-3.9501e-01, -1.6066e-01, -2.3003e+00,  ...,  6.2951e-01,\n",
       "           -5.4489e-01,  7.9849e+00],\n",
       "          [-1.0793e+00, -1.5838e+00, -2.2592e+00,  ..., -2.2888e-02,\n",
       "           -1.3322e+00,  8.7666e+00]],\n",
       "\n",
       "         [[ 3.1238e-01, -1.4696e-01,  4.9636e-01,  ..., -1.3897e-01,\n",
       "           -1.4884e-01, -1.9907e+00],\n",
       "          [-9.3001e-01,  1.1153e+00,  2.0952e+00,  ...,  7.2824e-01,\n",
       "           -2.8254e-02,  7.5361e+00],\n",
       "          [-1.3606e+00, -7.3180e-01,  2.4763e+00,  ..., -2.0710e-01,\n",
       "           -7.6466e-01,  6.5242e+00],\n",
       "          ...,\n",
       "          [-1.3611e+00, -9.5596e-01,  2.6358e+00,  ..., -1.2263e+00,\n",
       "           -2.4827e-01,  3.4555e+00],\n",
       "          [-2.7452e+00, -4.6643e-01,  2.3355e+00,  ..., -1.0588e+00,\n",
       "            4.7443e-01,  3.1850e+00],\n",
       "          [ 2.3440e-01,  5.0387e-01,  1.5756e+00,  ...,  1.2388e+00,\n",
       "           -1.3404e+00,  2.5325e+00]],\n",
       "\n",
       "         [[ 1.0076e-01, -5.9661e-01, -2.0160e-01,  ...,  1.2367e-01,\n",
       "            2.6615e-01, -2.0257e-01],\n",
       "          [ 3.8539e-01,  1.6449e+00,  4.8919e-01,  ...,  3.6195e-01,\n",
       "            5.1179e-01, -1.3867e+00],\n",
       "          [-7.5750e-01,  1.8272e+00, -3.1122e-02,  ..., -2.9052e-01,\n",
       "           -1.4626e-01,  3.0877e-02],\n",
       "          ...,\n",
       "          [ 7.5688e-01,  2.2956e+00,  3.8608e-01,  ..., -8.0571e-01,\n",
       "            1.0755e-01,  9.0155e-01],\n",
       "          [ 1.3011e+00,  8.9241e-01, -9.0363e-01,  ..., -1.2788e+00,\n",
       "            1.7174e+00,  6.5413e-01],\n",
       "          [-5.3658e-01,  1.5515e+00, -4.1949e-01,  ..., -2.8350e-01,\n",
       "            6.4557e-01,  1.1334e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-3.5032e-01, -2.8345e-02,  2.3919e-02,  ...,  1.1191e+00,\n",
       "            6.5258e-03,  1.6623e+00],\n",
       "          [ 7.5628e-01, -6.9727e-01, -1.2533e+00,  ..., -5.1757e+00,\n",
       "           -1.3228e+00, -2.0802e+00],\n",
       "          [ 8.3789e-01, -1.8562e-01,  7.4441e-02,  ..., -3.6968e+00,\n",
       "           -2.2579e-03, -1.9339e+00],\n",
       "          ...,\n",
       "          [ 1.1727e+00,  1.3474e+00,  5.5748e-01,  ..., -2.7368e+00,\n",
       "            2.4165e-02, -5.7410e-01],\n",
       "          [ 6.8052e-01,  1.5279e+00,  7.5630e-01,  ..., -1.0001e+00,\n",
       "           -5.3962e-01,  6.7673e-01],\n",
       "          [ 6.5439e-01,  6.4587e-01, -4.2587e-02,  ..., -3.2730e+00,\n",
       "            2.0664e-01, -4.2537e-01]],\n",
       "\n",
       "         [[-2.7857e-01, -1.1606e-01,  2.1084e-01,  ...,  2.0329e-01,\n",
       "           -2.5767e-02,  7.5833e-02],\n",
       "          [-8.7725e-01, -3.5614e-01, -4.2435e-02,  ..., -5.5870e-01,\n",
       "            3.9070e-01,  1.7531e+00],\n",
       "          [-9.2767e-01, -2.9832e-01, -6.5987e-01,  ..., -3.1950e-02,\n",
       "           -4.6064e-01,  1.9048e-01],\n",
       "          ...,\n",
       "          [ 5.4113e-01,  3.7743e-01, -1.2867e+00,  ..., -4.7462e-01,\n",
       "            1.8941e-01, -1.5637e+00],\n",
       "          [-4.5001e-01, -9.7498e-02,  2.6061e-01,  ..., -8.0481e-01,\n",
       "           -3.3231e-01, -1.0566e+00],\n",
       "          [-1.8227e-01,  6.0048e-01,  4.6443e-01,  ..., -4.8119e-01,\n",
       "           -1.5986e+00,  1.2402e+00]],\n",
       "\n",
       "         [[ 3.3919e+00,  1.4897e+00, -2.7191e+00,  ..., -2.7649e+00,\n",
       "           -4.0659e+00, -1.4586e+00],\n",
       "          [-3.0717e+00, -2.5502e+00,  3.9875e+00,  ..., -2.7199e-01,\n",
       "            1.1428e+01, -2.3410e+00],\n",
       "          [-4.9339e+00, -3.2748e+00,  2.2195e+00,  ..., -1.7633e+00,\n",
       "            1.2068e+01, -8.7374e-01],\n",
       "          ...,\n",
       "          [-3.9514e+00, -2.3005e+00,  7.2576e+00,  ..., -1.8185e+00,\n",
       "            7.6777e+00,  2.7285e-01],\n",
       "          [-2.3765e-01, -2.2040e+00,  1.0715e+01,  ...,  5.9747e-01,\n",
       "            5.5862e+00,  1.3056e+00],\n",
       "          [-3.0100e+00, -1.3479e+00,  8.0360e+00,  ...,  2.5767e+00,\n",
       "            1.0698e+01,  5.3380e-01]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[ 2.3599e-02, -2.0255e-02,  3.2086e-02,  ...,  5.2608e-02,\n",
       "            3.5070e-02,  7.1486e-02],\n",
       "          [-4.7239e-02,  1.3519e-01,  3.9259e-01,  ..., -5.0644e-02,\n",
       "            3.1967e-01,  1.2956e-02],\n",
       "          [-1.3030e-01,  9.3782e-03,  2.5804e-01,  ..., -1.4863e-01,\n",
       "            4.8173e-01,  2.3377e-01],\n",
       "          ...,\n",
       "          [-6.0358e-02,  1.5319e-01,  5.4309e-01,  ...,  2.2823e-01,\n",
       "           -4.8518e-01, -5.8641e-02],\n",
       "          [-1.5736e-01,  4.6935e-01, -3.8965e-02,  ...,  6.4282e-02,\n",
       "           -2.5121e-03,  2.6902e-01],\n",
       "          [-2.7348e-02,  9.7147e-01,  5.0009e-01,  ...,  2.3972e-01,\n",
       "            1.4259e-01, -1.0275e+00]],\n",
       "\n",
       "         [[-4.9450e-02,  3.0911e-02, -1.1652e-01,  ..., -2.8467e-02,\n",
       "            3.5315e-02,  9.1912e-03],\n",
       "          [-1.5000e-01,  2.1895e-01,  5.3990e-01,  ..., -1.4040e-01,\n",
       "            4.1709e-05,  2.7697e-01],\n",
       "          [-2.5668e-01,  5.2249e-01, -7.0404e-02,  ...,  2.1387e-01,\n",
       "            3.5178e-01,  1.6200e-01],\n",
       "          ...,\n",
       "          [-2.6046e-01, -8.4009e-03,  2.5444e-01,  ..., -2.4751e-02,\n",
       "            2.9131e-02, -4.9069e-01],\n",
       "          [-6.3026e-01,  1.2626e-01, -9.9541e-02,  ...,  1.1198e+00,\n",
       "           -5.3596e-01,  5.5749e-01],\n",
       "          [-2.7787e-01,  1.9723e-01, -1.2068e-01,  ..., -3.9889e-01,\n",
       "           -4.3301e-03, -3.2802e-02]],\n",
       "\n",
       "         [[ 4.4233e-02,  5.6652e-02,  5.6155e-02,  ...,  1.9330e-02,\n",
       "           -5.1314e-02,  3.2902e-02],\n",
       "          [ 7.0868e-01,  4.0349e-01, -1.3648e-01,  ...,  7.4399e-02,\n",
       "           -6.5978e-01,  2.0453e-01],\n",
       "          [ 8.8006e-02,  2.2971e-01, -8.9756e-02,  ..., -1.7564e-01,\n",
       "           -4.6339e-01,  1.0599e-01],\n",
       "          ...,\n",
       "          [ 1.1331e+00,  3.2651e-01, -1.3137e-01,  ..., -9.1554e-02,\n",
       "            1.3199e-03,  2.6105e-01],\n",
       "          [-1.0202e+00,  1.1463e+00,  1.1819e-01,  ...,  9.3613e-02,\n",
       "           -3.1310e-01,  6.2630e-01],\n",
       "          [ 1.7332e-01, -2.4858e-01,  1.2596e-01,  ..., -6.0141e-03,\n",
       "            6.8246e-01, -2.1596e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.8518e-02,  7.5956e-02, -6.2162e-02,  ...,  1.4098e-02,\n",
       "            2.5723e-02, -1.3595e-01],\n",
       "          [ 2.9714e-01,  1.4240e-01,  6.7918e-02,  ...,  1.1450e-01,\n",
       "           -2.5393e-01, -2.0505e-01],\n",
       "          [ 1.2973e-01,  1.6346e-02,  3.3992e-01,  ...,  5.0629e-02,\n",
       "            2.0515e-01,  2.4527e-01],\n",
       "          ...,\n",
       "          [ 1.1398e-01,  5.6268e-01, -1.6699e-02,  ...,  2.4644e-01,\n",
       "            6.4151e-01, -5.9921e-01],\n",
       "          [ 2.4357e-01, -5.5891e-01,  1.5980e-01,  ..., -5.1543e-01,\n",
       "            3.1344e-01,  2.4917e-01],\n",
       "          [ 4.2161e-01,  2.8825e-01,  2.7889e-01,  ..., -1.7157e-01,\n",
       "           -5.3255e-01, -6.2641e-04]],\n",
       "\n",
       "         [[-1.2348e-01, -4.5686e-02,  6.1339e-02,  ..., -3.2211e-02,\n",
       "            2.8631e-02, -2.8165e-02],\n",
       "          [-4.8698e-02,  1.1693e+00, -8.2036e-01,  ...,  1.8517e-01,\n",
       "           -3.9606e-01,  3.1117e-01],\n",
       "          [ 6.7750e-01,  3.9446e-01, -2.4252e-01,  ...,  6.7541e-01,\n",
       "            1.6220e-01, -1.3033e-02],\n",
       "          ...,\n",
       "          [ 3.1270e-02, -3.4561e-01, -2.1793e-02,  ..., -6.8258e-02,\n",
       "           -1.0220e-01, -8.3195e-01],\n",
       "          [ 5.6483e-01,  2.9848e-01,  1.6201e+00,  ...,  1.2882e+00,\n",
       "            2.3477e-01, -1.5526e+00],\n",
       "          [-2.8784e-01,  1.7500e-01,  1.1844e+00,  ..., -5.7531e-02,\n",
       "            5.7418e-01, -2.1995e-01]],\n",
       "\n",
       "         [[-3.6170e-03,  2.4679e-02, -2.6419e-02,  ..., -3.1119e-02,\n",
       "            1.1999e-02,  3.5070e-02],\n",
       "          [-3.6602e-02,  9.6639e-02,  1.1699e-01,  ...,  1.3329e-01,\n",
       "           -6.7894e-02,  4.8756e-01],\n",
       "          [ 2.1306e-01, -1.0771e-01, -3.2780e-01,  ..., -3.0078e-02,\n",
       "           -9.9587e-02,  1.8089e-01],\n",
       "          ...,\n",
       "          [-4.4582e-01,  4.4302e-01, -4.7381e-02,  ...,  5.6203e-01,\n",
       "           -3.6227e-01,  4.7314e-01],\n",
       "          [-1.0143e-02,  1.8780e-01, -1.9245e-01,  ...,  3.1774e-01,\n",
       "            3.7461e-01, -1.9328e-02],\n",
       "          [ 3.3521e-01,  3.3743e-02,  1.6071e+00,  ...,  8.1328e-01,\n",
       "            1.7064e-01,  7.1025e-01]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[-1.0975e-02, -2.8705e-01,  2.1533e-01,  ...,  1.4592e+00,\n",
       "           -1.7735e-01, -1.5723e-02],\n",
       "          [ 1.0639e-02,  8.1240e-01,  5.6452e-01,  ..., -1.7811e+00,\n",
       "            1.2961e+00, -6.3379e-01],\n",
       "          [-1.1005e-01,  2.3060e-02,  2.3760e-02,  ..., -2.2690e+00,\n",
       "            1.4818e-01, -3.4189e-01],\n",
       "          ...,\n",
       "          [-1.3483e+00, -1.8458e+00, -2.6039e-01,  ..., -4.5733e+00,\n",
       "            5.3055e-02, -1.7489e-01],\n",
       "          [-4.0923e-01, -7.0637e-02, -7.1382e-03,  ..., -3.2199e+00,\n",
       "            2.4415e-01, -4.9722e-01],\n",
       "          [-4.9164e-01, -7.9679e-01, -1.5352e+00,  ..., -3.5371e+00,\n",
       "           -4.4186e-01, -1.9392e-01]],\n",
       "\n",
       "         [[ 1.7343e-01,  8.1968e-01, -1.2307e+00,  ..., -1.2898e-01,\n",
       "            2.7799e-01,  7.8210e-01],\n",
       "          [ 1.0020e-01, -2.5740e+00,  4.3210e-01,  ..., -5.0274e-01,\n",
       "            5.0626e-01, -1.2718e+00],\n",
       "          [ 9.4922e-01, -2.6693e+00,  8.2233e-02,  ..., -1.5135e+00,\n",
       "           -5.6715e-01, -8.9571e-01],\n",
       "          ...,\n",
       "          [ 1.0255e+00, -3.5629e+00,  2.4391e+00,  ..., -9.1229e-01,\n",
       "            2.5119e+00, -3.4231e+00],\n",
       "          [ 1.3036e+00, -1.2388e+00,  1.7273e+00,  ..., -1.4405e+00,\n",
       "            1.6542e+00, -2.5272e+00],\n",
       "          [ 5.8190e-01, -1.8213e+00,  4.1066e+00,  ..., -8.8487e-01,\n",
       "            2.7088e+00, -1.7128e+00]],\n",
       "\n",
       "         [[-6.6441e-01,  1.1464e-01, -6.5455e-03,  ...,  7.2032e-02,\n",
       "            1.0701e-01, -2.6402e-01],\n",
       "          [ 7.7326e-01,  3.3692e-01, -2.7091e-01,  ...,  3.6581e-01,\n",
       "            6.0133e-01, -4.9843e-01],\n",
       "          [ 2.2114e+00,  7.7174e-01, -3.5037e-01,  ..., -2.6573e-01,\n",
       "           -6.6625e-01, -8.2685e-01],\n",
       "          ...,\n",
       "          [ 2.3229e+00, -6.3435e-01,  1.6090e+00,  ...,  4.1781e-01,\n",
       "            7.6907e-01, -6.9171e-01],\n",
       "          [ 5.7422e-01, -1.4255e+00,  6.6885e-01,  ...,  1.2177e+00,\n",
       "            1.2764e+00,  2.0630e-01],\n",
       "          [ 1.0420e+00, -1.4322e+00,  8.8623e-01,  ...,  3.6141e-03,\n",
       "            1.5313e+00, -1.4943e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-4.1440e-02,  5.8181e-02,  1.4865e-01,  ..., -9.6627e-02,\n",
       "            2.4565e-02,  1.3746e-01],\n",
       "          [ 2.1182e+00, -1.0237e-01,  6.1345e-01,  ...,  1.6160e-02,\n",
       "            2.6028e-01,  4.8420e-01],\n",
       "          [ 1.7233e+00,  6.2631e-01,  1.1279e+00,  ..., -3.1150e-02,\n",
       "            1.6256e-01, -6.5411e-02],\n",
       "          ...,\n",
       "          [-4.4559e-01,  8.2594e-01, -8.2461e-02,  ...,  1.2161e-01,\n",
       "            2.5711e-02,  3.8233e-01],\n",
       "          [ 3.9124e-01, -1.1350e+00,  8.6474e-01,  ..., -3.8798e-01,\n",
       "           -2.3915e-01, -6.9305e-01],\n",
       "          [-7.4081e-01, -1.6993e+00,  1.2160e+00,  ...,  5.1095e-01,\n",
       "            2.0750e-01, -2.0779e-02]],\n",
       "\n",
       "         [[-2.6535e+00,  3.8615e-01, -1.3803e-02,  ..., -4.5092e-01,\n",
       "           -2.8958e-01,  1.1768e+00],\n",
       "          [ 4.4476e+00, -1.2610e-01, -1.4526e-03,  ..., -1.1920e+00,\n",
       "           -9.4771e-01,  9.0810e-01],\n",
       "          [ 4.3885e+00,  2.3312e-01, -9.2612e-01,  ..., -1.0636e+00,\n",
       "           -4.3096e-01,  7.8953e-01],\n",
       "          ...,\n",
       "          [ 4.9655e+00, -2.5980e-01, -7.3178e-01,  ..., -5.6124e-01,\n",
       "            1.6466e-01, -3.5334e-01],\n",
       "          [ 4.7204e+00, -8.3616e-01, -1.9187e-01,  ..., -3.9811e-01,\n",
       "           -1.1830e+00,  7.7597e-01],\n",
       "          [ 4.7032e+00, -3.4989e-01,  2.0490e-01,  ..., -5.1268e-01,\n",
       "            2.1746e+00, -1.0975e+00]],\n",
       "\n",
       "         [[ 3.7829e-02, -2.2848e-01,  6.5408e-03,  ..., -1.7037e-01,\n",
       "            3.5663e-01,  1.3012e-01],\n",
       "          [ 4.9994e-01, -5.7046e-01,  1.8382e-01,  ..., -8.6132e-02,\n",
       "            1.7181e+00, -8.8885e-01],\n",
       "          [ 3.6855e-01, -1.1214e+00, -3.9706e-01,  ...,  7.9067e-01,\n",
       "            1.1037e+00, -4.0723e-01],\n",
       "          ...,\n",
       "          [ 9.6589e-02, -1.8708e+00,  7.9793e-02,  ..., -2.4507e-01,\n",
       "            2.2143e-01,  1.5306e-01],\n",
       "          [-1.1074e+00, -2.0089e+00, -1.0068e+00,  ...,  1.4054e+00,\n",
       "           -7.4824e-02,  5.7204e-01],\n",
       "          [ 1.1876e-01,  8.5921e-01, -5.1683e-01,  ...,  3.4444e-01,\n",
       "           -1.1833e-02, -9.5438e-01]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[-3.0007e-03, -1.0269e-02,  2.5252e-02,  ..., -5.8876e-03,\n",
       "           -2.7782e-02,  2.9319e-01],\n",
       "          [ 6.1419e-02,  3.8079e-01,  4.1829e-01,  ...,  2.2550e-01,\n",
       "            4.8459e-01, -1.0755e-01],\n",
       "          [ 8.6920e-01,  1.7722e-01,  2.2370e-01,  ..., -5.8062e-01,\n",
       "            7.7392e-01, -7.0909e-01],\n",
       "          ...,\n",
       "          [ 5.5645e-01, -9.6041e-01, -1.9077e-01,  ..., -3.1962e-01,\n",
       "           -5.0814e-01, -1.0034e+00],\n",
       "          [ 4.2956e-01,  5.9292e-01,  2.7573e-01,  ...,  1.0783e-01,\n",
       "           -1.0791e-01, -1.1829e+00],\n",
       "          [ 3.7429e-01,  4.1114e-01,  4.1482e-01,  ...,  3.7167e-01,\n",
       "           -4.5735e-01, -3.0483e-01]],\n",
       "\n",
       "         [[ 1.4225e-02, -3.2158e-02, -7.4767e-03,  ..., -2.0682e-02,\n",
       "           -1.5941e-02, -6.1626e-03],\n",
       "          [ 6.9079e-01, -4.8276e-02, -8.5209e-01,  ..., -4.5079e-01,\n",
       "            1.3598e+00, -4.5734e-01],\n",
       "          [ 1.5451e+00, -4.0991e-02, -4.8676e-01,  ..., -2.3202e-01,\n",
       "            1.0109e+00,  7.6311e-02],\n",
       "          ...,\n",
       "          [ 6.2795e-01, -3.1951e-01,  1.5598e-01,  ...,  3.8007e-01,\n",
       "            3.0410e-01,  3.3608e-04],\n",
       "          [ 1.7902e-02,  1.6594e-01, -4.6554e-01,  ..., -5.8931e-01,\n",
       "            2.9828e-01, -7.9607e-02],\n",
       "          [-6.7439e-01,  3.5281e-01,  4.6497e-01,  ..., -1.2815e+00,\n",
       "           -6.9689e-01, -1.3630e+00]],\n",
       "\n",
       "         [[-3.3407e-02,  1.9988e-02, -2.0681e-02,  ..., -5.6353e-02,\n",
       "            3.0523e-02, -7.9550e-02],\n",
       "          [-1.0731e-01,  1.5261e-02,  7.2175e-02,  ...,  1.4584e-01,\n",
       "           -2.2800e-01, -1.1277e-01],\n",
       "          [-6.3317e-03,  4.6781e-01, -3.2585e-01,  ..., -3.7369e-01,\n",
       "            5.0738e-01,  2.4008e-01],\n",
       "          ...,\n",
       "          [ 1.1731e+00,  6.9067e-01,  5.7706e-01,  ..., -2.2573e-01,\n",
       "           -7.6317e-01,  2.0210e-01],\n",
       "          [-3.2891e-01, -3.4113e-01,  4.0858e-01,  ..., -1.2164e+00,\n",
       "           -1.9897e-01,  2.8576e-01],\n",
       "          [ 3.8532e-01,  9.8635e-01,  7.8301e-01,  ...,  7.5645e-01,\n",
       "           -1.7149e+00, -3.5381e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.4786e-01, -8.0112e-02, -4.1510e-02,  ..., -4.2204e-01,\n",
       "            1.6747e-01,  6.9607e-02],\n",
       "          [ 7.4160e-01, -9.5208e-01, -6.7841e-02,  ...,  9.8351e-01,\n",
       "            1.3057e-01, -1.1073e+00],\n",
       "          [ 7.1311e-01, -8.9457e-01, -7.6325e-01,  ...,  1.6451e+00,\n",
       "           -2.6021e-01, -4.8010e-01],\n",
       "          ...,\n",
       "          [-1.0487e+00, -9.5320e-01,  8.3795e-01,  ...,  1.6726e-01,\n",
       "            4.3559e-01,  5.2488e-01],\n",
       "          [ 3.1049e-02, -7.6678e-01,  1.4021e+00,  ..., -1.1818e-01,\n",
       "           -1.0887e+00, -1.5078e+00],\n",
       "          [ 8.7805e-01,  6.6784e-01,  4.9668e-01,  ..., -2.6668e-01,\n",
       "            5.5992e-01, -2.1934e+00]],\n",
       "\n",
       "         [[-9.7283e-02, -1.1640e-01, -5.7265e-02,  ..., -1.4053e-01,\n",
       "           -1.1866e-01,  8.5977e-02],\n",
       "          [ 1.5585e-01,  1.4863e-01, -1.2429e-01,  ..., -3.9403e-01,\n",
       "            4.1040e-01,  9.2649e-02],\n",
       "          [ 1.8223e-02,  6.3648e-02, -4.8299e-01,  ..., -3.3920e-01,\n",
       "           -4.1437e-01, -2.5764e-01],\n",
       "          ...,\n",
       "          [ 7.1709e-02, -4.3549e-01,  3.4586e-01,  ...,  8.5039e-01,\n",
       "           -4.7060e-01,  4.8395e-02],\n",
       "          [ 3.2840e-01,  6.3409e-03, -4.6007e-02,  ...,  5.1359e-01,\n",
       "            6.3565e-02, -4.1298e-01],\n",
       "          [-2.6743e-01, -9.2029e-01,  2.0720e-01,  ..., -1.7736e-01,\n",
       "           -2.4991e-01, -1.6023e-01]],\n",
       "\n",
       "         [[-5.1410e-02, -5.0676e-02,  8.0793e-02,  ...,  7.2558e-02,\n",
       "           -2.1244e-02,  1.0650e-02],\n",
       "          [ 3.8632e-01,  2.8314e-01,  5.7158e-01,  ...,  3.3883e-01,\n",
       "            2.3144e-01,  1.5330e-01],\n",
       "          [-1.7825e-01,  4.4261e-01, -5.6225e-01,  ..., -7.0969e-01,\n",
       "            2.8624e-01, -1.7672e-01],\n",
       "          ...,\n",
       "          [ 1.1804e+00, -5.4463e-01, -1.3670e+00,  ...,  1.7909e-01,\n",
       "           -5.1962e-01,  3.3931e-01],\n",
       "          [ 2.3002e+00, -1.6801e+00, -1.4358e+00,  ..., -1.5541e+00,\n",
       "           -4.9502e-01,  1.7225e+00],\n",
       "          [-3.2565e-01, -4.9859e-02, -8.4127e-01,  ...,  4.5712e-01,\n",
       "           -4.3438e-01,  7.7001e-01]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[-2.7507e-01,  6.4022e-01, -2.8222e-01,  ...,  1.0715e+00,\n",
       "           -2.6509e-01,  2.2134e-01],\n",
       "          [-4.0640e-01, -5.3484e+00,  1.9776e-01,  ..., -3.1350e+00,\n",
       "            1.8505e+00,  3.7320e-01],\n",
       "          [ 4.1216e-01, -4.4894e+00, -2.6691e-02,  ..., -2.6544e+00,\n",
       "            1.0043e+00,  1.6130e+00],\n",
       "          ...,\n",
       "          [ 1.7288e-01, -2.6414e+00,  2.1703e+00,  ..., -1.9024e+00,\n",
       "            5.2257e-01,  9.3356e-01],\n",
       "          [ 1.2497e+00, -3.6835e+00,  4.0954e-01,  ..., -2.9921e+00,\n",
       "           -1.5458e-01,  3.7753e-01],\n",
       "          [ 5.9708e-02, -1.8778e+00,  2.2701e+00,  ..., -2.1521e+00,\n",
       "           -9.8841e-01,  1.9011e+00]],\n",
       "\n",
       "         [[-4.2665e-02,  7.6331e-01, -6.3369e-01,  ..., -1.0015e-01,\n",
       "            2.8089e-01, -5.5085e-02],\n",
       "          [ 1.6277e+00,  2.1614e+00, -5.7761e-01,  ...,  1.5745e-01,\n",
       "            7.1634e-01, -9.4698e-01],\n",
       "          [ 6.3507e-01,  1.8688e+00, -1.0399e+00,  ...,  9.5179e-01,\n",
       "            4.5587e-01, -8.2784e-01],\n",
       "          ...,\n",
       "          [-8.2330e-02, -1.1232e+00, -8.5797e-01,  ..., -7.6283e-02,\n",
       "            9.8615e-01, -3.0949e-01],\n",
       "          [-5.9620e-01, -6.8557e-01, -5.6425e-02,  ..., -4.6824e-01,\n",
       "            9.6672e-01, -1.2627e+00],\n",
       "          [-1.9135e-01,  7.7555e-01, -8.9607e-02,  ..., -5.9890e-01,\n",
       "            1.0537e+00, -1.0985e+00]],\n",
       "\n",
       "         [[-2.8718e-01,  1.2457e-01, -8.6505e-01,  ..., -3.1391e-01,\n",
       "            1.8779e-02, -9.7453e-02],\n",
       "          [-6.0182e-01,  6.1755e-01,  3.7309e+00,  ...,  7.4514e-01,\n",
       "            7.5872e-02, -7.7273e-01],\n",
       "          [-2.4125e-01,  1.7412e-01,  2.6763e+00,  ...,  3.8896e-01,\n",
       "           -9.5461e-01,  1.5705e-01],\n",
       "          ...,\n",
       "          [-4.6316e-01,  5.8537e-01,  1.0258e+00,  ...,  4.0486e-01,\n",
       "           -7.5530e-01, -2.7197e-01],\n",
       "          [-1.2144e-01, -6.9627e-01,  6.2906e-01,  ...,  1.3455e+00,\n",
       "           -1.1286e+00,  1.1834e+00],\n",
       "          [ 3.9349e-01,  1.6241e+00,  2.0219e+00,  ...,  7.8529e-01,\n",
       "            9.1349e-01,  1.4555e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.2016e-01,  4.5280e-02, -6.0067e-02,  ...,  3.6574e-02,\n",
       "            1.9019e-01, -2.5614e-02],\n",
       "          [-9.2613e-01,  8.6485e-02, -2.3562e-01,  ..., -7.5047e-01,\n",
       "            4.0712e-01, -2.1066e-01],\n",
       "          [-2.4343e-01, -7.8994e-01, -4.3415e-02,  ..., -7.5071e-01,\n",
       "            6.1958e-02, -6.9401e-01],\n",
       "          ...,\n",
       "          [ 4.0727e-01, -1.1705e+00,  1.6583e+00,  ...,  3.7931e-01,\n",
       "           -8.0390e-01, -3.8224e-02],\n",
       "          [ 1.7190e-01, -5.9297e-01,  8.6100e-01,  ..., -2.2744e-01,\n",
       "            1.6594e-01,  7.8090e-01],\n",
       "          [-4.2068e-01,  5.2060e-01,  1.3777e+00,  ...,  1.3230e+00,\n",
       "            7.7503e-02,  9.6879e-01]],\n",
       "\n",
       "         [[ 2.2049e-01,  8.5001e-02,  2.6589e-01,  ...,  3.2094e-01,\n",
       "            6.0526e-02,  2.3229e-01],\n",
       "          [ 1.2087e+00,  7.9662e-01,  7.4289e-02,  ...,  6.7964e-01,\n",
       "           -8.9217e-01,  2.6535e-01],\n",
       "          [-2.7851e-01,  5.2153e-01,  5.7161e-01,  ..., -3.6024e-01,\n",
       "            8.4129e-02, -2.9692e-01],\n",
       "          ...,\n",
       "          [ 2.3620e-01, -3.3627e-01,  2.4231e-01,  ..., -6.7138e-01,\n",
       "           -1.0179e+00, -1.4965e+00],\n",
       "          [ 2.4293e-02,  1.0921e+00,  4.1701e-01,  ..., -8.1524e-01,\n",
       "            1.9783e-01,  3.3819e-01],\n",
       "          [ 1.1633e+00, -4.8260e-01,  2.3214e-01,  ..., -1.6108e+00,\n",
       "           -7.6200e-01,  6.6906e-01]],\n",
       "\n",
       "         [[-2.7614e+00,  3.7896e-01,  3.9004e-01,  ..., -7.8563e-01,\n",
       "            2.8747e-01,  1.4416e-01],\n",
       "          [ 1.0445e+01, -1.7699e-01, -1.1411e+00,  ...,  4.0690e+00,\n",
       "           -9.0085e-01,  1.7045e+00],\n",
       "          [ 9.7918e+00,  8.0002e-03, -1.8386e+00,  ...,  2.8927e+00,\n",
       "           -8.4133e-01,  2.1277e+00],\n",
       "          ...,\n",
       "          [ 8.0690e+00, -1.0057e+00,  2.8025e-01,  ...,  1.3302e+00,\n",
       "            1.0319e+00, -6.4284e-01],\n",
       "          [ 7.3058e+00, -1.4214e+00, -1.6226e+00,  ...,  2.1555e-01,\n",
       "            1.7112e-01, -1.2057e+00],\n",
       "          [ 6.6788e+00, -7.2899e-01, -5.1488e-01,  ...,  4.7668e-01,\n",
       "           -1.1274e+00, -5.4167e-01]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[-2.0502e-02, -7.2253e-03,  1.5728e-02,  ..., -8.8364e-02,\n",
       "           -3.0822e-02, -1.1890e-01],\n",
       "          [-4.8458e-01, -2.9315e-01, -1.0869e-01,  ...,  4.7950e-02,\n",
       "           -6.8197e-02, -9.9591e-01],\n",
       "          [-1.0591e-01,  1.8328e-01, -4.2269e-01,  ...,  2.4274e-01,\n",
       "           -2.5571e-01, -4.3939e-01],\n",
       "          ...,\n",
       "          [-1.3860e-01,  2.7729e-01, -8.2746e-01,  ..., -6.4335e-03,\n",
       "            5.0687e-01,  2.7192e-01],\n",
       "          [ 2.2718e-01, -1.9320e-01, -4.4630e-01,  ...,  3.5271e-01,\n",
       "           -5.9913e-01,  9.0867e-02],\n",
       "          [-2.3382e-01,  5.3194e-01, -1.4935e-01,  ..., -2.0650e-01,\n",
       "           -7.6206e-01, -9.8652e-01]],\n",
       "\n",
       "         [[ 6.6624e-02, -1.4993e-02,  1.6834e-03,  ..., -3.0188e-02,\n",
       "            2.0378e-02, -6.0369e-03],\n",
       "          [ 3.0436e-02,  3.1926e-01, -4.9895e-01,  ..., -5.2394e-01,\n",
       "           -1.7727e-01, -4.2826e-01],\n",
       "          [ 9.3342e-02,  2.3561e-01, -1.0101e+00,  ...,  7.6194e-01,\n",
       "           -5.9351e-01,  2.9755e-01],\n",
       "          ...,\n",
       "          [ 2.2050e-01,  1.1752e+00, -3.5891e-01,  ...,  7.3674e-01,\n",
       "           -1.1131e+00,  1.1567e-01],\n",
       "          [-1.0246e-01, -5.9956e-01,  3.7127e-01,  ..., -2.8524e-01,\n",
       "            6.0171e-01,  1.2508e-01],\n",
       "          [-7.3710e-01, -6.8684e-01, -1.3423e+00,  ...,  9.5323e-01,\n",
       "            6.0086e-01,  8.4318e-02]],\n",
       "\n",
       "         [[ 6.7167e-02,  2.1480e-02, -1.0381e-02,  ...,  4.9186e-02,\n",
       "            5.7107e-03,  4.1016e-02],\n",
       "          [-2.5147e-01, -1.8193e-01, -5.7122e-01,  ...,  2.7193e-01,\n",
       "            1.4405e+00,  6.8265e-01],\n",
       "          [-5.5509e-01,  1.6786e-01, -4.9883e-01,  ...,  2.9455e-01,\n",
       "           -3.3884e-01,  7.6752e-01],\n",
       "          ...,\n",
       "          [-4.0717e-01, -9.1969e-01,  3.3521e-01,  ..., -6.7300e-02,\n",
       "           -3.1175e-01,  4.9907e-01],\n",
       "          [ 3.1522e-01,  6.1127e-02, -5.9542e-01,  ..., -3.3488e-01,\n",
       "            1.4367e+00, -8.9857e-03],\n",
       "          [-1.4532e+00, -1.2939e+00, -8.8232e-01,  ...,  3.0747e-01,\n",
       "            5.0196e-01,  2.6975e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.3611e-02,  3.8592e-02,  1.3044e-02,  ..., -2.6977e-02,\n",
       "           -2.1484e-02,  1.0393e-02],\n",
       "          [-6.5130e-01,  1.6605e-01,  1.0657e-01,  ...,  2.7835e-01,\n",
       "           -6.9238e-02, -3.0253e-01],\n",
       "          [-5.5479e-01, -5.4661e-01, -1.2732e-01,  ...,  4.4478e-01,\n",
       "           -1.3895e+00,  6.9371e-02],\n",
       "          ...,\n",
       "          [ 7.1077e-03, -2.0203e-01, -1.5514e-01,  ..., -4.3295e-02,\n",
       "           -1.5142e+00,  7.4447e-01],\n",
       "          [ 6.8730e-01,  4.3394e-01,  7.8727e-01,  ...,  3.8452e-01,\n",
       "           -5.5940e-01,  2.6835e-01],\n",
       "          [-3.3768e-01, -7.1513e-01,  5.8005e-01,  ..., -9.3141e-01,\n",
       "            2.1281e+00,  1.7262e-01]],\n",
       "\n",
       "         [[ 6.3200e-02, -1.0620e-02, -1.6518e-02,  ...,  9.4679e-02,\n",
       "           -1.0668e-02,  3.3107e-02],\n",
       "          [ 5.1620e-01, -7.9607e-01, -6.5327e-01,  ...,  7.5826e-02,\n",
       "            2.6742e-01,  7.0262e-01],\n",
       "          [-2.9301e-01,  1.1497e-01,  1.1904e-01,  ..., -5.7305e-01,\n",
       "           -2.3403e-01, -3.7106e-01],\n",
       "          ...,\n",
       "          [-8.5946e-01, -5.4443e-01, -1.4565e-01,  ..., -4.1868e-01,\n",
       "            5.7312e-01,  5.7441e-01],\n",
       "          [ 1.3619e-01, -1.2818e-01,  1.0067e-01,  ..., -1.9136e-01,\n",
       "            1.5723e+00, -7.1590e-01],\n",
       "          [-1.8020e+00,  6.4935e-02,  8.0408e-01,  ...,  1.1006e+00,\n",
       "            7.3148e-01, -8.9776e-01]],\n",
       "\n",
       "         [[ 2.7450e-02, -1.7117e-01, -4.1035e-02,  ..., -6.8331e-02,\n",
       "            1.5973e-01, -1.2446e-02],\n",
       "          [-3.5405e-01, -1.4234e-01, -2.1591e-01,  ..., -7.4673e-01,\n",
       "            2.5460e-02,  5.6931e-01],\n",
       "          [-4.9000e-01,  3.0493e-02, -2.4359e-02,  ..., -1.4033e-01,\n",
       "           -2.5847e-01,  1.9334e-01],\n",
       "          ...,\n",
       "          [ 1.0194e-01,  1.1360e+00,  3.7560e-01,  ..., -1.7933e-01,\n",
       "           -9.7488e-02,  4.8762e-01],\n",
       "          [ 1.5532e-01,  6.6894e-01,  4.3730e-02,  ..., -8.7515e-01,\n",
       "           -2.5893e-01, -6.4448e-01],\n",
       "          [ 5.5215e-01, -5.3483e-01, -2.2079e-01,  ..., -1.5374e+00,\n",
       "           -7.4178e-01, -1.4181e-02]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[ 9.9479e-01, -1.9414e-01, -1.2558e-01,  ...,  5.1885e-01,\n",
       "            6.0851e-01, -1.8959e-01],\n",
       "          [-6.4870e+00, -2.3747e+00, -7.0520e-01,  ...,  6.8807e-02,\n",
       "           -4.7217e+00, -1.2840e-01],\n",
       "          [-5.4583e+00, -1.8097e+00, -3.4476e-01,  ...,  8.4178e-01,\n",
       "           -4.4909e+00, -4.9890e-01],\n",
       "          ...,\n",
       "          [-5.0441e+00, -1.5804e+00, -4.2431e-01,  ...,  2.4251e-01,\n",
       "           -3.3673e+00, -2.8065e-01],\n",
       "          [-3.4643e+00, -8.2889e-01,  3.3777e-02,  ..., -1.0679e+00,\n",
       "           -3.1331e+00, -1.1749e-01],\n",
       "          [-3.2718e+00, -3.1036e+00, -8.0092e-01,  ..., -1.2695e+00,\n",
       "           -2.6305e+00,  8.5056e-01]],\n",
       "\n",
       "         [[-1.5334e-01, -1.2854e-01,  2.2089e-01,  ...,  4.5993e-02,\n",
       "           -8.0182e-01, -1.0308e-01],\n",
       "          [ 5.7813e-01,  3.0842e-02, -1.3740e-01,  ..., -1.1853e+00,\n",
       "           -8.8004e-01,  9.6248e-02],\n",
       "          [-2.6747e-01,  3.0370e-01, -7.9243e-01,  ...,  1.4508e-01,\n",
       "            2.8252e-01,  5.9529e-01],\n",
       "          ...,\n",
       "          [ 3.1740e-01, -3.0217e-01, -1.0712e+00,  ..., -9.6065e-01,\n",
       "           -1.8706e+00,  9.5390e-01],\n",
       "          [-1.4635e+00,  2.6672e-01, -6.0326e-01,  ...,  3.8400e-01,\n",
       "            1.0399e+00,  9.7562e-01],\n",
       "          [-4.9877e-01, -8.5461e-01, -3.5172e-01,  ..., -2.5356e-02,\n",
       "            1.2686e+00, -8.3560e-01]],\n",
       "\n",
       "         [[ 2.7887e-01,  1.7484e-01,  1.0342e+00,  ..., -3.8073e-01,\n",
       "            3.5110e-01, -4.0208e-01],\n",
       "          [-3.4856e-01, -1.5613e-01, -1.2746e+00,  ..., -4.7523e-02,\n",
       "           -5.3294e-01,  1.9315e+00],\n",
       "          [-9.7536e-01, -4.4070e-01, -1.1045e+00,  ..., -7.8743e-01,\n",
       "           -1.4267e+00,  2.1690e+00],\n",
       "          ...,\n",
       "          [ 9.2098e-01, -1.3095e+00, -9.9568e-01,  ...,  2.2007e+00,\n",
       "           -8.6714e-01, -1.2989e+00],\n",
       "          [ 1.1834e+00, -9.3749e-01, -4.6653e-01,  ...,  5.1853e-01,\n",
       "           -5.1408e-01,  1.9486e+00],\n",
       "          [ 7.5667e-01, -4.0592e-01, -2.9426e-01,  ...,  9.7518e-01,\n",
       "            1.7011e+00,  9.2694e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.8243e-01,  2.9479e-02, -1.9406e-01,  ...,  1.0815e-02,\n",
       "            1.1205e-01,  2.1801e-02],\n",
       "          [-1.3697e+00,  4.6499e-01,  7.2391e-01,  ...,  6.2479e-01,\n",
       "           -1.0985e+00,  4.1697e-01],\n",
       "          [-1.6349e+00, -7.1807e-02, -3.4046e-03,  ...,  1.0923e+00,\n",
       "            3.3014e-01, -1.0764e-01],\n",
       "          ...,\n",
       "          [ 2.0497e+00,  7.1454e-01,  1.6261e+00,  ...,  1.3428e+00,\n",
       "            1.3166e+00,  5.7375e-01],\n",
       "          [ 4.9388e-01, -7.0137e-01,  1.0655e+00,  ...,  2.5426e+00,\n",
       "           -4.5952e-01, -9.0583e-01],\n",
       "          [-5.1293e-01,  4.4050e-01, -7.1246e-01,  ...,  2.4626e+00,\n",
       "           -1.8039e+00, -1.4068e+00]],\n",
       "\n",
       "         [[-2.9473e-01, -1.9238e+00,  7.5591e-02,  ..., -7.7601e-02,\n",
       "           -1.1944e-02,  7.4603e-01],\n",
       "          [ 9.4397e-02, -1.7699e-01, -2.6439e-01,  ...,  1.7119e+00,\n",
       "           -6.8571e-01,  1.5071e+00],\n",
       "          [ 7.3983e-02,  1.9254e+00, -1.1640e+00,  ...,  6.6325e-01,\n",
       "           -1.6861e+00,  1.1845e+00],\n",
       "          ...,\n",
       "          [ 1.4900e+00,  4.0860e+00, -2.3482e-01,  ...,  6.8161e-01,\n",
       "           -1.7958e-01,  1.0659e+00],\n",
       "          [ 1.9281e+00,  2.9092e+00, -7.0417e-01,  ...,  1.8595e+00,\n",
       "           -8.2575e-01,  7.9743e-01],\n",
       "          [ 4.4357e-01,  2.7224e+00, -1.8195e+00,  ...,  1.9567e-01,\n",
       "            5.3245e-01,  5.6104e-02]],\n",
       "\n",
       "         [[ 3.3432e-01,  1.0390e-01, -3.5090e-02,  ...,  6.1020e-01,\n",
       "            7.0413e-02,  1.8607e-01],\n",
       "          [ 4.9481e-01, -5.1091e-01, -5.8546e-01,  ...,  7.6237e-04,\n",
       "            8.5323e-01, -9.8859e-01],\n",
       "          [ 5.5508e-01, -5.6845e-01, -6.4282e-01,  ..., -2.9933e-01,\n",
       "            4.5320e-01, -1.1204e+00],\n",
       "          ...,\n",
       "          [-1.2041e+00, -1.3657e+00, -9.1095e-01,  ..., -1.0108e+00,\n",
       "           -1.9571e-01,  7.3557e-01],\n",
       "          [-2.4892e+00, -3.6849e-01, -9.8251e-01,  ...,  5.2286e-01,\n",
       "            9.2830e-01, -1.9107e-01],\n",
       "          [-4.9245e-01,  6.9687e-01,  7.1328e-01,  ..., -1.2302e+00,\n",
       "            1.3787e+00,  4.4085e-01]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[-5.8269e-02,  7.9075e-02, -2.1800e-03,  ..., -5.3603e-03,\n",
       "            1.9098e-02, -1.8329e-03],\n",
       "          [ 6.6435e-01,  2.9061e-01, -3.5737e-01,  ..., -5.3055e-01,\n",
       "           -3.5535e-01,  1.3024e-01],\n",
       "          [ 5.0552e-01,  6.5623e-03,  4.1853e-01,  ...,  2.1469e-01,\n",
       "            8.6897e-03, -1.1240e+00],\n",
       "          ...,\n",
       "          [-1.3074e-01, -4.7285e-01, -8.2047e-01,  ...,  7.2317e-01,\n",
       "           -2.2004e-01, -2.8986e-01],\n",
       "          [-5.8622e-01, -1.1543e+00, -7.5487e-01,  ..., -1.3910e-01,\n",
       "            4.9126e-01,  3.9337e-02],\n",
       "          [ 9.7936e-01,  3.2980e-01,  5.7194e-01,  ..., -2.8916e-02,\n",
       "           -6.7608e-01, -1.3264e-02]],\n",
       "\n",
       "         [[ 4.1871e-02, -3.4714e-02, -6.4294e-02,  ...,  4.4134e-02,\n",
       "           -5.9664e-02,  1.8934e-02],\n",
       "          [ 1.9969e-01, -7.5374e-01,  5.5932e-01,  ...,  1.2155e+00,\n",
       "            3.0278e-01, -2.3196e-01],\n",
       "          [ 4.4199e-01, -4.6059e-01, -5.4278e-01,  ...,  2.6089e-01,\n",
       "           -1.4515e-01, -2.2863e-01],\n",
       "          ...,\n",
       "          [ 4.6902e-01, -3.1878e-02, -1.2724e+00,  ..., -2.0524e-02,\n",
       "           -6.8541e-01, -1.5602e+00],\n",
       "          [-1.4198e-01,  1.8788e-01, -4.6792e-01,  ...,  4.2809e-01,\n",
       "           -7.2574e-01, -2.9631e-01],\n",
       "          [ 4.3750e-01,  8.6597e-02,  5.8160e-01,  ...,  1.0865e+00,\n",
       "           -4.9115e-01, -7.8770e-01]],\n",
       "\n",
       "         [[ 2.5277e-03, -7.7282e-02,  5.5962e-02,  ...,  3.9435e-03,\n",
       "            1.7322e-02, -1.8569e-03],\n",
       "          [ 1.1882e-01, -3.8645e-01,  3.4290e-02,  ...,  3.9168e-01,\n",
       "            3.2247e-01, -8.4531e-01],\n",
       "          [-6.2453e-01,  1.7796e-01,  2.9343e-01,  ...,  8.5606e-01,\n",
       "            1.5518e-01,  1.1123e+00],\n",
       "          ...,\n",
       "          [ 1.0543e+00, -8.5031e-01, -1.5077e-01,  ...,  2.8069e-01,\n",
       "           -1.1114e+00,  9.9831e-01],\n",
       "          [-9.8172e-01, -2.0846e-02,  2.0630e+00,  ..., -1.5524e+00,\n",
       "           -4.0262e-01,  4.6047e-01],\n",
       "          [ 2.2016e+00, -1.3753e-01,  8.5331e-01,  ...,  9.7334e-01,\n",
       "           -1.0878e+00, -1.9967e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.8943e-01,  8.5971e-02,  1.1202e-02,  ...,  2.2126e-02,\n",
       "            6.7317e-02, -1.2352e-01],\n",
       "          [-2.6760e-01,  5.7474e-02,  2.2625e-01,  ..., -2.1064e-01,\n",
       "            1.4632e-01, -5.2240e-03],\n",
       "          [ 4.3437e-01,  6.8842e-02,  3.4234e-01,  ...,  4.5501e-03,\n",
       "           -6.6397e-02,  9.5493e-03],\n",
       "          ...,\n",
       "          [ 2.6096e-02,  3.0867e-01, -5.4878e-01,  ...,  1.2157e+00,\n",
       "           -1.2446e-01, -2.1312e+00],\n",
       "          [ 6.4955e-01, -7.4723e-01, -1.9590e+00,  ..., -2.6645e-01,\n",
       "            3.6911e-01,  6.3399e-01],\n",
       "          [ 1.2305e+00,  1.0732e+00,  2.2029e+00,  ..., -7.1112e-02,\n",
       "            2.4877e+00,  1.2696e+00]],\n",
       "\n",
       "         [[-6.2090e-01, -4.4224e-02,  3.7323e-02,  ..., -9.8202e-03,\n",
       "            3.3941e-02,  1.5782e-02],\n",
       "          [-1.3818e+00, -7.0548e-01, -1.5672e-01,  ..., -2.5114e-02,\n",
       "            1.4072e-01, -4.3044e-03],\n",
       "          [-1.5816e+00,  8.3161e-02, -7.8729e-01,  ...,  1.6745e-01,\n",
       "            6.0404e-01,  8.2122e-01],\n",
       "          ...,\n",
       "          [-6.6020e-01,  4.8764e-01,  4.1053e-01,  ...,  1.7444e-01,\n",
       "           -2.2602e-01,  1.0631e+00],\n",
       "          [-5.2186e-01,  4.1676e-01, -6.9493e-01,  ..., -1.7358e-02,\n",
       "           -1.7737e-01, -5.7582e-01],\n",
       "          [-2.5040e+00, -3.0483e-01,  3.3099e-01,  ...,  2.3339e-01,\n",
       "            7.1812e-01,  3.5100e-01]],\n",
       "\n",
       "         [[ 3.7707e-03,  4.5164e-02,  1.3004e-02,  ...,  5.2309e-02,\n",
       "            4.1151e-02, -4.1251e-02],\n",
       "          [-7.5355e-01, -6.9623e-01, -6.1423e-01,  ..., -7.5540e-01,\n",
       "           -4.1026e-01, -1.3270e-01],\n",
       "          [-1.5002e-01, -1.3822e-01, -4.0623e-01,  ..., -4.1132e-01,\n",
       "           -7.8420e-01,  5.5188e-01],\n",
       "          ...,\n",
       "          [-5.7186e-01, -2.4123e-01, -1.3142e+00,  ..., -6.9304e-01,\n",
       "           -1.6025e+00, -3.9369e-01],\n",
       "          [ 8.9201e-01, -2.5896e-02, -7.6055e-01,  ...,  2.2399e-01,\n",
       "           -1.4211e+00,  2.8828e-01],\n",
       "          [ 1.1539e+00, -1.4886e+00, -2.0009e+00,  ..., -1.4166e+00,\n",
       "           -5.8074e-01,  7.2278e-01]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[ 1.2184e-03, -2.0833e+00,  1.1535e-01,  ..., -3.0240e-01,\n",
       "           -2.6283e-01,  1.1954e-01],\n",
       "          [-6.9394e-01,  3.0267e+00,  4.1918e-01,  ...,  1.0098e-01,\n",
       "           -6.2548e-01,  1.1934e+00],\n",
       "          [-4.3634e-01,  3.5824e+00,  1.1881e+00,  ..., -1.0684e+00,\n",
       "            2.5700e-02,  4.1898e-01],\n",
       "          ...,\n",
       "          [-5.5111e-01,  5.1450e+00,  6.4910e-01,  ..., -1.0215e+00,\n",
       "           -1.9327e+00, -1.7129e-01],\n",
       "          [-4.4773e-01,  4.9171e+00, -3.8925e-01,  ...,  1.2071e+00,\n",
       "           -8.5487e-01,  3.5959e-01],\n",
       "          [-6.1700e-01,  3.1145e+00, -4.0252e-01,  ...,  1.5893e+00,\n",
       "           -1.4454e+00,  3.7237e-01]],\n",
       "\n",
       "         [[-7.7905e-01,  1.6446e-01,  2.5265e-01,  ..., -3.5163e-01,\n",
       "            9.6341e-01,  1.0939e+00],\n",
       "          [ 7.4747e-01, -3.3873e-02,  1.4712e+00,  ...,  4.5877e-01,\n",
       "            1.0041e+00,  6.4554e-01],\n",
       "          [ 1.0080e+00,  6.1670e-01,  9.7308e-01,  ...,  5.3741e-01,\n",
       "            1.2096e+00, -5.6713e-01],\n",
       "          ...,\n",
       "          [-6.8660e-02,  1.2100e+00, -9.5643e-01,  ...,  1.0397e+00,\n",
       "            4.3187e-01, -3.3688e-01],\n",
       "          [-1.3949e+00,  2.2560e-01, -5.2797e-01,  ...,  1.5744e+00,\n",
       "            1.8514e+00, -6.4552e-01],\n",
       "          [-4.0797e-01, -2.7150e-01, -7.2799e-01,  ...,  2.7775e+00,\n",
       "            2.7610e+00, -7.4257e-01]],\n",
       "\n",
       "         [[-7.6268e-01,  4.4276e-01, -9.5781e-02,  ...,  4.8300e-01,\n",
       "           -2.3391e-01,  9.8322e-01],\n",
       "          [ 1.5705e-01, -7.6900e-01,  4.9016e-01,  ...,  1.5090e-01,\n",
       "           -1.4515e-01, -4.4801e-01],\n",
       "          [ 8.7244e-01,  7.1832e-03,  1.2565e-01,  ...,  7.3611e-01,\n",
       "            6.6373e-01, -7.3180e-01],\n",
       "          ...,\n",
       "          [ 5.0680e-01, -3.0503e-01,  5.0514e-01,  ...,  9.9416e-02,\n",
       "            5.2691e-01,  4.0007e-01],\n",
       "          [ 1.0713e+00, -1.1371e-01,  1.0815e+00,  ...,  7.9386e-01,\n",
       "            6.9764e-01, -3.6888e-01],\n",
       "          [ 1.5364e+00, -1.6921e-01, -1.9529e+00,  ...,  1.4523e+00,\n",
       "            8.6944e-01,  4.6636e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.5718e-01, -1.8602e-01,  7.3205e-02,  ...,  8.9509e-02,\n",
       "            1.5443e+00, -2.5225e+00],\n",
       "          [ 7.7794e-02,  3.5895e-01,  9.8278e-01,  ...,  5.5001e-01,\n",
       "           -4.2420e+00,  4.6809e+00],\n",
       "          [ 4.2089e-02,  1.3513e-01,  8.4750e-01,  ..., -1.1967e-01,\n",
       "           -3.9307e+00,  5.1969e+00],\n",
       "          ...,\n",
       "          [-1.0382e-01,  3.5065e-01,  6.0993e-02,  ...,  2.4028e-01,\n",
       "           -3.8434e+00,  5.2682e+00],\n",
       "          [-8.2728e-01, -6.3383e-02, -2.6255e-01,  ..., -8.3399e-02,\n",
       "           -3.0744e+00,  3.7387e+00],\n",
       "          [-2.7687e-01,  8.5504e-01,  1.3464e+00,  ..., -1.1811e+00,\n",
       "           -4.8298e+00,  4.6020e+00]],\n",
       "\n",
       "         [[-5.0916e-03,  2.9697e-01,  1.8534e-01,  ..., -7.7122e-02,\n",
       "            9.4513e-02, -1.0038e-01],\n",
       "          [ 1.0721e-01, -2.1103e-01,  5.4218e-01,  ...,  2.8986e-01,\n",
       "           -1.0361e+00,  1.9597e-01],\n",
       "          [-6.1149e-01, -1.1187e+00,  8.9654e-01,  ..., -1.3778e-01,\n",
       "           -8.6350e-01,  7.0713e-01],\n",
       "          ...,\n",
       "          [-5.4061e-01, -7.0633e-01,  8.4810e-02,  ...,  6.2804e-01,\n",
       "           -1.4455e+00,  1.0842e+00],\n",
       "          [-2.5896e-01,  1.3560e-01,  8.0471e-01,  ...,  5.9688e-01,\n",
       "           -1.9739e+00,  6.8923e-02],\n",
       "          [-5.0205e-01,  5.0282e-02,  1.2287e+00,  ...,  1.1203e+00,\n",
       "           -1.0592e+00, -2.8834e-01]],\n",
       "\n",
       "         [[ 3.6016e-01,  1.0746e-01,  4.9256e-01,  ...,  4.1980e-01,\n",
       "            5.5004e-01, -2.9025e-01],\n",
       "          [ 2.2500e-01,  1.0245e-01, -5.3045e-02,  ..., -2.1573e+00,\n",
       "           -4.5847e+00,  1.4257e-01],\n",
       "          [ 4.2621e-01, -4.9956e-01, -1.4888e-01,  ..., -1.9308e+00,\n",
       "           -4.3484e+00, -8.1245e-01],\n",
       "          ...,\n",
       "          [ 2.6362e-01,  6.4181e-01, -1.9238e+00,  ..., -1.1488e+00,\n",
       "           -3.8448e+00,  8.2864e-01],\n",
       "          [ 5.7864e-01,  2.8646e-01, -7.5498e-01,  ..., -9.5551e-01,\n",
       "           -2.8840e+00, -4.6161e-01],\n",
       "          [ 1.2465e+00, -7.6305e-01, -1.6178e+00,  ..., -7.7838e-01,\n",
       "           -3.0351e+00, -7.8372e-01]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[ 7.4834e-02,  2.7919e-03,  8.8163e-03,  ...,  7.9741e-02,\n",
       "           -6.6632e-02, -3.0930e-03],\n",
       "          [-2.6620e-01,  9.6410e-02,  2.5688e-01,  ..., -4.8931e-01,\n",
       "           -1.1986e-01,  3.8747e-01],\n",
       "          [ 5.2016e-01, -4.4896e-01, -5.2432e-01,  ..., -3.2095e-02,\n",
       "            5.4696e-02, -5.9564e-02],\n",
       "          ...,\n",
       "          [ 9.1947e-01, -5.9997e-01,  3.8508e-01,  ...,  7.2078e-01,\n",
       "            5.6388e-01,  1.3634e+00],\n",
       "          [-8.2009e-01,  1.4632e-01,  1.4504e+00,  ..., -1.0529e+00,\n",
       "           -6.9924e-01,  4.9574e-03],\n",
       "          [ 1.3816e+00,  7.6788e-01,  4.4746e-01,  ..., -5.7217e-01,\n",
       "           -1.6960e+00,  1.1857e+00]],\n",
       "\n",
       "         [[ 3.5484e-02,  4.7282e-02,  3.2800e-02,  ...,  1.9289e-03,\n",
       "           -2.0579e-02, -7.7747e-02],\n",
       "          [ 4.1006e-01,  3.1853e-01,  6.9131e-01,  ...,  5.2548e-01,\n",
       "           -1.7748e-01, -6.8511e-01],\n",
       "          [-6.8207e-01,  3.9662e-01,  7.9579e-01,  ...,  1.6144e+00,\n",
       "           -2.0265e-01,  7.0344e-01],\n",
       "          ...,\n",
       "          [ 1.0498e+00,  2.9903e-01, -6.9823e-01,  ...,  1.9747e-01,\n",
       "            7.8318e-01, -2.0122e-01],\n",
       "          [ 1.1674e+00,  5.1814e-01,  4.6844e-01,  ...,  1.1537e+00,\n",
       "            1.3417e+00, -6.3153e-02],\n",
       "          [ 2.4332e+00,  2.0015e+00,  2.1242e-01,  ...,  1.6590e+00,\n",
       "           -1.2233e+00,  9.6925e-01]],\n",
       "\n",
       "         [[ 4.0498e-02, -5.1324e-02, -8.8137e-03,  ...,  1.4119e-02,\n",
       "           -3.3248e-02, -8.4295e-02],\n",
       "          [ 3.8749e-02, -3.8769e-01, -8.0873e-02,  ...,  5.8763e-01,\n",
       "           -1.6718e-01, -1.5292e-01],\n",
       "          [-2.9367e-01, -3.5884e-01, -9.3030e-02,  ...,  7.7348e-01,\n",
       "            1.6459e-01, -1.9514e-01],\n",
       "          ...,\n",
       "          [ 1.2262e-01,  6.0338e-01,  2.4163e-01,  ...,  3.0874e-01,\n",
       "            2.1477e-01, -3.6240e-01],\n",
       "          [ 2.9407e-01, -4.1585e-01,  1.1182e-01,  ..., -5.7365e-01,\n",
       "           -5.6255e-01, -4.1960e-01],\n",
       "          [-5.4308e-01, -1.2697e-01, -3.8661e-01,  ...,  1.7194e+00,\n",
       "           -7.9439e-01,  5.4347e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-8.5139e-02, -2.5277e-02,  3.4757e-02,  ..., -1.1381e-01,\n",
       "           -5.7558e-03,  2.5408e-02],\n",
       "          [ 8.8222e-01, -2.4795e-01,  5.1234e-01,  ..., -2.7057e-01,\n",
       "           -1.6965e-01, -2.4758e-01],\n",
       "          [ 1.8280e-01,  4.3207e-01,  6.7528e-01,  ...,  2.3622e-01,\n",
       "           -3.4924e-01,  1.3818e-01],\n",
       "          ...,\n",
       "          [-4.1916e-01, -7.4961e-01,  5.0030e-01,  ..., -7.8956e-01,\n",
       "            8.8995e-01, -5.0807e-01],\n",
       "          [-2.3750e-01, -9.5395e-01, -1.4818e+00,  ...,  1.1277e+00,\n",
       "            2.4521e-01, -1.4829e+00],\n",
       "          [ 6.1140e-01,  6.5996e-01,  5.7557e-01,  ...,  3.9986e-01,\n",
       "           -1.3476e+00, -8.2806e-02]],\n",
       "\n",
       "         [[ 1.1130e-01,  4.0168e-02,  1.2024e-01,  ...,  3.3958e-02,\n",
       "            3.0896e-02, -9.6359e-02],\n",
       "          [-2.6191e-01,  2.1796e-01,  4.3853e-01,  ..., -4.8718e-01,\n",
       "            2.8565e-01, -1.4433e-02],\n",
       "          [-6.1816e-01, -4.3221e-01, -1.1778e-01,  ..., -2.4048e-01,\n",
       "            3.0270e-01,  5.5311e-01],\n",
       "          ...,\n",
       "          [-5.9933e-01, -3.7806e-01,  9.6016e-01,  ..., -1.7435e+00,\n",
       "            1.4025e+00, -2.7294e-01],\n",
       "          [-8.1845e-01,  2.6822e-01,  5.2452e-01,  ..., -6.0304e-01,\n",
       "           -5.0351e-01, -1.6386e+00],\n",
       "          [-1.4450e+00, -1.4911e+00, -4.3253e-01,  ..., -1.3040e-01,\n",
       "           -1.5553e+00, -4.3523e-01]],\n",
       "\n",
       "         [[ 6.6786e-02, -3.2479e-02, -9.0227e-02,  ...,  2.5162e-02,\n",
       "            3.0339e-02,  4.8937e-02],\n",
       "          [-2.9442e-01,  1.1041e+00, -2.3202e-02,  ...,  3.6114e-01,\n",
       "            2.8867e-02,  4.1353e-01],\n",
       "          [-7.8311e-02,  2.6655e-01, -7.8538e-02,  ...,  3.5223e-01,\n",
       "           -6.1101e-01,  7.7168e-01],\n",
       "          ...,\n",
       "          [ 2.4466e-02,  8.2577e-01, -5.0679e-02,  ...,  9.9351e-01,\n",
       "            2.7788e-01,  7.3800e-01],\n",
       "          [-3.3863e-01,  1.4988e+00,  5.5973e-01,  ...,  1.3324e+00,\n",
       "            2.4721e-01,  2.2142e-01],\n",
       "          [-2.1820e+00,  2.1276e+00, -8.8676e-02,  ...,  2.0532e+00,\n",
       "            2.4773e-01, -1.0361e+00]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[-2.4552e-02, -2.5609e-01, -6.0953e-01,  ...,  1.2874e-01,\n",
       "            2.5091e-01,  2.8309e-01],\n",
       "          [ 4.3556e-04, -6.5144e-01, -2.2126e+00,  ..., -9.9235e-01,\n",
       "            1.0124e-01,  1.4989e+00],\n",
       "          [ 2.1278e-01, -8.8329e-01, -1.7187e+00,  ..., -1.1004e+00,\n",
       "            5.3343e-01,  2.3500e-01],\n",
       "          ...,\n",
       "          [ 3.1181e-01, -2.3863e-01, -7.5790e-01,  ..., -6.9967e-01,\n",
       "            1.3620e+00, -2.1052e-01],\n",
       "          [ 1.9872e+00, -8.1031e-01, -7.2225e-01,  ...,  1.0388e-01,\n",
       "            7.8025e-01, -1.3313e+00],\n",
       "          [-1.2261e-01, -3.7138e-01, -2.6080e+00,  ..., -7.2437e-01,\n",
       "            2.7752e-01,  2.3769e-01]],\n",
       "\n",
       "         [[-8.5720e-02,  6.6886e-02,  2.1438e-02,  ..., -5.0474e-02,\n",
       "           -9.1062e-01, -4.9872e-02],\n",
       "          [ 1.6242e-01,  1.0454e-01, -1.6625e+00,  ...,  1.1432e+00,\n",
       "           -2.8806e-01,  6.5892e-01],\n",
       "          [-1.1909e-01, -7.1676e-01, -1.2695e+00,  ...,  1.0190e+00,\n",
       "           -8.9100e-01,  8.9781e-01],\n",
       "          ...,\n",
       "          [ 2.4821e-01,  8.1516e-01, -9.3333e-01,  ..., -5.7180e-01,\n",
       "           -1.3130e+00,  1.8800e-01],\n",
       "          [-1.6164e-02,  1.4203e+00, -1.5770e+00,  ..., -9.7311e-01,\n",
       "           -1.0645e+00,  1.8665e-01],\n",
       "          [ 1.0775e-01,  3.8071e-01, -1.1953e+00,  ..., -7.4595e-02,\n",
       "            2.6989e+00,  9.3474e-01]],\n",
       "\n",
       "         [[-1.0835e+00, -2.1533e-01,  5.7668e-01,  ..., -5.8848e-01,\n",
       "            3.1888e-01, -1.5244e-01],\n",
       "          [ 4.8932e-01,  2.0648e+00,  2.8612e-01,  ..., -1.7786e-01,\n",
       "           -4.7479e-01,  2.1718e+00],\n",
       "          [ 6.3288e-01,  1.5237e+00,  2.0409e-01,  ...,  5.0559e-02,\n",
       "           -1.7812e-01,  1.2295e+00],\n",
       "          ...,\n",
       "          [ 1.8686e+00,  1.2863e+00, -2.9339e-01,  ...,  6.9843e-01,\n",
       "           -9.1180e-01,  1.3372e+00],\n",
       "          [ 1.6602e+00,  2.1034e+00, -6.7328e-01,  ...,  5.1011e-01,\n",
       "            1.4908e-01,  6.7414e-01],\n",
       "          [ 1.1078e+00,  6.2377e-01, -4.1099e-01,  ..., -6.5872e-01,\n",
       "           -2.3511e+00, -1.6125e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 8.7414e-01, -8.3196e-01, -5.5562e-01,  ..., -7.0355e-01,\n",
       "           -4.0933e-01,  3.7644e-01],\n",
       "          [ 6.8675e-01, -9.8233e-01, -9.2800e-01,  ..., -7.1730e-01,\n",
       "           -1.4953e+00, -1.3230e+00],\n",
       "          [ 9.1623e-01, -1.9751e+00, -1.7616e+00,  ..., -8.6197e-03,\n",
       "           -9.7587e-01, -2.3569e+00],\n",
       "          ...,\n",
       "          [ 1.9210e-02, -1.2795e+00, -1.3157e-02,  ..., -5.7216e-01,\n",
       "            1.4039e+00, -8.0574e-01],\n",
       "          [ 6.7900e-01,  6.4385e-01, -9.5754e-01,  ..., -1.2473e+00,\n",
       "            4.1568e-02, -1.1206e+00],\n",
       "          [ 9.6710e-01, -6.6789e-01, -7.9581e-01,  ...,  1.7412e+00,\n",
       "            6.7048e-01, -5.2389e-01]],\n",
       "\n",
       "         [[-7.0835e-01,  2.4083e+00,  2.7163e-01,  ...,  2.6945e-01,\n",
       "            1.8442e+00, -3.9787e-01],\n",
       "          [ 1.5706e-01, -3.4948e+00,  4.9121e-01,  ...,  4.1223e-01,\n",
       "           -5.1733e+00,  1.5911e-01],\n",
       "          [ 9.3584e-01, -3.6962e+00,  4.1559e-01,  ...,  2.4091e-01,\n",
       "           -5.3373e+00,  1.0048e-01],\n",
       "          ...,\n",
       "          [ 1.2738e+00, -4.0688e+00,  9.8577e-01,  ..., -7.6206e-01,\n",
       "           -3.3955e+00,  3.8617e-01],\n",
       "          [-4.7824e-01, -4.7798e+00,  8.8071e-01,  ..., -4.9367e-01,\n",
       "           -2.5335e+00, -1.5804e-01],\n",
       "          [ 1.2832e+00, -4.0214e+00,  3.3191e-01,  ...,  1.3804e+00,\n",
       "           -3.3081e+00,  2.3362e-01]],\n",
       "\n",
       "         [[-1.8354e+00, -2.6941e-01, -1.0993e+00,  ..., -4.0523e-01,\n",
       "           -1.8190e-03,  2.9553e-01],\n",
       "          [-2.0828e-01,  3.0981e-01,  9.0816e-01,  ...,  2.8955e-01,\n",
       "            4.7910e-01,  7.8999e-01],\n",
       "          [ 1.4088e+00,  6.2306e-01,  7.9610e-01,  ...,  2.3588e-01,\n",
       "            6.8631e-01,  1.3676e+00],\n",
       "          ...,\n",
       "          [ 1.7083e+00, -1.5953e-01,  4.0742e-01,  ..., -6.2828e-01,\n",
       "            9.3649e-01, -1.2348e-01],\n",
       "          [ 2.3891e+00,  3.4919e-01,  1.4405e+00,  ..., -7.7895e-01,\n",
       "            6.9840e-01, -1.3609e+00],\n",
       "          [ 1.4040e+00,  2.9001e-01,  1.0972e+00,  ..., -7.6860e-01,\n",
       "           -1.0373e+00,  8.7131e-02]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[-0.0190, -0.0765, -0.0424,  ...,  0.1279, -0.0636,  0.0475],\n",
       "          [-0.1790, -0.0087, -0.3183,  ..., -0.0344, -0.2515, -0.0438],\n",
       "          [ 0.0104,  0.1164, -0.1390,  ...,  0.1871, -0.1671, -0.2085],\n",
       "          ...,\n",
       "          [ 0.8608,  0.7115,  0.7698,  ...,  0.4441, -0.0627,  0.7643],\n",
       "          [ 0.5301,  0.8404,  1.5253,  ...,  0.6434, -0.2175,  1.2828],\n",
       "          [ 0.8813,  0.7015,  0.6055,  ...,  0.9393, -0.8441, -0.5704]],\n",
       "\n",
       "         [[ 0.0202,  0.0457, -0.0816,  ...,  0.0678, -0.0060,  0.0267],\n",
       "          [-0.0636,  0.1559, -0.7707,  ...,  0.2351, -0.0729, -0.2515],\n",
       "          [ 0.1258,  0.1419, -0.3094,  ..., -0.1364, -0.2869, -0.3394],\n",
       "          ...,\n",
       "          [ 1.2104,  0.1229,  0.5430,  ..., -0.6587, -0.1250, -0.1446],\n",
       "          [ 0.6810, -1.0165,  0.8062,  ..., -2.5428, -0.7844,  0.5967],\n",
       "          [-0.5965, -1.3648, -2.4881,  ...,  1.1753, -0.9771,  1.5127]],\n",
       "\n",
       "         [[ 0.0768,  0.0236, -0.0593,  ..., -0.0089, -0.1168,  0.0202],\n",
       "          [ 0.1738, -0.3307, -0.0198,  ...,  0.1301, -0.4070,  0.0238],\n",
       "          [-0.2300,  0.0876, -0.2756,  ..., -0.0723, -0.1953, -0.0949],\n",
       "          ...,\n",
       "          [-0.4216, -0.1682,  0.5182,  ..., -0.0506, -0.5898,  0.3809],\n",
       "          [ 0.6983, -0.1807, -1.4435,  ...,  0.8407, -0.2086, -0.7136],\n",
       "          [ 0.7082,  1.3064, -0.0277,  ..., -2.2144,  1.0605, -1.3338]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0360,  0.0060, -0.0194,  ..., -0.0423, -0.0291,  0.0554],\n",
       "          [-0.1718, -0.4975,  0.3018,  ...,  0.0817, -0.1193,  0.0877],\n",
       "          [-0.6367,  0.5010,  0.8512,  ...,  0.7556,  0.1010,  0.6587],\n",
       "          ...,\n",
       "          [ 0.4749,  0.0965,  0.5546,  ..., -0.6786,  0.3054,  0.0695],\n",
       "          [-0.0741, -0.2385, -1.2009,  ..., -0.8113,  0.5280, -0.6684],\n",
       "          [-0.5731,  0.3547,  0.7614,  ..., -1.5478,  0.6221,  0.1204]],\n",
       "\n",
       "         [[-0.0585, -0.0177,  0.0134,  ...,  0.0672, -0.0722, -0.0751],\n",
       "          [-0.7060, -0.1354,  0.5487,  ..., -0.0961,  0.5358,  0.8762],\n",
       "          [-0.0720,  0.0891,  0.6421,  ..., -0.3245, -0.1857,  0.7516],\n",
       "          ...,\n",
       "          [-0.8501,  0.1307, -0.5797,  ...,  0.0457,  0.8882, -0.1287],\n",
       "          [-0.5179, -0.5108, -0.1249,  ..., -0.5509,  0.9103,  0.7736],\n",
       "          [-0.3450, -0.9507,  0.3352,  ...,  0.6453,  0.6853,  0.6491]],\n",
       "\n",
       "         [[-0.0179, -0.0472, -0.0579,  ..., -0.0164,  0.0320,  0.0696],\n",
       "          [ 0.0058, -0.2948, -0.3967,  ..., -0.1686,  0.6218, -0.1383],\n",
       "          [ 0.1773, -0.1753, -0.7094,  ...,  0.0066, -0.6143, -0.8782],\n",
       "          ...,\n",
       "          [ 0.2534,  0.0761,  1.3683,  ..., -0.4279, -0.0707, -0.7469],\n",
       "          [-0.8193,  0.0640,  0.2136,  ...,  0.4242,  0.2451,  1.7876],\n",
       "          [-0.7359, -1.2512, -2.6274,  ...,  0.7690, -0.1927, -0.1254]]]],\n",
       "       device='cuda:0', grad_fn=<PermuteBackward0>)), (tensor([[[[-4.2833e-01,  4.0119e-01, -7.1688e-01,  ..., -8.9434e-01,\n",
       "           -1.0990e+00,  2.5194e-01],\n",
       "          [ 1.1638e-01,  6.1153e-01, -8.7752e-01,  ...,  2.1436e+00,\n",
       "            1.2091e-01, -4.8563e-01],\n",
       "          [ 2.6422e-01,  6.8506e-01,  3.6102e-01,  ...,  2.6777e+00,\n",
       "            1.2344e+00, -1.9305e+00],\n",
       "          ...,\n",
       "          [ 8.8586e-01, -6.7127e-02,  7.5867e-01,  ...,  2.0382e+00,\n",
       "            1.9679e+00, -1.0005e+00],\n",
       "          [ 9.2929e-02,  3.0962e-02, -1.7749e-01,  ...,  1.3384e+00,\n",
       "           -5.5362e-01,  2.0228e-01],\n",
       "          [ 1.7251e+00, -4.5761e-01, -6.7784e-01,  ...,  1.7714e-01,\n",
       "            7.1203e-01,  8.1319e-01]],\n",
       "\n",
       "         [[ 5.6335e-01, -1.9005e+00,  5.1516e-02,  ...,  1.8932e-01,\n",
       "           -2.2772e+00, -4.4409e-01],\n",
       "          [ 6.8211e-01,  5.0421e-02,  1.7744e-01,  ...,  1.3284e+00,\n",
       "           -8.3552e-01, -1.3756e+00],\n",
       "          [ 1.7001e+00,  7.4201e-01, -3.0304e-01,  ...,  1.4023e+00,\n",
       "           -1.6894e-01, -4.0719e-01],\n",
       "          ...,\n",
       "          [ 1.0599e+00,  9.7945e-01,  4.8775e-02,  ..., -1.3906e-01,\n",
       "            2.9569e+00,  5.5176e-01],\n",
       "          [ 7.0662e-01,  1.3404e+00,  8.4498e-03,  ...,  1.3618e+00,\n",
       "            1.5988e+00, -1.3686e+00],\n",
       "          [ 1.2476e+00,  1.6749e+00,  4.7190e-03,  ..., -2.2534e+00,\n",
       "            2.3903e+00, -6.0317e-01]],\n",
       "\n",
       "         [[ 7.5612e-01,  3.8158e-01, -8.4937e-02,  ..., -8.7823e-01,\n",
       "           -1.2418e+00, -3.6199e-01],\n",
       "          [ 1.5409e-01, -9.1625e-02,  3.2694e-03,  ..., -9.9949e-01,\n",
       "           -1.8939e+00, -4.6256e-01],\n",
       "          [ 1.8810e-01, -3.5437e-01, -3.9867e-01,  ...,  6.8521e-02,\n",
       "           -1.3506e+00, -1.1289e+00],\n",
       "          ...,\n",
       "          [-4.2985e-01, -7.1551e-02, -9.1017e-01,  ...,  6.3849e-01,\n",
       "            5.2949e-01, -7.9018e-01],\n",
       "          [-8.4678e-02, -2.7761e-01, -6.8256e-02,  ...,  1.8074e+00,\n",
       "           -3.1844e-01,  1.4833e-02],\n",
       "          [ 3.7730e-02, -1.9163e+00,  1.2448e+00,  ...,  1.2232e-01,\n",
       "            3.5409e-01,  4.9997e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.9584e-01, -3.3335e-01,  4.9308e-01,  ..., -5.7565e-01,\n",
       "            9.5598e-01,  2.0867e-01],\n",
       "          [-7.6755e-01,  8.3844e-01, -1.4696e+00,  ..., -3.6185e+00,\n",
       "            7.7263e-01,  8.5823e-01],\n",
       "          [-9.4201e-01,  9.2409e-01, -1.8947e+00,  ..., -3.9799e+00,\n",
       "            5.2653e-02,  2.3416e-01],\n",
       "          ...,\n",
       "          [-2.5086e+00,  2.0617e+00, -4.2726e-01,  ..., -1.1746e+00,\n",
       "            9.2659e-01,  5.7983e-01],\n",
       "          [-3.7109e+00,  1.0691e+00,  2.5062e-01,  ..., -1.2587e+00,\n",
       "           -2.9028e+00,  1.8281e+00],\n",
       "          [-1.0435e+00, -2.7766e-01, -9.8826e-01,  ..., -4.3700e+00,\n",
       "           -1.3780e+00, -6.3088e-01]],\n",
       "\n",
       "         [[ 1.0397e-02,  3.7879e-01,  3.1131e-01,  ...,  4.2854e-01,\n",
       "            3.7295e-02,  6.1596e-01],\n",
       "          [ 5.7676e-01,  1.2840e+00,  1.0258e+00,  ...,  5.0608e-01,\n",
       "            7.9394e-01,  1.0510e+00],\n",
       "          [-7.6680e-02,  2.1751e+00,  5.1605e-01,  ..., -9.7608e-01,\n",
       "            2.2116e-01,  8.6639e-01],\n",
       "          ...,\n",
       "          [ 6.8581e-01,  9.5732e-01, -1.4903e+00,  ..., -1.4521e+00,\n",
       "           -8.9020e-01, -1.6430e+00],\n",
       "          [ 2.2314e-01, -1.4309e+00, -8.0343e-01,  ...,  4.3502e-01,\n",
       "            4.5748e-02, -1.2316e+00],\n",
       "          [-1.5136e-01, -1.9652e+00, -1.5761e-01,  ...,  9.4936e-01,\n",
       "            1.3235e+00,  4.6285e-01]],\n",
       "\n",
       "         [[-5.1308e-01,  1.4424e-01, -1.3822e+00,  ..., -3.1163e-01,\n",
       "            2.3875e-01, -1.3048e+00],\n",
       "          [-4.4983e-01, -6.6438e-01,  2.1105e-01,  ...,  1.0483e+00,\n",
       "            9.5588e-01, -1.2768e+00],\n",
       "          [-9.4926e-01,  4.8960e-02, -1.5164e+00,  ...,  6.2954e-01,\n",
       "            1.4325e+00, -5.4650e-01],\n",
       "          ...,\n",
       "          [ 8.2360e-01,  2.3695e+00,  2.0068e+00,  ...,  1.2966e-01,\n",
       "           -2.7034e-01,  3.4984e-01],\n",
       "          [ 9.8558e-01,  8.3916e-02,  5.3647e-01,  ...,  1.2984e+00,\n",
       "           -1.4363e+00,  2.7236e+00],\n",
       "          [-2.3753e+00, -1.7018e+00,  4.5031e-01,  ...,  2.6782e+00,\n",
       "           -8.6351e-01, -5.1981e-01]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[-3.7526e-02,  2.7923e-02, -5.2675e-02,  ..., -2.2516e-03,\n",
       "           -5.4810e-02, -2.7626e-02],\n",
       "          [ 2.3330e-01, -1.4482e-01,  7.3012e-01,  ..., -2.5168e-01,\n",
       "           -3.6763e-01,  5.2084e-01],\n",
       "          [-4.3621e-01, -3.9911e-01,  5.2653e-03,  ...,  2.0098e-01,\n",
       "            4.8707e-01, -3.4185e-01],\n",
       "          ...,\n",
       "          [ 7.0236e-01,  2.2150e-01, -2.9017e-01,  ..., -2.0959e-01,\n",
       "            3.5382e-02, -8.9983e-02],\n",
       "          [ 1.0080e+00,  3.6086e-02, -2.4421e+00,  ...,  2.0403e-01,\n",
       "           -9.2016e-01, -9.2373e-01],\n",
       "          [ 7.7469e-01,  1.0134e+00, -1.9460e-01,  ..., -1.3042e-01,\n",
       "            1.0256e+00, -3.2485e-01]],\n",
       "\n",
       "         [[-6.9995e-03,  1.6803e-02,  4.6388e-02,  ..., -1.9624e-02,\n",
       "           -8.5326e-03, -3.6014e-02],\n",
       "          [-2.1148e-01,  3.8860e-01,  1.9330e-01,  ...,  2.2063e-01,\n",
       "           -2.8770e-01,  9.5667e-02],\n",
       "          [-1.5418e-01,  4.2292e-01,  3.5209e-01,  ...,  3.4114e-01,\n",
       "            9.0835e-03,  3.3256e-01],\n",
       "          ...,\n",
       "          [ 2.5614e-01,  1.0447e+00,  1.0071e-01,  ..., -1.3430e+00,\n",
       "            2.5056e-01, -6.6234e-01],\n",
       "          [ 5.4001e-02, -1.3128e+00,  9.6416e-01,  ..., -1.0019e+00,\n",
       "           -1.8363e-01, -7.6541e-01],\n",
       "          [ 1.5871e+00, -4.3698e+00,  1.4128e+00,  ..., -2.4644e+00,\n",
       "           -1.0057e+00,  1.6049e+00]],\n",
       "\n",
       "         [[ 4.8382e-02, -4.5176e-03, -9.5268e-02,  ..., -2.9838e-02,\n",
       "            5.3437e-02,  1.0858e-02],\n",
       "          [ 3.3203e-01,  2.0448e-01,  2.9551e-01,  ..., -4.5296e-02,\n",
       "            4.2294e-01, -2.5559e-01],\n",
       "          [-2.1841e-01, -2.0459e-02,  2.0897e-01,  ...,  2.2263e-01,\n",
       "           -7.7524e-01,  6.2625e-02],\n",
       "          ...,\n",
       "          [-4.9797e-01, -2.3504e-01,  2.8933e-01,  ...,  3.1015e-01,\n",
       "           -1.0535e-01, -2.0000e-01],\n",
       "          [-1.3433e+00,  2.5012e-01, -6.0040e-01,  ..., -1.3830e-01,\n",
       "            5.3113e-01, -6.0073e-02],\n",
       "          [ 1.7485e-01, -8.0855e-01,  8.6254e-01,  ..., -9.7438e-01,\n",
       "            1.0562e-01, -5.0944e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.1053e-01, -2.7636e-02,  1.4724e-02,  ..., -1.0697e-01,\n",
       "           -7.7417e-02, -1.1279e-02],\n",
       "          [-1.0301e-01,  7.0053e-02,  3.0764e-01,  ..., -7.2358e-01,\n",
       "           -1.1502e+00,  1.6529e-01],\n",
       "          [ 3.5984e-01,  3.8626e-02,  7.4935e-01,  ...,  9.7463e-02,\n",
       "           -5.9644e-01,  1.4069e-01],\n",
       "          ...,\n",
       "          [-4.9541e-01,  2.3009e-01, -6.6513e-01,  ...,  3.9666e-01,\n",
       "            7.3364e-01,  2.7093e-01],\n",
       "          [ 5.6509e-01, -5.2380e-01, -8.8856e-01,  ..., -6.1650e-01,\n",
       "           -6.3938e-01,  2.5930e-01],\n",
       "          [-4.9213e-01,  4.8602e-01, -6.9618e-02,  ..., -7.3391e-01,\n",
       "           -4.1955e-01, -3.7190e-01]],\n",
       "\n",
       "         [[ 9.6703e-02, -6.4121e-02,  1.1108e-01,  ...,  5.8712e-02,\n",
       "           -1.7044e-02,  6.2150e-02],\n",
       "          [ 2.2069e-01,  5.3800e-01,  1.2339e+00,  ...,  2.1216e-01,\n",
       "            6.0625e-01,  1.1651e-01],\n",
       "          [-4.2379e-01,  4.8064e-02,  9.6946e-01,  ...,  3.9437e-01,\n",
       "            1.3823e+00, -1.0728e+00],\n",
       "          ...,\n",
       "          [ 2.1293e-01,  9.2398e-01,  6.8560e-01,  ..., -9.3987e-02,\n",
       "            3.6338e-01, -6.2850e-01],\n",
       "          [ 2.0134e-01, -6.1853e-01, -5.1163e-01,  ..., -3.7742e-01,\n",
       "            9.4697e-01,  1.3415e+00],\n",
       "          [ 1.2218e+00,  2.7610e-01,  3.0190e+00,  ...,  2.6295e+00,\n",
       "            3.9637e+00,  1.7359e+00]],\n",
       "\n",
       "         [[-1.0726e-01,  4.1451e-02, -6.5714e-02,  ..., -1.0736e-01,\n",
       "            2.5596e-01,  6.3685e-02],\n",
       "          [-5.0980e-01,  2.5806e-01, -2.7699e-01,  ..., -2.9918e-01,\n",
       "            2.0003e-01,  3.9059e-01],\n",
       "          [-2.3359e-01,  5.0709e-01, -4.8002e-01,  ...,  2.4822e-02,\n",
       "            5.4253e-01, -4.8311e-01],\n",
       "          ...,\n",
       "          [ 4.9087e-01,  2.8361e-01,  3.0637e-01,  ...,  1.5158e-01,\n",
       "           -1.1434e+00,  1.5296e-01],\n",
       "          [ 6.7631e-01,  1.8988e-01, -6.5552e-01,  ..., -1.7095e-01,\n",
       "           -2.5397e-01,  6.2007e-01],\n",
       "          [-2.0218e-01,  6.0629e-01, -3.6095e-01,  ..., -1.8175e-01,\n",
       "           -1.4935e+00,  6.3679e-01]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[-1.5048, -0.3655, -0.3176,  ...,  0.2945,  0.4740, -0.4216],\n",
       "          [ 1.7445, -0.9015, -0.9502,  ...,  0.6803, -0.7974,  0.0727],\n",
       "          [ 0.8478, -1.4312, -0.2897,  ...,  1.2900, -0.8248, -0.0814],\n",
       "          ...,\n",
       "          [ 0.9461, -0.1709, -0.2567,  ...,  0.5853,  0.4585,  0.3012],\n",
       "          [ 1.9240,  0.3753, -1.1677,  ...,  0.6261, -1.0396,  0.3416],\n",
       "          [ 1.6134, -0.0935,  0.5670,  ..., -0.8710, -2.0859, -0.7878]],\n",
       "\n",
       "         [[ 0.2264, -0.3188,  1.9831,  ...,  0.2838, -0.0204, -0.1733],\n",
       "          [ 0.9626, -0.9672, -0.7345,  ...,  0.3543, -0.4477, -0.9536],\n",
       "          [ 0.7963, -1.2603, -1.7316,  ...,  0.5586, -0.6859, -0.7541],\n",
       "          ...,\n",
       "          [ 0.2094, -0.6958, -1.1682,  ..., -0.3977, -0.8803, -0.3158],\n",
       "          [ 0.6769, -1.4065, -0.7633,  ..., -0.3663, -0.4704, -0.7464],\n",
       "          [ 0.8182, -0.2300, -0.7829,  ..., -1.1434, -0.3024, -0.6757]],\n",
       "\n",
       "         [[ 0.0299,  1.0962,  0.3237,  ..., -0.5227,  0.4827, -0.1406],\n",
       "          [-0.0820,  1.0275,  0.4286,  ...,  1.4535,  0.9308, -0.5109],\n",
       "          [-0.5877,  0.4889,  0.7799,  ...,  1.5119,  1.1832,  0.0445],\n",
       "          ...,\n",
       "          [-0.8966, -0.4631, -0.2403,  ...,  0.8140, -0.0962, -0.5373],\n",
       "          [-1.0091,  0.3007, -0.0166,  ..., -0.5937,  1.3064, -0.1100],\n",
       "          [ 0.8368,  0.1835, -0.4055,  ...,  1.4378,  0.5481, -0.4359]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.6139,  0.9203, -0.7404,  ..., -0.7381,  0.7569,  0.8474],\n",
       "          [ 0.5317,  0.5609, -0.5017,  ..., -0.6295,  0.4701,  0.7266],\n",
       "          [-0.0836,  0.1750, -0.3670,  ..., -0.8601,  0.5581, -0.3255],\n",
       "          ...,\n",
       "          [-1.0329,  0.9417,  1.4676,  ..., -0.1111, -0.5468, -1.3466],\n",
       "          [ 0.1309,  1.0380,  0.3225,  ..., -0.6756,  0.7887, -0.5205],\n",
       "          [-2.7255, -0.9396, -1.0175,  ...,  0.9740, -0.9082,  0.0586]],\n",
       "\n",
       "         [[-0.4332,  0.4827,  0.2152,  ...,  0.3254, -0.1317, -0.2257],\n",
       "          [-1.2258,  1.3802, -1.9712,  ...,  0.0138, -0.8335, -0.7315],\n",
       "          [-1.1823,  1.2860, -0.9657,  ...,  0.8041, -1.2825, -0.6479],\n",
       "          ...,\n",
       "          [-1.4934,  0.2745, -0.6567,  ..., -0.5868, -1.6948, -0.1512],\n",
       "          [-0.7967, -0.1291, -0.2830,  ..., -0.1884, -1.5578, -0.6648],\n",
       "          [ 0.2441, -1.4639, -1.0149,  ...,  0.1597, -1.1423,  0.5776]],\n",
       "\n",
       "         [[-0.8536, -0.6226,  0.7523,  ...,  0.4060,  0.5306,  0.1347],\n",
       "          [-1.1564, -2.9920,  3.4981,  ...,  2.2504,  1.6697,  1.1044],\n",
       "          [-0.8049, -0.9299,  1.3115,  ...,  0.4833, -0.9292,  0.9483],\n",
       "          ...,\n",
       "          [-0.1148, -1.4088,  1.5591,  ..., -1.0088, -0.8051,  0.3165],\n",
       "          [ 0.5216, -0.5913,  1.8569,  ..., -0.0347, -0.6184,  0.3831],\n",
       "          [ 0.4885, -1.2989,  3.0939,  ...,  0.9915,  0.8954, -0.0272]]]],\n",
       "       device='cuda:0', grad_fn=<PermuteBackward0>), tensor([[[[-9.2268e-02,  4.0138e-02, -2.2460e-01,  ..., -3.1631e-01,\n",
       "            2.9635e-01, -9.7802e-02],\n",
       "          [-7.4926e-01, -2.0352e-01,  4.9592e-01,  ...,  1.0409e+00,\n",
       "            1.4757e-01,  7.7034e-01],\n",
       "          [ 3.5785e-01,  2.2947e-01,  6.9549e-01,  ...,  1.8727e+00,\n",
       "           -5.3698e-01,  1.4875e+00],\n",
       "          ...,\n",
       "          [ 1.9701e+00, -5.0417e-01, -4.0414e-01,  ..., -7.0796e-02,\n",
       "           -1.4605e+00,  1.6840e+00],\n",
       "          [ 1.0876e+00, -1.5279e+00,  7.3467e-01,  ...,  6.8719e-01,\n",
       "            4.7327e-01,  1.4645e-01],\n",
       "          [-5.5603e-01,  3.7557e-01, -4.4664e+00,  ...,  1.9154e+00,\n",
       "           -2.2398e+00,  2.5600e+00]],\n",
       "\n",
       "         [[ 5.2639e-02,  1.1032e-01, -1.5635e-01,  ..., -3.0815e-02,\n",
       "           -1.2518e-01,  2.3706e-01],\n",
       "          [-2.9925e-01,  3.8152e-01, -4.5563e-01,  ...,  1.1521e-01,\n",
       "           -2.9767e-01,  3.7977e-01],\n",
       "          [-9.3882e-01,  3.5888e-01,  2.0390e-02,  ..., -3.5800e-01,\n",
       "           -4.1639e-01,  6.9946e-01],\n",
       "          ...,\n",
       "          [ 1.0691e-01,  2.4415e-01,  3.9023e-01,  ...,  2.0034e-01,\n",
       "            9.5098e-02,  5.4304e-01],\n",
       "          [-7.0797e-02, -5.8903e-01, -1.5210e+00,  ...,  5.2678e-01,\n",
       "            8.1986e-01,  4.2475e-01],\n",
       "          [-1.9166e+00, -1.4382e-02, -3.8578e-01,  ...,  2.0354e+00,\n",
       "           -1.2715e+00, -4.7379e-01]],\n",
       "\n",
       "         [[ 8.4900e-02,  4.7989e-02,  4.3692e-02,  ...,  1.2683e-01,\n",
       "            4.4727e-02,  8.5139e-02],\n",
       "          [ 2.4059e-01, -1.8757e-01,  4.3986e-01,  ...,  9.5578e-01,\n",
       "           -1.2711e-01,  2.1678e-01],\n",
       "          [-7.2067e-01, -6.4289e-02,  1.3092e-01,  ..., -4.8219e-01,\n",
       "            4.1917e-01, -1.6609e-01],\n",
       "          ...,\n",
       "          [-8.7433e-01,  2.4720e-01, -9.9506e-01,  ..., -2.4358e-01,\n",
       "           -2.1130e-01, -4.9095e-01],\n",
       "          [ 7.5933e-02, -1.3066e+00,  3.9015e-01,  ...,  1.4342e-01,\n",
       "           -1.2999e+00, -1.9982e+00],\n",
       "          [-1.6529e+00,  9.8755e-01,  4.3088e-01,  ..., -4.1497e+00,\n",
       "           -1.8465e+00, -4.5113e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 4.0527e-02,  8.6179e-02,  9.1670e-03,  ...,  5.5687e-02,\n",
       "           -3.9958e-03,  2.8480e-03],\n",
       "          [ 6.5457e-02,  5.4259e-01,  5.3600e-01,  ...,  1.1442e-01,\n",
       "            3.7120e-02,  1.2222e-01],\n",
       "          [-3.4592e-01,  7.0790e-01, -3.0636e-01,  ...,  1.3374e-01,\n",
       "            3.7890e-01,  4.0651e-01],\n",
       "          ...,\n",
       "          [-5.8367e-01,  2.0491e-01, -8.4521e-01,  ...,  1.5429e+00,\n",
       "           -4.7018e-01,  3.9475e-01],\n",
       "          [-3.7567e-01, -4.6717e-02, -2.1022e-01,  ...,  4.5731e-01,\n",
       "            6.6336e-03, -1.6766e+00],\n",
       "          [ 3.8326e-01,  3.2322e-02, -7.5032e-01,  ...,  2.0903e+00,\n",
       "            1.1470e+00,  1.5780e+00]],\n",
       "\n",
       "         [[ 1.5685e-02, -8.0025e-02,  2.6944e-02,  ..., -9.7456e-02,\n",
       "            6.2074e-02, -8.1147e-02],\n",
       "          [-5.0784e-01, -9.5583e-02,  6.8213e-01,  ...,  7.2852e-02,\n",
       "           -1.4960e-02, -6.5167e-02],\n",
       "          [ 4.2610e-02, -1.0781e-02,  1.7646e-01,  ...,  1.9041e-01,\n",
       "            8.3044e-01, -6.9885e-02],\n",
       "          ...,\n",
       "          [-5.2934e-01,  3.5324e-01,  2.4530e-01,  ...,  4.1069e-01,\n",
       "           -1.4655e-01, -5.5327e-01],\n",
       "          [-4.9828e-01,  7.2298e-01,  4.1905e-01,  ...,  1.7218e+00,\n",
       "           -7.4260e-01,  8.6987e-01],\n",
       "          [-2.5850e-01, -5.1415e-01, -2.9700e-01,  ..., -5.1235e-01,\n",
       "            3.0946e-02, -4.1542e-01]],\n",
       "\n",
       "         [[ 2.2753e-01,  5.2361e-02, -2.6776e-01,  ...,  3.7044e-01,\n",
       "            1.7803e-01,  6.4308e-02],\n",
       "          [ 9.3284e-01,  1.3933e+00, -3.0063e+00,  ...,  3.4657e+00,\n",
       "            1.9156e+00,  7.2947e-01],\n",
       "          [-2.5834e-02, -1.7672e-01, -5.9644e-01,  ..., -1.6570e-01,\n",
       "            2.7773e-01,  4.0972e-01],\n",
       "          ...,\n",
       "          [ 1.0988e+00,  1.0014e+00,  7.6467e-01,  ...,  1.1725e-01,\n",
       "            1.1107e-01, -1.6653e-01],\n",
       "          [ 1.5394e-01, -6.9176e-01,  5.3755e-02,  ..., -1.5934e-01,\n",
       "            2.2135e-01,  9.4580e-01],\n",
       "          [ 4.8940e-01,  2.1415e+00, -1.5182e-01,  ...,  1.9921e+00,\n",
       "            4.0293e+00,  5.8001e-01]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>))), decoder_hidden_states=None, decoder_attentions=None, cross_attentions=None, encoder_last_hidden_state=tensor([[[-0.2607,  0.0198,  0.4755,  ..., -0.0941, -0.0225, -0.3256],\n",
       "         [-0.0041, -0.0816,  0.2196,  ...,  0.2457, -0.3431,  0.1485],\n",
       "         [ 0.3718, -0.6029, -0.0986,  ..., -0.0779, -0.3115, -0.4040],\n",
       "         ...,\n",
       "         [-0.4011,  0.0278,  0.4655,  ..., -0.1463, -0.0469, -0.1834],\n",
       "         [-0.3879, -0.2103, -0.5007,  ...,  0.1551, -0.2414, -0.0241],\n",
       "         [-0.2757, -0.2442,  0.2686,  ..., -0.1122,  0.4609,  0.2692]]],\n",
       "       device='cuda:0', grad_fn=<CopySlices>), encoder_hidden_states=None, encoder_attentions=None)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(pixel_values, labels=output_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "cf1479fa-ffb0-44a6-886b-20963f3ea668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_attentions <class 'bool'>\n",
      "output_hidden_states <class 'bool'>\n",
      "return_dict <class 'bool'>\n",
      "pixel_values <class 'torch.Tensor'>\n",
      "---- RETURN VAL ---\n",
      "<class 'transformers.modeling_outputs.BaseModelOutputWithPooling'>\n",
      "last_hidden_state torch.Size([1, 197, 768])\n",
      "pooler_output torch.Size([1, 768])\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'a person standing next to a pile of luggage'"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_ids = model.generate(pixel_values, **gen_kwargs)\n",
    "tokenizer.batch_decode(output_ids, skip_special_tokens=True)[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8e72e194-3bce-4915-9055-634d59eb4b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "handle.remove()\n",
    "def hook(m, input, output):\n",
    "    print(type(m))\n",
    "    print('Input shapes', type(input), len(input))\n",
    "    \n",
    "    if isinstance(input, tuple):\n",
    "        for x in input:\n",
    "            print(type(x))\n",
    "    print('Output shapes')\n",
    "    \n",
    "    print(type(output))\n",
    "    \n",
    "    \n",
    "    print(output.shape)\n",
    "\n",
    "handle = model.decoder.register_forward_hook(hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "759fdb7c-65ac-408a-aad0-112be5d43220",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "image_path = 'croissant.jpg'\n",
    "image = Image.open(image_path)\n",
    "if image.mode != \"RGB\":\n",
    "    image = image.convert(mode=\"RGB\")\n",
    "pixel_values = feature_extractor(images=[image], return_tensors=\"pt\").pixel_values.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tp2",
   "language": "python",
   "name": "tp2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
