{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9485da5-3e40-42f1-873e-ccb244a74bc3",
   "metadata": {},
   "source": [
    "# Load musiccaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07bb0885-c2da-43e2-8df4-468ee5f97594",
   "metadata": {},
   "outputs": [],
   "source": [
    "from musiccaps import load_musiccaps\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8926e06-ef8c-40a7-8675-f4d1285d0afe",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration google--MusicCaps-7925612b943f961b\n",
      "Found cached dataset csv (/home/dominik/.cache/huggingface/datasets/google___csv/google--MusicCaps-7925612b943f961b/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/dominik/.cache/huggingface/datasets/google___csv/google--MusicCaps-7925612b943f961b/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-3309f9007425eecd.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/dominik/.cache/huggingface/datasets/google___csv/google--MusicCaps-7925612b943f961b/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-70279f61db8a5fbb.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/dominik/.cache/huggingface/datasets/google___csv/google--MusicCaps-7925612b943f961b/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-60f7e51bf7ab1aae.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/dominik/.cache/huggingface/datasets/google___csv/google--MusicCaps-7925612b943f961b/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-54cb21bf4ee59f82.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/dominik/.cache/huggingface/datasets/google___csv/google--MusicCaps-7925612b943f961b/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-6cb3cbe00008b97a.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/dominik/.cache/huggingface/datasets/google___csv/google--MusicCaps-7925612b943f961b/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-1a5fb4f6dff5ee60.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/dominik/.cache/huggingface/datasets/google___csv/google--MusicCaps-7925612b943f961b/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-fbf6f8ab350eeb18.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/dominik/.cache/huggingface/datasets/google___csv/google--MusicCaps-7925612b943f961b/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-810290b7b9443a8c.arrow\n"
     ]
    }
   ],
   "source": [
    "ds = load_musiccaps(\n",
    "    './music_data',\n",
    "    sampling_rate=16000,\n",
    "    limit=None,\n",
    "    num_proc=8,\n",
    "    writer_batch_size=1000,\n",
    ")\n",
    "embeddings = np.load('embeddings.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "d183427c-b2e6-4253-8577-113e97d8ead9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batcher(bs):\n",
    "    for epoch in itertools.count(0, 1):\n",
    "        captions, embs = [], []\n",
    "        \n",
    "        for i in np.random.permutation(len(ds)):\n",
    "            i = int(i)\n",
    "            try:\n",
    "                captions.append(ds[i]['caption'])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue\n",
    "            embs.append(embeddings[ds[i]['ytid']])\n",
    "            \n",
    "            if len(captions) == bs:\n",
    "                assert len(embs) == bs\n",
    "                captions = tokenizer(captions, padding='longest', return_tensors='pt')['input_ids'].cuda()\n",
    "                embs = torch.from_numpy(np.stack(embs)).cuda()\n",
    "                yield captions, embs, epoch\n",
    "                captions, embs = [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd545edf-5fb3-4f57-9505-9faed44c8d51",
   "metadata": {},
   "source": [
    "# Image captioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "1bdf0432-60e4-4e76-ab97-1fdfd9d3e384",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import VisionEncoderDecoderModel, ViTFeatureExtractor, AutoTokenizer\n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torchinfo\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "c4d70c2d-06cb-45a7-85e7-cc7789845d43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\").cuda()\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "\n",
    "encoder_forward = model.encoder.forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "3f3feada-cadf-4678-866a-108d8bf00a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class B2T(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(512, 768),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(768, 768),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(768, 768)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.main(x)\n",
    "    \n",
    "b2t = B2T().cuda()\n",
    "opt = torch.optim.Adam([*b2t.parameters()], lr=0.0001) # , *model.decoder.parameters()]\n",
    "losses = []\n",
    "bs = 32\n",
    "fake_pixel_values = torch.zeros((bs, 3, 224, 224)).cuda()\n",
    "batcher = create_batcher(bs)\n",
    "patch_enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "7fb9e1d5-a144-4b4d-9e17-ab20f3337bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patched_forward(*args, **kwargs):\n",
    "    result = encoder_forward(*args, **kwargs)\n",
    "    if not patch_enabled:\n",
    "        result.last_hidden_state = b2t(embs[0:1]).unsqueeze(1).repeat(1, 197, 1)\n",
    "    else:\n",
    "        result.last_hidden_state = b2t(embs).unsqueeze(1).repeat(1, 197, 1)\n",
    "        # torch.randn_like(result.last_hidden_state)*0.3\n",
    "    return result\n",
    "\n",
    "model.encoder.forward = patched_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdc2aaa-8423-40ac-9770-ca4387c2ff73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f690473db574617b9f48d80a9d1f6ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'music_data/0J_2K1Gvruk.wav'\n",
      "a person standing on a ledge with a bunch of stuff on it\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a person standing next to a wooden table with a bunch of water bottles\n",
      "a person standing next to a wooden table with a bunch of water bottles\n"
     ]
    }
   ],
   "source": [
    "for step in tqdm(itertools.count(0, 1)):\n",
    "    captions, embs, epoch = next(batcher)\n",
    "\n",
    "    patch_enabled = True\n",
    "    loss = model(fake_pixel_values, labels=captions).loss\n",
    "    patch_enabled = False\n",
    "    \n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    output_ids = model.generate(fake_pixel_values[0:1], max_length=256, num_beams=1)\n",
    "    print(tokenizer.batch_decode(output_ids, skip_special_tokens=True)[0].strip())\n",
    "    \n",
    "    if step % 10 == 0:\n",
    "        plt.plot(losses)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26d61cec-92c8-4b95-b3b6-6d03df6c737e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patched_forward(*args, **kwargs):\n",
    "    for arg in args:\n",
    "        if not arg is None:\n",
    "            print(type(arg))\n",
    "    for k, v in kwargs.items():\n",
    "        if not v is None:\n",
    "            print(k, type(v))\n",
    "    print('---- RETURN VAL ---')\n",
    "    result = f(*args, **kwargs)\n",
    "    print(type(result))\n",
    "    for k in result:\n",
    "        print(k, getattr(result, k).shape)\n",
    "    print('\\n'*3)\n",
    "    result.last_hidden_state[:] = torch.randn_like(result.last_hidden_state)*0.3\n",
    "    return result\n",
    "\n",
    "model.encoder.forward = patched_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "8b9730dc-3d80-4bfd-b5d8-4f01a41f9bd3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpixel_values\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbool_masked_pos\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBoolTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mhead_mask\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minterpolate_pos_encoding\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreturn_dict\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseModelOutputWithPooling\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "The [`ViTModel`] forward method, overrides the `__call__` special method.\n",
       "\n",
       "<Tip>\n",
       "\n",
       "Although the recipe for forward pass needs to be defined within this function, one should call the [`Module`]\n",
       "instance afterwards instead of this since the former takes care of running the pre and post processing steps while\n",
       "the latter silently ignores them.\n",
       "\n",
       "</Tip>\n",
       "\n",
       "Args:\n",
       "    pixel_values (`torch.FloatTensor` of shape `(batch_size, num_channels, height, width)`):\n",
       "        Pixel values. Pixel values can be obtained using [`AutoImageProcessor`]. See [`ViTImageProcessor.__call__`]\n",
       "        for details.\n",
       "\n",
       "    head_mask (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`, *optional*):\n",
       "        Mask to nullify selected heads of the self-attention modules. Mask values selected in `[0, 1]`:\n",
       "\n",
       "        - 1 indicates the head is **not masked**,\n",
       "        - 0 indicates the head is **masked**.\n",
       "\n",
       "    output_attentions (`bool`, *optional*):\n",
       "        Whether or not to return the attentions tensors of all attention layers. See `attentions` under returned\n",
       "        tensors for more detail.\n",
       "    output_hidden_states (`bool`, *optional*):\n",
       "        Whether or not to return the hidden states of all layers. See `hidden_states` under returned tensors for\n",
       "        more detail.\n",
       "    interpolate_pos_encoding (`bool`, *optional*):\n",
       "        Whether to interpolate the pre-trained position encodings.\n",
       "    return_dict (`bool`, *optional*):\n",
       "        Whether or not to return a [`~utils.ModelOutput`] instead of a plain tuple.\n",
       "\n",
       "Returns:\n",
       "    [`transformers.modeling_outputs.BaseModelOutputWithPooling`] or `tuple(torch.FloatTensor)`: A [`transformers.modeling_outputs.BaseModelOutputWithPooling`] or a tuple of\n",
       "    `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`) comprising various\n",
       "    elements depending on the configuration ([`ViTConfig`]) and inputs.\n",
       "\n",
       "    - **last_hidden_state** (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`) -- Sequence of hidden-states at the output of the last layer of the model.\n",
       "    - **pooler_output** (`torch.FloatTensor` of shape `(batch_size, hidden_size)`) -- Last layer hidden-state of the first token of the sequence (classification token) after further processing\n",
       "      through the layers used for the auxiliary pretraining task. E.g. for BERT-family of models, this returns\n",
       "      the classification token after processing through a linear layer and a tanh activation function. The linear\n",
       "      layer weights are trained from the next sentence prediction (classification) objective during pretraining.\n",
       "    - **hidden_states** (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`) -- Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model has an embedding layer, +\n",
       "      one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.\n",
       "\n",
       "      Hidden-states of the model at the output of each layer plus the optional initial embedding outputs.\n",
       "    - **attentions** (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_attentions=True`) -- Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads, sequence_length,\n",
       "      sequence_length)`.\n",
       "\n",
       "      Attentions weights after the attention softmax, used to compute the weighted average in the self-attention\n",
       "      heads.\n",
       "\n",
       "Example:\n",
       "\n",
       "```python\n",
       ">>> from transformers import AutoImageProcessor, ViTModel\n",
       ">>> import torch\n",
       ">>> from datasets import load_dataset\n",
       "\n",
       ">>> dataset = load_dataset(\"huggingface/cats-image\")\n",
       ">>> image = dataset[\"test\"][\"image\"][0]\n",
       "\n",
       ">>> image_processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
       ">>> model = ViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
       "\n",
       ">>> inputs = image_processor(image, return_tensors=\"pt\")\n",
       "\n",
       ">>> with torch.no_grad():\n",
       "...     outputs = model(**inputs)\n",
       "\n",
       ">>> last_hidden_states = outputs.last_hidden_state\n",
       ">>> list(last_hidden_states.shape)\n",
       "[1, 197, 768]\n",
       "```\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "    \u001b[0;34m@\u001b[0m\u001b[0madd_start_docstrings_to_model_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVIT_INPUTS_DOCSTRING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0madd_code_sample_docstrings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mcheckpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_CHECKPOINT_FOR_DOC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0moutput_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBaseModelOutputWithPooling\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mconfig_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_CONFIG_FOR_DOC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmodality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"vision\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mexpected_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_EXPECTED_OUTPUT_SHAPE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mpixel_values\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mbool_masked_pos\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBoolTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mhead_mask\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0minterpolate_pos_encoding\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mreturn_dict\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseModelOutputWithPooling\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0moutput_attentions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_attentions\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_attentions\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0moutput_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0moutput_hidden_states\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_hidden_states\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mpixel_values\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You have to specify pixel_values\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Prepare head mask if needed\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# 1.0 in head_mask indicate we keep the head\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# attention_probs has shape bsz x n_heads x N x N\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# TODO: maybe have a cleaner way to cast the input (from `ImageProcessor` side?)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mexpected_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprojection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mpixel_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexpected_dtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mpixel_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpixel_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0membedding_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mpixel_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool_masked_pos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool_masked_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolate_pos_encoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolate_pos_encoding\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mencoder_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mhead_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooled_output\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpooled_output\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mhead_outputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mBaseModelOutputWithPooling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mpooler_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpooled_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mattentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/envs/tp2/lib/python3.9/site-packages/transformers/models/vit/modeling_vit.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "2394b7c7-a99e-423e-aca9-ddd3fbbfdf5c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpixel_values\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBoolTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpast_key_values\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdecoder_inputs_embeds\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0muse_cache\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreturn_dict\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeq2SeqLMOutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "The [`VisionEncoderDecoderModel`] forward method, overrides the `__call__` special method.\n",
       "\n",
       "<Tip>\n",
       "\n",
       "Although the recipe for forward pass needs to be defined within this function, one should call the [`Module`]\n",
       "instance afterwards instead of this since the former takes care of running the pre and post processing steps while\n",
       "the latter silently ignores them.\n",
       "\n",
       "</Tip>\n",
       "\n",
       "Args:\n",
       "    pixel_values (`torch.FloatTensor` of shape `(batch_size, num_channels, height, width)`):\n",
       "        Pixel values. Pixel values can be obtained using an image processor (e.g. if you use ViT as the encoder,\n",
       "        you should use [`AutoImageProcessor`]). See [`ViTImageProcessor.__call__`] for details.\n",
       "    decoder_input_ids (`torch.LongTensor` of shape `(batch_size, target_sequence_length)`, *optional*):\n",
       "        Indices of decoder input sequence tokens in the vocabulary.\n",
       "\n",
       "        Indices can be obtained using [`PreTrainedTokenizer`]. See [`PreTrainedTokenizer.encode`] and\n",
       "        [`PreTrainedTokenizer.__call__`] for details.\n",
       "\n",
       "        [What are input IDs?](../glossary#input-ids)\n",
       "\n",
       "        If `past_key_values` is used, optionally only the last `decoder_input_ids` have to be input (see\n",
       "        `past_key_values`).\n",
       "\n",
       "        For training, `decoder_input_ids` are automatically created by the model by shifting the `labels` to the\n",
       "        right, replacing -100 by the `pad_token_id` and prepending them with the `decoder_start_token_id`.\n",
       "    decoder_attention_mask (`torch.BoolTensor` of shape `(batch_size, target_sequence_length)`, *optional*):\n",
       "        Default behavior: generate a tensor that ignores pad tokens in `decoder_input_ids`. Causal mask will also\n",
       "        be used by default.\n",
       "    encoder_outputs (`tuple(torch.FloatTensor)`, *optional*):\n",
       "        This tuple must consist of (`last_hidden_state`, *optional*: `hidden_states`, *optional*: `attentions`)\n",
       "        `last_hidden_state` (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`) is a tensor\n",
       "        of hidden-states at the output of the last layer of the encoder. Used in the cross-attention of the\n",
       "        decoder.\n",
       "    past_key_values (`tuple(tuple(torch.FloatTensor))` of length `config.n_layers` with each tuple having 4 tensors of shape `(batch_size, num_heads, sequence_length - 1, embed_size_per_head)`):\n",
       "        Contains precomputed key and value hidden states of the attention blocks. Can be used to speed up decoding.\n",
       "\n",
       "        If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids` (those that\n",
       "        don't have their past key value states given to this model) of shape `(batch_size, 1)` instead of all\n",
       "        `decoder_input_ids` of shape `(batch_size, sequence_length)`.\n",
       "    decoder_inputs_embeds (`torch.FloatTensor` of shape `(batch_size, target_sequence_length, hidden_size)`, *optional*):\n",
       "        Optionally, instead of passing `decoder_input_ids` you can choose to directly pass an embedded\n",
       "        representation. This is useful if you want more control over how to convert `decoder_input_ids` indices\n",
       "        into associated vectors than the model's internal embedding lookup matrix.\n",
       "    labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
       "        Labels for computing the masked language modeling loss for the decoder. Indices should be in `[-100, 0,\n",
       "        ..., config.vocab_size]` (see `input_ids` docstring) Tokens with indices set to `-100` are ignored\n",
       "        (masked), the loss is only computed for the tokens with labels in `[0, ..., config.vocab_size]`\n",
       "    use_cache (`bool`, *optional*):\n",
       "        If set to `True`, `past_key_values` key value states are returned and can be used to speed up decoding (see\n",
       "        `past_key_values`).\n",
       "    output_attentions (`bool`, *optional*):\n",
       "        Whether or not to return the attentions tensors of all attention layers. See `attentions` under returned\n",
       "        tensors for more detail.\n",
       "    output_hidden_states (`bool`, *optional*):\n",
       "        Whether or not to return the hidden states of all layers. See `hidden_states` under returned tensors for\n",
       "        more detail.\n",
       "    return_dict (`bool`, *optional*):\n",
       "        If set to `True`, the model will return a [`~utils.Seq2SeqLMOutput`] instead of a plain tuple.\n",
       "    kwargs (*optional*): Remaining dictionary of keyword arguments. Keyword arguments come in two flavors:\n",
       "\n",
       "        - Without a prefix which will be input as `**encoder_kwargs` for the encoder forward function.\n",
       "        - With a *decoder_* prefix which will be input as `**decoder_kwargs` for the decoder forward function.\n",
       "\n",
       "\n",
       "    Returns:\n",
       "        [`transformers.modeling_outputs.Seq2SeqLMOutput`] or `tuple(torch.FloatTensor)`: A [`transformers.modeling_outputs.Seq2SeqLMOutput`] or a tuple of\n",
       "        `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`) comprising various\n",
       "        elements depending on the configuration ([`VisionEncoderDecoderConfig`]) and inputs.\n",
       "\n",
       "        - **loss** (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels` is provided) -- Language modeling loss.\n",
       "        - **logits** (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.vocab_size)`) -- Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax).\n",
       "        - **past_key_values** (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`) -- Tuple of `tuple(torch.FloatTensor)` of length `config.n_layers`, with each tuple having 2 tensors of shape\n",
       "          `(batch_size, num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of shape\n",
       "          `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.\n",
       "\n",
       "          Contains pre-computed hidden-states (key and values in the self-attention blocks and in the cross-attention\n",
       "          blocks) that can be used (see `past_key_values` input) to speed up sequential decoding.\n",
       "        - **decoder_hidden_states** (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`) -- Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model has an embedding layer, +\n",
       "          one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.\n",
       "\n",
       "          Hidden-states of the decoder at the output of each layer plus the initial embedding outputs.\n",
       "        - **decoder_attentions** (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_attentions=True`) -- Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads, sequence_length,\n",
       "          sequence_length)`.\n",
       "\n",
       "          Attentions weights of the decoder, after the attention softmax, used to compute the weighted average in the\n",
       "          self-attention heads.\n",
       "        - **cross_attentions** (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_attentions=True`) -- Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads, sequence_length,\n",
       "          sequence_length)`.\n",
       "\n",
       "          Attentions weights of the decoder's cross-attention layer, after the attention softmax, used to compute the\n",
       "          weighted average in the cross-attention heads.\n",
       "        - **encoder_last_hidden_state** (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*) -- Sequence of hidden-states at the output of the last layer of the encoder of the model.\n",
       "        - **encoder_hidden_states** (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`) -- Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model has an embedding layer, +\n",
       "          one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.\n",
       "\n",
       "          Hidden-states of the encoder at the output of each layer plus the initial embedding outputs.\n",
       "        - **encoder_attentions** (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_attentions=True`) -- Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads, sequence_length,\n",
       "          sequence_length)`.\n",
       "\n",
       "          Attentions weights of the encoder, after the attention softmax, used to compute the weighted average in the\n",
       "          self-attention heads.\n",
       "  \n",
       "\n",
       "    Examples:\n",
       "\n",
       "    ```python\n",
       "    >>> from transformers import AutoProcessor, VisionEncoderDecoderModel\n",
       "    >>> import requests\n",
       "    >>> from PIL import Image\n",
       "    >>> import torch\n",
       "\n",
       "    >>> processor = AutoProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
       "    >>> model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
       "\n",
       "    >>> # load image from the IAM dataset\n",
       "    >>> url = \"https://fki.tic.heia-fr.ch/static/img/a01-122-02.jpg\"\n",
       "    >>> image = Image.open(requests.get(url, stream=True).raw).convert(\"RGB\")\n",
       "\n",
       "    >>> # training\n",
       "    >>> model.config.decoder_start_token_id = processor.tokenizer.cls_token_id\n",
       "    >>> model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
       "    >>> model.config.vocab_size = model.config.decoder.vocab_size\n",
       "\n",
       "    >>> pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n",
       "    >>> text = \"hello world\"\n",
       "    >>> labels = processor.tokenizer(text, return_tensors=\"pt\").input_ids\n",
       "    >>> outputs = model(pixel_values=pixel_values, labels=labels)\n",
       "    >>> loss = outputs.loss\n",
       "\n",
       "    >>> # inference (generation)\n",
       "    >>> generated_ids = model.generate(pixel_values)\n",
       "    >>> generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
       "    ```\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "    \u001b[0;34m@\u001b[0m\u001b[0madd_start_docstrings_to_model_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVISION_ENCODER_DECODER_INPUTS_DOCSTRING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mreplace_return_docstrings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSeq2SeqLMOutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_CONFIG_FOR_DOC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mpixel_values\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBoolTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mpast_key_values\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdecoder_inputs_embeds\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0muse_cache\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mreturn_dict\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeq2SeqLMOutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"\u001b[0m\n",
       "\u001b[0;34m        Returns:\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Examples:\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        ```python\u001b[0m\n",
       "\u001b[0;34m        >>> from transformers import AutoProcessor, VisionEncoderDecoderModel\u001b[0m\n",
       "\u001b[0;34m        >>> import requests\u001b[0m\n",
       "\u001b[0;34m        >>> from PIL import Image\u001b[0m\n",
       "\u001b[0;34m        >>> import torch\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        >>> processor = AutoProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\")\u001b[0m\n",
       "\u001b[0;34m        >>> model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-handwritten\")\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        >>> # load image from the IAM dataset\u001b[0m\n",
       "\u001b[0;34m        >>> url = \"https://fki.tic.heia-fr.ch/static/img/a01-122-02.jpg\"\u001b[0m\n",
       "\u001b[0;34m        >>> image = Image.open(requests.get(url, stream=True).raw).convert(\"RGB\")\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        >>> # training\u001b[0m\n",
       "\u001b[0;34m        >>> model.config.decoder_start_token_id = processor.tokenizer.cls_token_id\u001b[0m\n",
       "\u001b[0;34m        >>> model.config.pad_token_id = processor.tokenizer.pad_token_id\u001b[0m\n",
       "\u001b[0;34m        >>> model.config.vocab_size = model.config.decoder.vocab_size\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        >>> pixel_values = processor(image, return_tensors=\"pt\").pixel_values\u001b[0m\n",
       "\u001b[0;34m        >>> text = \"hello world\"\u001b[0m\n",
       "\u001b[0;34m        >>> labels = processor.tokenizer(text, return_tensors=\"pt\").input_ids\u001b[0m\n",
       "\u001b[0;34m        >>> outputs = model(pixel_values=pixel_values, labels=labels)\u001b[0m\n",
       "\u001b[0;34m        >>> loss = outputs.loss\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        >>> # inference (generation)\u001b[0m\n",
       "\u001b[0;34m        >>> generated_ids = model.generate(pixel_values)\u001b[0m\n",
       "\u001b[0;34m        >>> generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\u001b[0m\n",
       "\u001b[0;34m        ```\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mkwargs_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0margument\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0margument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"decoder_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mkwargs_decoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0margument\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"decoder_\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0margument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"decoder_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mencoder_outputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mpixel_values\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You have to specify pixel_values\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mencoder_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mpixel_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m**\u001b[0m\u001b[0mkwargs_encoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mencoder_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBaseModelOutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mencoder_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# optionally project encoder_hidden_states\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attention_hidden_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mencoder_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_to_dec_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# else:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mencoder_attention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdecoder_inputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mdecoder_input_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshift_tokens_right\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_token_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder_start_token_id\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Decode\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdecoder_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_inputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mpast_key_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m**\u001b[0m\u001b[0mkwargs_decoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Compute loss independent from decoder (as some shift the logits inside them)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdecoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mloss_fct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdecoder_outputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mreturn\u001b[0m \u001b[0mdecoder_outputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mSeq2SeqLMOutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mpast_key_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mdecoder_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mdecoder_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mcross_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mencoder_last_hidden_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mencoder_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/envs/tp2/lib/python3.9/site-packages/transformers/models/vision_encoder_decoder/modeling_vision_encoder_decoder.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.forward??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "514dd1c2-b360-4483-97c7-4da61bca8fea",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "return_dict <class 'bool'>\n",
      "---- RETURN VAL ---\n",
      "<class 'transformers.modeling_outputs.BaseModelOutputWithPooling'>\n",
      "last_hidden_state torch.Size([1, 197, 768])\n",
      "pooler_output torch.Size([1, 768])\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Seq2SeqLMOutput(loss=tensor(2.3366, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[[ -35.8679,  -26.7638,  -27.6791,  ...,  -47.7585,  -43.8306,\n",
       "           -32.5497],\n",
       "         [ -42.1690,  -32.1792,  -33.5180,  ...,  -53.5255,  -48.5961,\n",
       "           -37.6655],\n",
       "         [ -32.6727,  -30.1231,  -34.8829,  ...,  -42.8414,  -30.4824,\n",
       "           -30.9890],\n",
       "         ...,\n",
       "         [ -46.9919,  -44.8377,  -49.4250,  ...,  -55.7228,  -49.0115,\n",
       "           -45.0781],\n",
       "         [ -62.6528,  -61.6987,  -66.5732,  ...,  -79.3381,  -68.3395,\n",
       "           -59.0497],\n",
       "         [-125.0046, -122.8182, -127.5253,  ..., -142.7821, -135.1219,\n",
       "           -94.1819]]], device='cuda:0', grad_fn=<UnsafeViewBackward0>), past_key_values=((tensor([[[[-0.4639,  1.0217,  0.5178,  ..., -1.3494,  0.0604,  0.9517],\n",
       "          [-0.8643,  0.9492,  1.7128,  ..., -1.6513, -0.4688,  1.2078],\n",
       "          [-1.5492,  2.0069,  1.2288,  ..., -0.7368, -1.7374,  1.7684],\n",
       "          ...,\n",
       "          [-2.2556,  2.2525,  1.3288,  ..., -0.7211, -1.8382,  2.2704],\n",
       "          [-3.1566,  1.9203,  0.3840,  ..., -0.7096, -1.8810,  2.0603],\n",
       "          [-2.2085,  1.5743,  2.8767,  ..., -1.9283, -0.8342,  2.5784]],\n",
       "\n",
       "         [[-0.1709,  1.3958, -0.7572,  ...,  0.8681, -0.1085,  0.5793],\n",
       "          [-0.6734,  1.6048, -2.0867,  ...,  1.1256,  0.7438,  0.8776],\n",
       "          [-0.6826, -1.1386, -2.1555,  ..., -1.2235,  2.4112, -0.9106],\n",
       "          ...,\n",
       "          [ 0.5101, -0.6440, -1.4943,  ..., -1.1676,  2.5218, -2.1911],\n",
       "          [-3.2679, -0.6560,  2.0615,  ..., -1.8671,  3.6637,  1.1689],\n",
       "          [-0.2928, -2.2959, -0.7877,  ..., -1.6644,  1.7825,  1.3227]],\n",
       "\n",
       "         [[-0.6023,  0.1136,  0.7381,  ..., -0.0071, -2.5050, -0.1448],\n",
       "          [-0.5294,  0.6403,  0.5944,  ..., -0.1946, -1.6849,  0.5639],\n",
       "          [ 0.2801, -0.3446,  0.6339,  ..., -1.9807, -0.1341,  1.3065],\n",
       "          ...,\n",
       "          [ 0.4014, -0.0804,  0.6043,  ..., -2.0827,  1.0920,  1.5329],\n",
       "          [ 0.8178, -0.0686,  0.1494,  ..., -1.8214,  0.3489, -0.3452],\n",
       "          [ 0.3855, -0.3611,  0.0142,  ..., -2.8448,  3.0786,  2.9358]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.4222,  0.0616, -0.1848,  ..., -0.0974,  0.4861,  0.4959],\n",
       "          [ 0.2486,  0.3100, -0.0952,  ...,  0.0780,  0.1927,  0.4596],\n",
       "          [ 0.0621, -0.2378,  0.0138,  ...,  0.4158,  0.7536,  0.5775],\n",
       "          ...,\n",
       "          [ 0.1764, -0.0208,  0.0873,  ...,  0.8637,  0.4462,  0.6582],\n",
       "          [ 0.7419, -0.6762, -0.0127,  ...,  1.0659,  0.9892,  0.1607],\n",
       "          [ 0.3814,  0.9068,  0.0704,  ...,  0.2636,  0.2421, -0.6919]],\n",
       "\n",
       "         [[ 0.9829,  1.0664, -0.2753,  ...,  0.0853,  0.7661, -1.3274],\n",
       "          [ 0.9027,  0.8964, -0.2462,  ..., -0.3644,  1.0775, -1.0842],\n",
       "          [ 1.0328, -0.1387,  0.1453,  ..., -0.5498,  0.9003, -0.6484],\n",
       "          ...,\n",
       "          [ 0.7748, -0.8501, -0.3008,  ..., -0.6676,  0.2908,  0.0248],\n",
       "          [-0.4217, -0.2030, -0.5479,  ..., -0.8404,  0.9636,  0.6460],\n",
       "          [ 0.7618, -0.9330, -0.6736,  ..., -1.6479,  0.2907,  1.0127]],\n",
       "\n",
       "         [[ 0.8250, -0.1326,  0.2520,  ..., -0.6925, -0.0390,  1.1974],\n",
       "          [ 0.1323, -0.0119, -0.1868,  ..., -0.8618, -0.0680,  0.5035],\n",
       "          [-0.1263,  0.9682,  0.1751,  ...,  0.0700,  0.9173,  1.5292],\n",
       "          ...,\n",
       "          [-0.5006,  0.4279, -0.8383,  ...,  1.4743,  1.2508, -0.8302],\n",
       "          [ 0.0289,  0.0202,  1.4690,  ...,  0.3962,  1.0329,  0.5964],\n",
       "          [-0.8825,  0.6261,  0.5514,  ..., -0.7130, -0.1130,  0.6641]]]],\n",
       "       device='cuda:0', grad_fn=<PermuteBackward0>), tensor([[[[-0.0116,  0.0133, -0.0538,  ...,  0.0127,  0.0990,  0.0907],\n",
       "          [-0.0173,  0.0462, -0.0893,  ...,  0.0281,  0.2050,  0.0858],\n",
       "          [-0.1025, -0.1865,  0.0263,  ..., -0.1059, -0.0729, -0.0847],\n",
       "          ...,\n",
       "          [-0.0091, -0.0586, -0.0552,  ..., -0.0693, -0.0837,  0.1679],\n",
       "          [ 0.1970,  0.1516, -0.0356,  ..., -0.0436, -0.2108, -0.1274],\n",
       "          [ 0.0684,  0.0832,  0.2867,  ...,  0.2200, -0.2494, -0.2329]],\n",
       "\n",
       "         [[ 0.4531,  0.1616, -0.1039,  ..., -0.6283, -0.1871,  0.1476],\n",
       "          [ 0.3904,  0.0278,  0.1497,  ...,  0.0384,  0.3999, -0.0029],\n",
       "          [ 0.3040, -0.0567,  0.2907,  ..., -0.0153,  0.4408,  0.1848],\n",
       "          ...,\n",
       "          [ 0.5794, -0.0716, -0.4528,  ...,  0.0037,  0.5066,  0.1148],\n",
       "          [-0.2324, -0.1537,  0.0298,  ..., -0.1475, -0.1820, -0.0680],\n",
       "          [ 0.3200, -0.2112, -0.0987,  ..., -0.1551,  0.3486,  0.0079]],\n",
       "\n",
       "         [[-0.0189, -0.0522,  0.1322,  ..., -0.0537,  0.0645, -0.1144],\n",
       "          [-0.2031, -0.1509,  0.3074,  ..., -0.0499,  0.1557, -0.1257],\n",
       "          [-0.1392,  0.0239, -0.2544,  ..., -0.0349,  0.1054,  0.0122],\n",
       "          ...,\n",
       "          [ 0.2787,  0.3668,  0.5730,  ..., -0.0168,  0.0802, -0.2359],\n",
       "          [ 0.3179, -0.3128,  0.0209,  ...,  0.0506,  0.1402,  0.1437],\n",
       "          [-0.1689, -0.0395, -0.1370,  ..., -0.1166, -0.0083, -0.1704]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0466, -0.1552,  0.0751,  ..., -0.0830, -0.0483,  0.0384],\n",
       "          [-0.2655,  0.0708,  0.1249,  ...,  0.1390, -0.0240,  0.1049],\n",
       "          [-0.1982, -0.0088,  0.0996,  ..., -0.1435, -0.0298, -0.0388],\n",
       "          ...,\n",
       "          [-0.1228, -0.1899, -0.0529,  ..., -0.3667,  0.0277, -0.2626],\n",
       "          [ 0.0610,  0.1023, -0.0867,  ...,  0.3852,  0.2137, -0.0334],\n",
       "          [-0.0040,  0.5192, -0.1001,  ..., -0.1984, -0.1062, -0.3372]],\n",
       "\n",
       "         [[ 0.0463, -0.1344, -0.0974,  ...,  0.0155,  0.2473,  0.0619],\n",
       "          [-0.3434, -0.1193,  0.1018,  ..., -0.2534,  0.3936,  0.2524],\n",
       "          [-0.2981, -0.2441, -0.1768,  ..., -0.1245, -0.1830, -0.1067],\n",
       "          ...,\n",
       "          [ 0.1191,  0.1075, -0.0399,  ..., -0.0995, -0.1250,  0.0656],\n",
       "          [ 0.0988, -0.1641, -0.4581,  ...,  0.1152, -0.1215, -0.4268],\n",
       "          [-0.1038,  0.1295, -0.2949,  ..., -0.3168,  0.0486, -0.1971]],\n",
       "\n",
       "         [[ 0.1030, -0.4049, -0.0683,  ...,  0.0936, -0.2765,  0.1108],\n",
       "          [ 0.2123, -0.2173, -0.2996,  ...,  0.4282, -0.1852,  0.3884],\n",
       "          [-0.0156, -0.1790,  0.0197,  ...,  0.1377,  0.1793,  0.0707],\n",
       "          ...,\n",
       "          [ 0.1065, -0.0729,  0.3501,  ...,  0.0782,  0.2541,  0.1387],\n",
       "          [-0.0016,  0.2365, -0.1191,  ...,  0.0786, -0.1600,  0.2580],\n",
       "          [ 0.1129, -0.1474,  0.0665,  ...,  0.2391,  0.0589,  0.1002]]]],\n",
       "       device='cuda:0', grad_fn=<PermuteBackward0>)), (tensor([[[[ 0.0264,  1.6070, -1.3598,  ...,  1.0285, -0.7336,  1.3647],\n",
       "          [ 0.5799,  0.9280, -0.5876,  ..., -0.4643, -0.9049, -0.1461],\n",
       "          [ 0.6168,  1.1800, -0.8385,  ..., -0.0534, -1.6730,  0.0263],\n",
       "          ...,\n",
       "          [-1.2529,  0.3951,  1.0617,  ...,  0.7415, -1.5227, -0.6784],\n",
       "          [-1.0871,  0.9250,  1.2833,  ...,  0.5607, -0.3060, -0.6851],\n",
       "          [-1.5044, -0.4108,  2.8460,  ...,  1.3354, -2.0532, -1.7012]],\n",
       "\n",
       "         [[-1.1833, -0.9784, -0.1507,  ..., -0.4343,  0.6817, -0.4813],\n",
       "          [-0.3535,  0.3769, -0.2104,  ..., -0.6011, -0.2199, -0.1313],\n",
       "          [-0.7930,  1.1303, -0.7943,  ..., -0.8589, -0.3079,  0.2013],\n",
       "          ...,\n",
       "          [ 0.4594,  1.4230, -2.1283,  ..., -0.1442, -0.8521, -0.9140],\n",
       "          [-0.4307,  1.9260, -2.1981,  ...,  0.2702, -1.8982, -0.6463],\n",
       "          [-0.7730,  0.0725, -2.3191,  ...,  0.9225, -2.3243,  0.1465]],\n",
       "\n",
       "         [[ 0.1367, -0.0176, -0.0344,  ..., -0.9486,  0.1594, -0.0186],\n",
       "          [-0.1735,  0.0824, -0.0261,  ..., -0.6443, -0.2416,  0.1461],\n",
       "          [ 0.1143,  0.0660, -0.0446,  ..., -0.7896,  0.0592,  0.1514],\n",
       "          ...,\n",
       "          [-0.1066, -0.0762,  0.1305,  ..., -0.4486,  0.1023,  0.0630],\n",
       "          [-0.4509,  0.0520,  0.0628,  ..., -0.5313,  0.0274,  0.3564],\n",
       "          [-0.4270, -0.0294, -0.3297,  ..., -0.4022, -0.0728,  0.3086]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.2418, -0.1362, -0.5449,  ..., -0.3621,  0.3883, -0.6006],\n",
       "          [-0.9853,  1.0303,  1.3352,  ...,  0.3267, -1.9134,  0.8039],\n",
       "          [ 0.3806, -0.1967,  1.1572,  ..., -0.7151, -0.3842,  0.7042],\n",
       "          ...,\n",
       "          [ 2.0098, -1.6095,  1.5421,  ...,  0.7165,  0.1206, -0.9411],\n",
       "          [ 0.9453,  0.7150,  1.1043,  ...,  1.4112,  1.6639,  0.1390],\n",
       "          [ 1.5487, -1.9690,  1.6582,  ..., -0.1922, -0.3365, -0.6021]],\n",
       "\n",
       "         [[-0.8930, -2.5253,  0.2164,  ...,  1.6279,  1.4559, -1.4507],\n",
       "          [ 0.1382,  0.5931, -0.4466,  ..., -0.6541,  0.3486,  0.3197],\n",
       "          [ 0.1332,  0.3251, -0.6549,  ..., -0.5474,  0.4562, -0.0709],\n",
       "          ...,\n",
       "          [-0.3312,  0.2928, -0.7062,  ..., -0.8046,  1.1975,  0.6997],\n",
       "          [-0.6501,  0.8902, -0.7281,  ..., -0.2511,  0.9270,  0.7117],\n",
       "          [-0.4880,  0.2267, -0.7143,  ...,  0.0120,  1.2673,  0.5069]],\n",
       "\n",
       "         [[ 0.6973,  1.6856,  0.4155,  ..., -1.0832, -0.0126,  0.1515],\n",
       "          [-0.1326,  1.1586,  0.0764,  ..., -0.5080,  0.2095, -0.1227],\n",
       "          [ 0.9098,  1.2976,  0.6704,  ...,  0.8165, -0.6834,  1.1670],\n",
       "          ...,\n",
       "          [ 0.9386,  2.4669,  0.3321,  ..., -0.7600, -0.5702, -0.4497],\n",
       "          [ 0.9809,  0.7265,  0.2406,  ...,  1.0990,  0.0773, -0.2622],\n",
       "          [ 0.0704,  2.0301,  1.0358,  ...,  1.5591, -0.6616, -0.6271]]]],\n",
       "       device='cuda:0', grad_fn=<PermuteBackward0>), tensor([[[[ 2.5648e-01,  1.8042e-01,  7.4260e-02,  ..., -2.8533e-02,\n",
       "           -1.7049e-01, -2.2196e-01],\n",
       "          [ 1.7258e-01, -6.3773e-02,  1.6278e-01,  ...,  1.3137e-02,\n",
       "            1.4308e-02, -7.3419e-02],\n",
       "          [-2.2358e-01,  2.5937e-01, -3.4108e-01,  ...,  4.1551e-01,\n",
       "           -4.0694e-01,  3.5291e-01],\n",
       "          ...,\n",
       "          [ 1.6804e-01,  2.3295e-01,  2.4170e-01,  ..., -2.1760e-01,\n",
       "           -2.2068e-01,  3.0314e-01],\n",
       "          [-3.0431e-01,  1.2327e-02,  6.1776e-01,  ..., -1.9051e-01,\n",
       "           -1.6081e-01, -4.6769e-01],\n",
       "          [ 3.8817e-01, -2.7174e-01,  1.1641e-01,  ..., -5.5302e-01,\n",
       "           -1.4844e-01, -7.1275e-01]],\n",
       "\n",
       "         [[ 8.7724e-02,  1.0590e-02,  3.3847e-02,  ..., -1.3090e-01,\n",
       "           -7.0346e-02,  1.0617e-01],\n",
       "          [ 2.1453e-01,  1.0732e-01,  1.2551e-01,  ...,  6.4013e-02,\n",
       "            1.4904e-01, -2.0000e-01],\n",
       "          [-6.6709e-02,  2.0006e-03,  1.6584e-01,  ...,  6.4318e-02,\n",
       "            2.5180e-01,  8.1402e-01],\n",
       "          ...,\n",
       "          [ 8.9405e-01,  8.6779e-02, -7.9537e-03,  ..., -9.6191e-01,\n",
       "           -1.7539e-02, -1.0715e-02],\n",
       "          [-4.9468e-02,  9.2011e-01, -6.7381e-02,  ...,  5.2180e-01,\n",
       "           -1.8519e-01,  2.8750e-01],\n",
       "          [ 8.4201e-01,  2.9632e-01,  2.8910e-01,  ...,  4.3946e-01,\n",
       "            6.2146e-01, -3.1281e-01]],\n",
       "\n",
       "         [[-1.2948e-01, -5.4070e-02,  1.8643e-01,  ..., -5.0071e-01,\n",
       "            2.4738e-02, -9.5170e-02],\n",
       "          [ 1.8113e-01, -1.0272e-01,  2.2109e-01,  ..., -3.5989e-01,\n",
       "           -5.0203e-02, -1.3107e-01],\n",
       "          [ 4.6299e-01,  6.6027e-03, -6.3111e-02,  ..., -6.5337e-01,\n",
       "           -8.1596e-02,  3.3318e-01],\n",
       "          ...,\n",
       "          [ 2.4127e-01,  3.1313e-01,  1.8944e-01,  ...,  5.4602e-01,\n",
       "            2.5952e-01, -1.7358e-01],\n",
       "          [ 7.3931e-02, -1.1542e-02, -3.5419e-01,  ...,  5.4639e-01,\n",
       "            2.8685e-01, -1.4808e-02],\n",
       "          [ 9.4727e-02,  2.6694e-01,  5.3107e-01,  ...,  6.3430e-01,\n",
       "           -6.3883e-02, -3.0911e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.2535e-03,  3.0946e-01, -1.5115e-02,  ..., -1.3393e-01,\n",
       "           -8.9087e-01, -1.0315e-01],\n",
       "          [-1.9617e-01, -8.6230e-01,  1.0564e-01,  ..., -4.4739e-01,\n",
       "           -4.0937e-01, -1.6588e-01],\n",
       "          [-3.2402e-01,  1.9108e-01,  2.4344e-01,  ..., -2.6970e-02,\n",
       "           -2.2377e-01, -9.3684e-02],\n",
       "          ...,\n",
       "          [-4.0293e-02, -4.6469e-01,  1.4626e-02,  ..., -7.5400e-02,\n",
       "           -1.7213e-01, -1.9927e-01],\n",
       "          [-7.7598e-01,  9.6259e-02,  2.5940e-01,  ...,  4.7957e-01,\n",
       "           -3.9567e-02, -4.9545e-01],\n",
       "          [ 1.5511e-02,  7.0599e-02, -1.2845e-01,  ...,  2.7811e-01,\n",
       "           -1.2594e-01, -4.3473e-01]],\n",
       "\n",
       "         [[ 2.1805e-01, -1.2601e-01,  9.6698e-03,  ...,  3.4453e-01,\n",
       "           -2.7822e+00, -2.7843e-01],\n",
       "          [ 2.4150e-01, -9.3690e-02,  7.9056e-01,  ..., -1.9297e-01,\n",
       "            3.6339e-01, -4.1727e-01],\n",
       "          [-2.1065e-01,  1.4282e-02,  6.7793e-02,  ..., -2.1820e-01,\n",
       "           -1.2495e-02, -3.5364e-01],\n",
       "          ...,\n",
       "          [ 2.4128e-01,  6.0968e-01, -1.8046e-01,  ..., -9.3071e-02,\n",
       "           -1.1879e-01, -1.6017e-01],\n",
       "          [ 3.9324e-01,  1.1017e-01, -4.1523e-02,  ..., -1.0274e-01,\n",
       "           -4.0915e-01,  2.9267e-01],\n",
       "          [ 4.5006e-01,  2.5402e-01,  1.3110e-01,  ...,  1.3367e-01,\n",
       "           -1.8600e-01, -2.2297e-01]],\n",
       "\n",
       "         [[ 1.5106e-01, -8.9231e-02,  5.4383e-02,  ..., -1.4270e-01,\n",
       "            2.7497e-01, -1.8535e-01],\n",
       "          [ 1.3056e-01, -2.6533e-02,  4.4511e-01,  ..., -1.1697e-01,\n",
       "            2.9667e-01, -2.0837e-01],\n",
       "          [-6.1207e-02, -9.5059e-02, -1.2494e-01,  ..., -2.1687e-01,\n",
       "            1.2216e-01,  6.3034e-02],\n",
       "          ...,\n",
       "          [-6.4190e-02,  2.3823e-01, -1.2938e-01,  ..., -3.0316e-02,\n",
       "           -1.3452e-01,  1.5983e-01],\n",
       "          [-5.0427e-02,  3.8609e-01,  1.5445e-01,  ..., -1.2500e-01,\n",
       "           -3.7161e-02, -9.3546e-02],\n",
       "          [ 3.9119e-01, -1.6262e-01,  7.8414e-02,  ...,  5.7470e-02,\n",
       "           -7.5112e-02, -1.8433e-01]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[-1.5028e-01, -1.2573e+00,  3.8984e-01,  ..., -6.5062e-01,\n",
       "            2.3107e-03,  1.0066e-01],\n",
       "          [ 3.2048e-01, -1.9416e+00,  1.1034e-01,  ..., -7.2924e-02,\n",
       "           -1.9806e-01, -1.7304e-01],\n",
       "          [ 1.8474e-01, -8.5224e-01, -4.9338e-01,  ..., -4.3706e-01,\n",
       "           -4.8154e-01, -5.6099e-01],\n",
       "          ...,\n",
       "          [-2.3635e-01, -7.5673e-02,  7.3575e-01,  ...,  1.6449e+00,\n",
       "            2.5364e-01,  5.8964e-02],\n",
       "          [-4.7844e-01, -2.0116e+00, -2.3463e-01,  ..., -2.6495e-01,\n",
       "            5.2161e-01,  1.6082e+00],\n",
       "          [-1.1308e-01, -1.1554e+00, -7.1182e-01,  ...,  9.9116e-01,\n",
       "            2.6742e-01,  1.7426e+00]],\n",
       "\n",
       "         [[-5.2495e-01,  4.8920e-01, -3.4092e-01,  ...,  1.0757e+00,\n",
       "           -6.0921e-01, -5.4653e-01],\n",
       "          [-1.3025e+00, -8.5876e-01, -7.1716e-01,  ..., -1.8806e-01,\n",
       "            4.3098e-01, -4.8368e-01],\n",
       "          [-6.1140e-01, -6.7692e-01,  1.6490e-01,  ..., -2.5253e-01,\n",
       "            4.9560e-01,  4.8844e-01],\n",
       "          ...,\n",
       "          [-3.6770e-02,  1.1126e+00, -1.5627e+00,  ...,  9.8144e-02,\n",
       "            1.0359e+00, -1.1237e-01],\n",
       "          [-1.3439e-01,  4.7272e-01, -1.8711e+00,  ..., -6.2682e-01,\n",
       "            6.7622e-01, -7.3442e-01],\n",
       "          [-7.3128e-01, -4.1476e-01, -1.6784e+00,  ...,  2.2011e-01,\n",
       "            7.4970e-01, -1.1074e+00]],\n",
       "\n",
       "         [[ 1.0294e+00,  2.9702e+00,  3.2573e+00,  ...,  6.8333e-01,\n",
       "            1.5467e+00, -1.0296e+00],\n",
       "          [-2.7730e+00,  8.3254e-01, -2.5434e+00,  ..., -1.8021e+00,\n",
       "            3.0752e+00,  2.4495e-02],\n",
       "          [-2.7469e+00, -5.1561e-01, -2.7319e+00,  ..., -3.2412e+00,\n",
       "            3.1357e+00,  4.2090e-01],\n",
       "          ...,\n",
       "          [-3.8323e+00, -3.0154e+00, -2.9731e+00,  ..., -2.8199e+00,\n",
       "            1.1238e+00,  1.0780e+00],\n",
       "          [-2.6334e+00, -3.8440e+00, -2.7107e+00,  ..., -2.2228e+00,\n",
       "            1.0278e+00,  2.2505e+00],\n",
       "          [-9.3880e-01, -3.7145e+00, -3.0877e+00,  ..., -3.8706e+00,\n",
       "            2.4650e+00,  8.4938e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.2173e+00, -2.3900e+00, -2.3826e+00,  ...,  9.8032e-01,\n",
       "            3.1857e-01,  2.5068e+00],\n",
       "          [-2.0807e+00,  1.8556e+00,  5.9296e-01,  ...,  3.5252e-02,\n",
       "           -1.5874e+00, -2.8508e-01],\n",
       "          [-2.3445e+00,  1.5207e+00,  7.9669e-01,  ...,  1.9894e-01,\n",
       "           -1.7064e+00, -1.6657e-01],\n",
       "          ...,\n",
       "          [-2.7147e+00,  4.4860e+00,  2.6488e+00,  ..., -1.8987e+00,\n",
       "           -3.3619e+00, -2.4925e+00],\n",
       "          [-3.1593e+00,  3.6590e+00,  2.0052e+00,  ..., -1.8279e+00,\n",
       "           -3.3981e+00, -3.0485e+00],\n",
       "          [-3.4492e+00,  4.5089e+00,  3.3710e+00,  ..., -7.5270e-01,\n",
       "           -2.2396e+00, -2.1703e+00]],\n",
       "\n",
       "         [[ 1.4356e+00,  4.8466e-01,  8.6465e-01,  ...,  9.9528e-03,\n",
       "           -6.8405e-01, -3.6284e-01],\n",
       "          [ 1.2910e+00,  4.7464e-01,  7.1452e-01,  ...,  5.2484e-01,\n",
       "           -2.9043e-01, -1.0093e+00],\n",
       "          [ 1.2049e+00,  3.5862e-01,  8.5139e-01,  ...,  9.6753e-02,\n",
       "           -8.0453e-01, -8.8311e-01],\n",
       "          ...,\n",
       "          [ 1.2520e+00,  2.0976e-01,  4.9444e-01,  ..., -4.5051e-01,\n",
       "           -1.5545e+00, -4.7004e-01],\n",
       "          [ 1.6363e+00,  5.9717e-02,  2.6171e-01,  ...,  1.4817e-01,\n",
       "           -2.6526e-01,  3.1770e-01],\n",
       "          [ 1.8311e+00, -1.0690e-03,  4.3851e-01,  ...,  4.2467e-01,\n",
       "           -1.6757e+00, -4.7380e-01]],\n",
       "\n",
       "         [[-2.8021e-01,  1.1031e-01, -6.9883e-01,  ...,  3.4148e-01,\n",
       "            3.4657e-01,  3.4493e-01],\n",
       "          [-8.4474e-01, -1.3965e-02, -4.6235e-01,  ...,  3.6767e-01,\n",
       "            4.7452e-01,  5.3764e-01],\n",
       "          [ 9.6175e-02,  1.8447e-01, -7.3913e-01,  ...,  1.0569e-01,\n",
       "            2.2062e-01,  4.3851e-01],\n",
       "          ...,\n",
       "          [ 1.4750e+00, -3.8273e-01, -3.8838e-01,  ...,  1.0873e-01,\n",
       "            5.2054e-01,  6.0020e-01],\n",
       "          [-1.0047e+00, -3.8809e-01, -3.1732e-01,  ...,  3.1362e-01,\n",
       "            6.2896e-01,  3.8098e-01],\n",
       "          [ 3.4324e-01, -2.0902e-01, -6.8091e-01,  ..., -6.4022e-02,\n",
       "            7.4529e-01,  2.1407e-01]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[-4.5773e-02,  1.5312e-02, -1.7873e-01,  ..., -9.5605e-02,\n",
       "            1.3617e-02, -6.4353e-01],\n",
       "          [ 3.0430e-01,  7.5265e-01, -6.2020e-01,  ..., -6.4600e-02,\n",
       "            1.4013e-01, -2.1759e-01],\n",
       "          [ 2.6531e-01,  2.7049e-01, -3.3175e-02,  ..., -1.0278e-02,\n",
       "            1.1628e-01,  2.7244e-01],\n",
       "          ...,\n",
       "          [ 9.2925e-03,  1.7527e-01, -1.8353e-01,  ...,  3.0274e-02,\n",
       "           -3.0006e-01,  3.4235e-01],\n",
       "          [-6.8181e-02, -1.2293e+00,  5.2933e-01,  ..., -3.8426e-01,\n",
       "            9.1415e-01,  3.9187e-01],\n",
       "          [ 9.0316e-01, -3.2168e-01,  3.2674e-01,  ...,  6.1106e-01,\n",
       "           -7.1257e-01, -2.1477e-01]],\n",
       "\n",
       "         [[ 5.9584e-03, -1.2852e-02,  2.3768e-02,  ...,  3.5301e-02,\n",
       "            2.2559e-02,  6.5780e-04],\n",
       "          [ 6.5509e-02,  2.5582e-01,  1.3689e-01,  ...,  1.4659e-01,\n",
       "           -5.9529e-02,  1.7478e-01],\n",
       "          [-5.1708e-02, -3.1805e-02,  1.1132e-01,  ...,  1.7759e-01,\n",
       "            2.7625e-01, -3.1351e-04],\n",
       "          ...,\n",
       "          [-1.2871e-01,  2.4950e-01, -2.0210e-01,  ...,  1.6748e-01,\n",
       "            1.0383e-01,  6.8394e-02],\n",
       "          [ 3.2066e-02,  3.3434e-01,  8.5797e-02,  ...,  2.0788e-01,\n",
       "            7.3799e-01, -4.3131e-01],\n",
       "          [-4.5602e-02, -4.3923e-01,  3.3035e-02,  ..., -3.0616e-01,\n",
       "            6.7190e-01, -4.4627e-01]],\n",
       "\n",
       "         [[ 9.1561e-02, -9.2142e-01, -5.4217e-03,  ...,  2.0044e-02,\n",
       "            2.1656e-02, -4.6488e-02],\n",
       "          [-1.2416e-03, -8.1114e-01,  1.4386e-02,  ...,  8.2425e-02,\n",
       "            4.5030e-03, -8.7687e-02],\n",
       "          [-1.8596e-01, -1.0593e+00, -1.8351e-02,  ...,  4.8312e-01,\n",
       "            2.8864e-02,  4.3763e-01],\n",
       "          ...,\n",
       "          [-5.1369e-01, -6.5822e-01, -5.4002e-01,  ..., -5.3425e-01,\n",
       "            4.6756e-02, -9.3715e-02],\n",
       "          [ 5.9994e-01, -1.7033e+00, -2.6492e-01,  ...,  2.7891e-01,\n",
       "           -6.4484e-02,  2.5962e-01],\n",
       "          [ 5.6732e-01, -1.1766e+00, -5.0773e-02,  ...,  5.3240e-01,\n",
       "           -5.8008e-01, -2.6174e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-5.9628e-02, -1.0636e-01,  1.5100e+00,  ..., -4.7289e-02,\n",
       "            1.9479e-01,  9.6400e-02],\n",
       "          [-1.3491e-02, -1.3643e-01,  1.7242e+00,  ...,  2.4679e-02,\n",
       "            7.1097e-02,  2.7233e-01],\n",
       "          [ 7.1882e-01,  4.5446e-01,  1.9988e+00,  ..., -1.2642e-01,\n",
       "            3.9528e-02, -3.3705e-02],\n",
       "          ...,\n",
       "          [-5.2185e-01,  3.1272e-01,  2.2864e+00,  ...,  1.0126e-01,\n",
       "           -3.5675e-01,  3.2413e-02],\n",
       "          [ 9.3450e-02, -3.4622e-01,  1.0696e+00,  ..., -1.6573e-01,\n",
       "           -7.2882e-02, -5.0589e-02],\n",
       "          [-2.4618e-01, -2.5642e-01,  1.9631e+00,  ..., -3.4110e-01,\n",
       "            1.4968e-01, -4.9283e-01]],\n",
       "\n",
       "         [[-8.4839e-02,  7.2570e-02, -1.5279e-01,  ..., -4.0045e-02,\n",
       "            9.5255e-02,  2.4219e-01],\n",
       "          [-8.5648e-01,  1.0369e+00,  4.0873e-01,  ..., -1.6662e-01,\n",
       "            7.2142e-02, -9.9685e-02],\n",
       "          [ 5.2418e-02,  6.5557e-02,  1.1180e-01,  ...,  2.8867e-01,\n",
       "           -2.5199e-01, -2.1195e-01],\n",
       "          ...,\n",
       "          [-5.0020e-01,  7.1284e-02,  6.1340e-01,  ...,  1.0013e+00,\n",
       "           -1.5522e-01, -6.3086e-01],\n",
       "          [ 4.6245e-01, -2.7737e-02,  5.4812e-01,  ...,  1.8846e-01,\n",
       "           -3.8442e-02, -2.2834e-02],\n",
       "          [-6.4406e-02,  6.5020e-01, -6.7211e-01,  ..., -6.3385e-02,\n",
       "            6.1224e-01,  1.0848e+00]],\n",
       "\n",
       "         [[-1.7838e-02,  7.4970e-02,  8.9196e-02,  ...,  1.3366e-02,\n",
       "            2.6077e-01, -2.0640e-02],\n",
       "          [-4.0540e-01, -5.5924e-02, -1.9258e-01,  ..., -1.9606e-01,\n",
       "           -1.0364e+00,  2.5853e-01],\n",
       "          [ 6.7627e-03, -2.9922e-01, -2.1357e-02,  ..., -1.3588e-01,\n",
       "           -1.5130e+00, -5.0325e-02],\n",
       "          ...,\n",
       "          [-1.4101e-01,  1.6672e-01,  6.9276e-02,  ...,  3.5731e-01,\n",
       "           -1.4280e+00, -2.1629e-01],\n",
       "          [ 2.3542e-01, -2.1355e-01, -6.9453e-01,  ..., -1.9706e-01,\n",
       "           -1.6304e+00, -8.9069e-01],\n",
       "          [-2.3135e-01, -3.0080e-01, -1.9450e-01,  ...,  4.1743e-01,\n",
       "           -1.4891e+00,  2.3966e-02]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[-0.0445, -0.1732,  0.1433,  ..., -0.8417,  0.5741, -0.9736],\n",
       "          [-1.1265, -0.8775, -0.0712,  ...,  0.6601, -0.4741, -0.6545],\n",
       "          [-0.4411,  0.7619, -1.4127,  ..., -0.1589, -1.3424,  1.7820],\n",
       "          ...,\n",
       "          [-0.2345, -0.2382, -0.0502,  ...,  1.1105, -0.3038,  0.8963],\n",
       "          [-0.9513, -0.2728,  0.4664,  ...,  0.6708, -0.5036,  2.3770],\n",
       "          [ 0.2713,  0.2616,  3.1454,  ..., -1.3161,  0.4158, -1.9686]],\n",
       "\n",
       "         [[ 0.7936,  0.1896, -0.0368,  ..., -0.1664, -1.0298, -0.1360],\n",
       "          [-0.7983, -1.3380, -1.2100,  ..., -0.2251,  3.2815,  2.0676],\n",
       "          [-0.6055, -1.1426, -0.8645,  ...,  0.5416,  5.1064,  1.4226],\n",
       "          ...,\n",
       "          [ 1.2395,  0.1238, -0.4556,  ..., -0.0304,  4.9970,  1.5094],\n",
       "          [ 1.2057,  1.1528, -0.4268,  ...,  0.1199,  4.4609,  0.9988],\n",
       "          [-1.4474,  0.0316, -0.4298,  ...,  1.0934,  2.9182, -0.9202]],\n",
       "\n",
       "         [[ 0.4372, -0.3605, -0.4240,  ...,  0.2929,  1.2889,  0.2960],\n",
       "          [-0.3895, -5.4025, -0.1113,  ..., -3.0232, -3.6669, -6.2828],\n",
       "          [-0.1608, -5.5462, -1.2650,  ..., -2.1021, -3.6281, -5.5311],\n",
       "          ...,\n",
       "          [-4.3580, -4.4129, -2.3035,  ..., -0.6905, -2.9552, -2.9318],\n",
       "          [-4.6971, -3.5403, -2.5549,  ..., -3.1455, -3.8185, -2.9296],\n",
       "          [-6.0150, -3.1827, -2.3115,  ..., -2.4671, -4.8162, -1.9092]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.1671,  1.7286,  0.4651,  ...,  0.1690,  0.3875, -1.3718],\n",
       "          [ 0.6924, -6.6042, -0.1578,  ..., -1.6872, -1.0313,  6.0350],\n",
       "          [-0.4899, -6.2238,  0.9068,  ..., -1.5398, -0.6905,  5.1511],\n",
       "          ...,\n",
       "          [ 0.5997, -5.0424, -0.4115,  ..., -3.3534, -3.8700,  6.5053],\n",
       "          [ 1.3103, -4.4278, -1.6812,  ..., -1.7889, -4.1748,  5.3079],\n",
       "          [ 0.0141, -5.2118, -1.4192,  ..., -2.2584, -1.9013,  5.8625]],\n",
       "\n",
       "         [[ 0.0731,  0.0137,  0.0860,  ..., -0.0897, -0.0516, -0.1223],\n",
       "          [-0.0769, -0.6908,  0.8271,  ...,  0.0351, -0.6309, -0.3521],\n",
       "          [-0.0395, -1.4319, -0.3336,  ...,  0.7169, -0.5604, -1.1322],\n",
       "          ...,\n",
       "          [-0.2395, -0.8231, -0.4184,  ...,  0.1113, -0.0143,  0.0979],\n",
       "          [ 0.2475, -0.3188, -1.0765,  ...,  0.0303, -0.0856, -0.0477],\n",
       "          [-0.0096,  0.3228, -0.0336,  ..., -0.3775,  0.1945,  0.5208]],\n",
       "\n",
       "         [[ 0.5052, -0.0414,  1.7121,  ..., -0.0885, -0.2402, -0.8461],\n",
       "          [ 1.5529,  1.1378, -4.0282,  ...,  0.0297,  0.4491,  3.6040],\n",
       "          [ 2.0955,  1.0104, -3.1706,  ...,  0.4620,  1.5717,  2.7603],\n",
       "          ...,\n",
       "          [-0.0932,  0.7036, -2.1452,  ..., -0.8211,  0.9730,  4.2033],\n",
       "          [ 0.8084, -0.4517, -1.8466,  ...,  0.0212,  0.0430,  4.5149],\n",
       "          [ 1.0315, -0.1052, -2.4650,  ..., -0.3019,  0.3305,  4.8601]]]],\n",
       "       device='cuda:0', grad_fn=<PermuteBackward0>), tensor([[[[ 3.3733e-02,  6.6012e-02,  1.6378e-02,  ...,  1.3302e-02,\n",
       "            4.8453e-02,  4.4001e-02],\n",
       "          [ 1.5891e-01,  3.1930e-01, -3.4281e-02,  ..., -2.4023e-01,\n",
       "            3.5412e-01, -2.4972e-02],\n",
       "          [-3.0374e-01, -4.7954e-01, -1.6503e-01,  ...,  8.7491e-02,\n",
       "           -8.3495e-02, -6.2058e-01],\n",
       "          ...,\n",
       "          [-3.6239e-01, -4.5833e-01, -7.1702e-01,  ...,  3.8925e-03,\n",
       "           -5.0935e-01,  2.0162e+00],\n",
       "          [ 1.6983e-01,  2.1001e-01, -2.8838e-03,  ...,  4.6965e-01,\n",
       "           -7.9713e-01,  4.2167e-01],\n",
       "          [ 6.5809e-01,  1.4029e-01, -4.7291e-01,  ...,  4.9714e-01,\n",
       "           -4.2475e-01,  9.1861e-01]],\n",
       "\n",
       "         [[-5.5499e-02, -1.1553e-02,  2.5362e-02,  ..., -5.0444e-02,\n",
       "           -4.4869e-02, -4.4578e-02],\n",
       "          [-4.0359e-01, -1.4406e-01, -2.1452e-01,  ..., -1.4276e-01,\n",
       "           -1.8613e-01,  1.4247e-01],\n",
       "          [ 2.7743e-01, -4.1466e-01,  2.2531e-01,  ...,  8.7252e-03,\n",
       "            2.0588e-01, -1.2202e-01],\n",
       "          ...,\n",
       "          [ 3.7603e-01,  2.3680e-01, -7.8820e-01,  ..., -1.1786e-02,\n",
       "           -5.1706e-01, -6.8942e-01],\n",
       "          [ 1.1261e-01, -4.7503e-01, -1.0802e+00,  ...,  1.8876e-01,\n",
       "            6.5399e-01, -2.0537e-01],\n",
       "          [ 3.4017e-01,  8.9463e-01, -8.5010e-01,  ...,  3.5150e-01,\n",
       "           -1.6857e-01, -6.8763e-01]],\n",
       "\n",
       "         [[ 1.7374e-02, -1.1135e-01, -4.8204e-02,  ..., -2.0336e-02,\n",
       "            5.0044e-02, -1.1479e-01],\n",
       "          [-2.7060e-01, -2.2818e-01,  4.0767e-02,  ..., -3.3700e-02,\n",
       "           -3.6734e-01,  1.8535e-01],\n",
       "          [-1.5032e-01, -6.2369e-02,  1.3662e+00,  ...,  2.4094e-01,\n",
       "            1.3030e-01, -1.3609e-01],\n",
       "          ...,\n",
       "          [ 4.9658e-01,  6.4447e-01, -4.2880e-01,  ..., -2.9902e-01,\n",
       "            6.9756e-01,  4.6350e-01],\n",
       "          [ 2.8800e-01,  1.3811e-01, -3.0088e-03,  ...,  2.2692e-01,\n",
       "           -3.4284e-01,  2.5572e-02],\n",
       "          [ 7.1157e-01,  1.3887e-01, -1.0990e+00,  ..., -3.9425e-01,\n",
       "           -1.2867e-01,  8.9076e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-4.3662e-03,  1.0092e-01, -1.6531e-02,  ..., -3.8738e-02,\n",
       "            3.1914e-02, -2.9104e-02],\n",
       "          [-2.3493e-01,  1.0163e-01, -9.4827e-02,  ..., -2.2074e-01,\n",
       "           -3.0056e-01,  6.5726e-02],\n",
       "          [ 4.3532e-02,  1.4715e-01, -6.1695e-02,  ...,  1.4896e-01,\n",
       "           -6.7345e-02,  1.0329e-01],\n",
       "          ...,\n",
       "          [ 2.8772e-02, -1.1140e-02,  1.8503e-01,  ..., -8.6666e-02,\n",
       "           -3.3609e-02, -1.3415e-01],\n",
       "          [ 1.0941e-01,  3.5161e-01, -2.4857e-01,  ..., -2.9885e-01,\n",
       "            2.1331e-01,  5.0402e-01],\n",
       "          [-1.5718e-03,  6.6608e-03,  7.5783e-01,  ...,  1.7732e-01,\n",
       "           -7.2552e-01, -1.1387e-01]],\n",
       "\n",
       "         [[-1.4882e-01, -1.1970e-01, -7.2217e-02,  ..., -2.1012e-01,\n",
       "           -5.3921e-02, -3.7135e-02],\n",
       "          [ 7.0431e-02,  8.3100e-02, -3.9138e-01,  ...,  6.9840e-01,\n",
       "            2.4757e-01,  4.7626e-02],\n",
       "          [ 7.5981e-02, -3.6651e-01,  2.7886e-02,  ...,  3.5553e-01,\n",
       "            8.2319e-01, -3.9667e-01],\n",
       "          ...,\n",
       "          [ 1.4828e+00,  1.8298e-01, -2.8312e-01,  ..., -7.9125e-01,\n",
       "           -1.7318e-01,  4.5868e-03],\n",
       "          [ 5.5531e-01,  4.7252e-01,  2.2221e-01,  ..., -3.4483e-01,\n",
       "            9.6402e-02,  8.8199e-02],\n",
       "          [ 7.2912e-01, -3.4486e-01, -2.3933e-02,  ...,  2.7319e-01,\n",
       "            1.0029e-01,  2.4822e-01]],\n",
       "\n",
       "         [[ 8.0465e-02, -2.5372e-02, -3.2156e-02,  ...,  1.2344e-02,\n",
       "           -7.1664e-02, -8.7208e-02],\n",
       "          [ 1.2070e-01,  1.9788e-01,  2.0074e-01,  ...,  1.3984e-01,\n",
       "            3.2800e-01, -1.1719e-01],\n",
       "          [ 1.3108e-01, -5.8355e-02, -1.4033e+00,  ..., -6.5388e-02,\n",
       "           -2.2900e-02,  2.7584e-01],\n",
       "          ...,\n",
       "          [ 2.4987e-01, -5.0051e-01,  3.7352e-02,  ..., -4.4063e-01,\n",
       "            8.4591e-02, -1.4338e-01],\n",
       "          [-4.2718e-01,  8.0369e-03,  8.7239e-01,  ..., -1.7318e-01,\n",
       "            2.7435e-01, -4.8682e-01],\n",
       "          [-4.6683e-02, -1.6957e-01, -8.6528e-02,  ..., -4.9601e-01,\n",
       "            3.4217e-01, -4.9665e-01]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[-7.5082e-01, -2.3918e-01,  3.2216e-01,  ..., -1.0383e+00,\n",
       "           -3.4044e-02, -2.8495e+00],\n",
       "          [ 2.2163e+00,  3.8017e-01, -2.7861e+00,  ..., -1.8368e+00,\n",
       "           -2.3042e+00,  9.1328e+00],\n",
       "          [ 2.4335e+00,  4.3201e-01, -1.8341e+00,  ..., -2.4225e+00,\n",
       "           -3.3043e+00,  8.3541e+00],\n",
       "          ...,\n",
       "          [ 2.6959e-01, -2.8727e+00,  9.0950e-01,  ...,  6.3065e-01,\n",
       "           -2.6118e+00,  6.8908e+00],\n",
       "          [-3.9501e-01, -1.6066e-01, -2.3003e+00,  ...,  6.2951e-01,\n",
       "           -5.4489e-01,  7.9849e+00],\n",
       "          [-1.0793e+00, -1.5838e+00, -2.2592e+00,  ..., -2.2888e-02,\n",
       "           -1.3322e+00,  8.7666e+00]],\n",
       "\n",
       "         [[ 3.1238e-01, -1.4696e-01,  4.9636e-01,  ..., -1.3897e-01,\n",
       "           -1.4884e-01, -1.9907e+00],\n",
       "          [-9.3001e-01,  1.1153e+00,  2.0952e+00,  ...,  7.2824e-01,\n",
       "           -2.8254e-02,  7.5361e+00],\n",
       "          [-1.3606e+00, -7.3180e-01,  2.4763e+00,  ..., -2.0710e-01,\n",
       "           -7.6466e-01,  6.5242e+00],\n",
       "          ...,\n",
       "          [-1.3611e+00, -9.5596e-01,  2.6358e+00,  ..., -1.2263e+00,\n",
       "           -2.4827e-01,  3.4555e+00],\n",
       "          [-2.7452e+00, -4.6643e-01,  2.3355e+00,  ..., -1.0588e+00,\n",
       "            4.7443e-01,  3.1850e+00],\n",
       "          [ 2.3440e-01,  5.0387e-01,  1.5756e+00,  ...,  1.2388e+00,\n",
       "           -1.3404e+00,  2.5325e+00]],\n",
       "\n",
       "         [[ 1.0076e-01, -5.9661e-01, -2.0160e-01,  ...,  1.2367e-01,\n",
       "            2.6615e-01, -2.0257e-01],\n",
       "          [ 3.8539e-01,  1.6449e+00,  4.8919e-01,  ...,  3.6195e-01,\n",
       "            5.1179e-01, -1.3867e+00],\n",
       "          [-7.5750e-01,  1.8272e+00, -3.1122e-02,  ..., -2.9052e-01,\n",
       "           -1.4626e-01,  3.0877e-02],\n",
       "          ...,\n",
       "          [ 7.5688e-01,  2.2956e+00,  3.8608e-01,  ..., -8.0571e-01,\n",
       "            1.0755e-01,  9.0155e-01],\n",
       "          [ 1.3011e+00,  8.9241e-01, -9.0363e-01,  ..., -1.2788e+00,\n",
       "            1.7174e+00,  6.5413e-01],\n",
       "          [-5.3658e-01,  1.5515e+00, -4.1949e-01,  ..., -2.8350e-01,\n",
       "            6.4557e-01,  1.1334e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-3.5032e-01, -2.8345e-02,  2.3919e-02,  ...,  1.1191e+00,\n",
       "            6.5258e-03,  1.6623e+00],\n",
       "          [ 7.5628e-01, -6.9727e-01, -1.2533e+00,  ..., -5.1757e+00,\n",
       "           -1.3228e+00, -2.0802e+00],\n",
       "          [ 8.3789e-01, -1.8562e-01,  7.4441e-02,  ..., -3.6968e+00,\n",
       "           -2.2579e-03, -1.9339e+00],\n",
       "          ...,\n",
       "          [ 1.1727e+00,  1.3474e+00,  5.5748e-01,  ..., -2.7368e+00,\n",
       "            2.4165e-02, -5.7410e-01],\n",
       "          [ 6.8052e-01,  1.5279e+00,  7.5630e-01,  ..., -1.0001e+00,\n",
       "           -5.3962e-01,  6.7673e-01],\n",
       "          [ 6.5439e-01,  6.4587e-01, -4.2587e-02,  ..., -3.2730e+00,\n",
       "            2.0664e-01, -4.2537e-01]],\n",
       "\n",
       "         [[-2.7857e-01, -1.1606e-01,  2.1084e-01,  ...,  2.0329e-01,\n",
       "           -2.5767e-02,  7.5833e-02],\n",
       "          [-8.7725e-01, -3.5614e-01, -4.2435e-02,  ..., -5.5870e-01,\n",
       "            3.9070e-01,  1.7531e+00],\n",
       "          [-9.2767e-01, -2.9832e-01, -6.5987e-01,  ..., -3.1950e-02,\n",
       "           -4.6064e-01,  1.9048e-01],\n",
       "          ...,\n",
       "          [ 5.4113e-01,  3.7743e-01, -1.2867e+00,  ..., -4.7462e-01,\n",
       "            1.8941e-01, -1.5637e+00],\n",
       "          [-4.5001e-01, -9.7498e-02,  2.6061e-01,  ..., -8.0481e-01,\n",
       "           -3.3231e-01, -1.0566e+00],\n",
       "          [-1.8227e-01,  6.0048e-01,  4.6443e-01,  ..., -4.8119e-01,\n",
       "           -1.5986e+00,  1.2402e+00]],\n",
       "\n",
       "         [[ 3.3919e+00,  1.4897e+00, -2.7191e+00,  ..., -2.7649e+00,\n",
       "           -4.0659e+00, -1.4586e+00],\n",
       "          [-3.0717e+00, -2.5502e+00,  3.9875e+00,  ..., -2.7199e-01,\n",
       "            1.1428e+01, -2.3410e+00],\n",
       "          [-4.9339e+00, -3.2748e+00,  2.2195e+00,  ..., -1.7633e+00,\n",
       "            1.2068e+01, -8.7374e-01],\n",
       "          ...,\n",
       "          [-3.9514e+00, -2.3005e+00,  7.2576e+00,  ..., -1.8185e+00,\n",
       "            7.6777e+00,  2.7285e-01],\n",
       "          [-2.3765e-01, -2.2040e+00,  1.0715e+01,  ...,  5.9747e-01,\n",
       "            5.5862e+00,  1.3056e+00],\n",
       "          [-3.0100e+00, -1.3479e+00,  8.0360e+00,  ...,  2.5767e+00,\n",
       "            1.0698e+01,  5.3380e-01]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[ 2.3599e-02, -2.0255e-02,  3.2086e-02,  ...,  5.2608e-02,\n",
       "            3.5070e-02,  7.1486e-02],\n",
       "          [-4.7239e-02,  1.3519e-01,  3.9259e-01,  ..., -5.0644e-02,\n",
       "            3.1967e-01,  1.2956e-02],\n",
       "          [-1.3030e-01,  9.3782e-03,  2.5804e-01,  ..., -1.4863e-01,\n",
       "            4.8173e-01,  2.3377e-01],\n",
       "          ...,\n",
       "          [-6.0358e-02,  1.5319e-01,  5.4309e-01,  ...,  2.2823e-01,\n",
       "           -4.8518e-01, -5.8641e-02],\n",
       "          [-1.5736e-01,  4.6935e-01, -3.8965e-02,  ...,  6.4282e-02,\n",
       "           -2.5121e-03,  2.6902e-01],\n",
       "          [-2.7348e-02,  9.7147e-01,  5.0009e-01,  ...,  2.3972e-01,\n",
       "            1.4259e-01, -1.0275e+00]],\n",
       "\n",
       "         [[-4.9450e-02,  3.0911e-02, -1.1652e-01,  ..., -2.8467e-02,\n",
       "            3.5315e-02,  9.1912e-03],\n",
       "          [-1.5000e-01,  2.1895e-01,  5.3990e-01,  ..., -1.4040e-01,\n",
       "            4.1709e-05,  2.7697e-01],\n",
       "          [-2.5668e-01,  5.2249e-01, -7.0404e-02,  ...,  2.1387e-01,\n",
       "            3.5178e-01,  1.6200e-01],\n",
       "          ...,\n",
       "          [-2.6046e-01, -8.4009e-03,  2.5444e-01,  ..., -2.4751e-02,\n",
       "            2.9131e-02, -4.9069e-01],\n",
       "          [-6.3026e-01,  1.2626e-01, -9.9541e-02,  ...,  1.1198e+00,\n",
       "           -5.3596e-01,  5.5749e-01],\n",
       "          [-2.7787e-01,  1.9723e-01, -1.2068e-01,  ..., -3.9889e-01,\n",
       "           -4.3301e-03, -3.2802e-02]],\n",
       "\n",
       "         [[ 4.4233e-02,  5.6652e-02,  5.6155e-02,  ...,  1.9330e-02,\n",
       "           -5.1314e-02,  3.2902e-02],\n",
       "          [ 7.0868e-01,  4.0349e-01, -1.3648e-01,  ...,  7.4399e-02,\n",
       "           -6.5978e-01,  2.0453e-01],\n",
       "          [ 8.8006e-02,  2.2971e-01, -8.9756e-02,  ..., -1.7564e-01,\n",
       "           -4.6339e-01,  1.0599e-01],\n",
       "          ...,\n",
       "          [ 1.1331e+00,  3.2651e-01, -1.3137e-01,  ..., -9.1554e-02,\n",
       "            1.3199e-03,  2.6105e-01],\n",
       "          [-1.0202e+00,  1.1463e+00,  1.1819e-01,  ...,  9.3613e-02,\n",
       "           -3.1310e-01,  6.2630e-01],\n",
       "          [ 1.7332e-01, -2.4858e-01,  1.2596e-01,  ..., -6.0141e-03,\n",
       "            6.8246e-01, -2.1596e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.8518e-02,  7.5956e-02, -6.2162e-02,  ...,  1.4098e-02,\n",
       "            2.5723e-02, -1.3595e-01],\n",
       "          [ 2.9714e-01,  1.4240e-01,  6.7918e-02,  ...,  1.1450e-01,\n",
       "           -2.5393e-01, -2.0505e-01],\n",
       "          [ 1.2973e-01,  1.6346e-02,  3.3992e-01,  ...,  5.0629e-02,\n",
       "            2.0515e-01,  2.4527e-01],\n",
       "          ...,\n",
       "          [ 1.1398e-01,  5.6268e-01, -1.6699e-02,  ...,  2.4644e-01,\n",
       "            6.4151e-01, -5.9921e-01],\n",
       "          [ 2.4357e-01, -5.5891e-01,  1.5980e-01,  ..., -5.1543e-01,\n",
       "            3.1344e-01,  2.4917e-01],\n",
       "          [ 4.2161e-01,  2.8825e-01,  2.7889e-01,  ..., -1.7157e-01,\n",
       "           -5.3255e-01, -6.2641e-04]],\n",
       "\n",
       "         [[-1.2348e-01, -4.5686e-02,  6.1339e-02,  ..., -3.2211e-02,\n",
       "            2.8631e-02, -2.8165e-02],\n",
       "          [-4.8698e-02,  1.1693e+00, -8.2036e-01,  ...,  1.8517e-01,\n",
       "           -3.9606e-01,  3.1117e-01],\n",
       "          [ 6.7750e-01,  3.9446e-01, -2.4252e-01,  ...,  6.7541e-01,\n",
       "            1.6220e-01, -1.3033e-02],\n",
       "          ...,\n",
       "          [ 3.1270e-02, -3.4561e-01, -2.1793e-02,  ..., -6.8258e-02,\n",
       "           -1.0220e-01, -8.3195e-01],\n",
       "          [ 5.6483e-01,  2.9848e-01,  1.6201e+00,  ...,  1.2882e+00,\n",
       "            2.3477e-01, -1.5526e+00],\n",
       "          [-2.8784e-01,  1.7500e-01,  1.1844e+00,  ..., -5.7531e-02,\n",
       "            5.7418e-01, -2.1995e-01]],\n",
       "\n",
       "         [[-3.6170e-03,  2.4679e-02, -2.6419e-02,  ..., -3.1119e-02,\n",
       "            1.1999e-02,  3.5070e-02],\n",
       "          [-3.6602e-02,  9.6639e-02,  1.1699e-01,  ...,  1.3329e-01,\n",
       "           -6.7894e-02,  4.8756e-01],\n",
       "          [ 2.1306e-01, -1.0771e-01, -3.2780e-01,  ..., -3.0078e-02,\n",
       "           -9.9587e-02,  1.8089e-01],\n",
       "          ...,\n",
       "          [-4.4582e-01,  4.4302e-01, -4.7381e-02,  ...,  5.6203e-01,\n",
       "           -3.6227e-01,  4.7314e-01],\n",
       "          [-1.0143e-02,  1.8780e-01, -1.9245e-01,  ...,  3.1774e-01,\n",
       "            3.7461e-01, -1.9328e-02],\n",
       "          [ 3.3521e-01,  3.3743e-02,  1.6071e+00,  ...,  8.1328e-01,\n",
       "            1.7064e-01,  7.1025e-01]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[-1.0975e-02, -2.8705e-01,  2.1533e-01,  ...,  1.4592e+00,\n",
       "           -1.7735e-01, -1.5723e-02],\n",
       "          [ 1.0639e-02,  8.1240e-01,  5.6452e-01,  ..., -1.7811e+00,\n",
       "            1.2961e+00, -6.3379e-01],\n",
       "          [-1.1005e-01,  2.3060e-02,  2.3760e-02,  ..., -2.2690e+00,\n",
       "            1.4818e-01, -3.4189e-01],\n",
       "          ...,\n",
       "          [-1.3483e+00, -1.8458e+00, -2.6039e-01,  ..., -4.5733e+00,\n",
       "            5.3055e-02, -1.7489e-01],\n",
       "          [-4.0923e-01, -7.0637e-02, -7.1382e-03,  ..., -3.2199e+00,\n",
       "            2.4415e-01, -4.9722e-01],\n",
       "          [-4.9164e-01, -7.9679e-01, -1.5352e+00,  ..., -3.5371e+00,\n",
       "           -4.4186e-01, -1.9392e-01]],\n",
       "\n",
       "         [[ 1.7343e-01,  8.1968e-01, -1.2307e+00,  ..., -1.2898e-01,\n",
       "            2.7799e-01,  7.8210e-01],\n",
       "          [ 1.0020e-01, -2.5740e+00,  4.3210e-01,  ..., -5.0274e-01,\n",
       "            5.0626e-01, -1.2718e+00],\n",
       "          [ 9.4922e-01, -2.6693e+00,  8.2233e-02,  ..., -1.5135e+00,\n",
       "           -5.6715e-01, -8.9571e-01],\n",
       "          ...,\n",
       "          [ 1.0255e+00, -3.5629e+00,  2.4391e+00,  ..., -9.1229e-01,\n",
       "            2.5119e+00, -3.4231e+00],\n",
       "          [ 1.3036e+00, -1.2388e+00,  1.7273e+00,  ..., -1.4405e+00,\n",
       "            1.6542e+00, -2.5272e+00],\n",
       "          [ 5.8190e-01, -1.8213e+00,  4.1066e+00,  ..., -8.8487e-01,\n",
       "            2.7088e+00, -1.7128e+00]],\n",
       "\n",
       "         [[-6.6441e-01,  1.1464e-01, -6.5455e-03,  ...,  7.2032e-02,\n",
       "            1.0701e-01, -2.6402e-01],\n",
       "          [ 7.7326e-01,  3.3692e-01, -2.7091e-01,  ...,  3.6581e-01,\n",
       "            6.0133e-01, -4.9843e-01],\n",
       "          [ 2.2114e+00,  7.7174e-01, -3.5037e-01,  ..., -2.6573e-01,\n",
       "           -6.6625e-01, -8.2685e-01],\n",
       "          ...,\n",
       "          [ 2.3229e+00, -6.3435e-01,  1.6090e+00,  ...,  4.1781e-01,\n",
       "            7.6907e-01, -6.9171e-01],\n",
       "          [ 5.7422e-01, -1.4255e+00,  6.6885e-01,  ...,  1.2177e+00,\n",
       "            1.2764e+00,  2.0630e-01],\n",
       "          [ 1.0420e+00, -1.4322e+00,  8.8623e-01,  ...,  3.6141e-03,\n",
       "            1.5313e+00, -1.4943e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-4.1440e-02,  5.8181e-02,  1.4865e-01,  ..., -9.6627e-02,\n",
       "            2.4565e-02,  1.3746e-01],\n",
       "          [ 2.1182e+00, -1.0237e-01,  6.1345e-01,  ...,  1.6160e-02,\n",
       "            2.6028e-01,  4.8420e-01],\n",
       "          [ 1.7233e+00,  6.2631e-01,  1.1279e+00,  ..., -3.1150e-02,\n",
       "            1.6256e-01, -6.5411e-02],\n",
       "          ...,\n",
       "          [-4.4559e-01,  8.2594e-01, -8.2461e-02,  ...,  1.2161e-01,\n",
       "            2.5711e-02,  3.8233e-01],\n",
       "          [ 3.9124e-01, -1.1350e+00,  8.6474e-01,  ..., -3.8798e-01,\n",
       "           -2.3915e-01, -6.9305e-01],\n",
       "          [-7.4081e-01, -1.6993e+00,  1.2160e+00,  ...,  5.1095e-01,\n",
       "            2.0750e-01, -2.0779e-02]],\n",
       "\n",
       "         [[-2.6535e+00,  3.8615e-01, -1.3803e-02,  ..., -4.5092e-01,\n",
       "           -2.8958e-01,  1.1768e+00],\n",
       "          [ 4.4476e+00, -1.2610e-01, -1.4526e-03,  ..., -1.1920e+00,\n",
       "           -9.4771e-01,  9.0810e-01],\n",
       "          [ 4.3885e+00,  2.3312e-01, -9.2612e-01,  ..., -1.0636e+00,\n",
       "           -4.3096e-01,  7.8953e-01],\n",
       "          ...,\n",
       "          [ 4.9655e+00, -2.5980e-01, -7.3178e-01,  ..., -5.6124e-01,\n",
       "            1.6466e-01, -3.5334e-01],\n",
       "          [ 4.7204e+00, -8.3616e-01, -1.9187e-01,  ..., -3.9811e-01,\n",
       "           -1.1830e+00,  7.7597e-01],\n",
       "          [ 4.7032e+00, -3.4989e-01,  2.0490e-01,  ..., -5.1268e-01,\n",
       "            2.1746e+00, -1.0975e+00]],\n",
       "\n",
       "         [[ 3.7829e-02, -2.2848e-01,  6.5408e-03,  ..., -1.7037e-01,\n",
       "            3.5663e-01,  1.3012e-01],\n",
       "          [ 4.9994e-01, -5.7046e-01,  1.8382e-01,  ..., -8.6132e-02,\n",
       "            1.7181e+00, -8.8885e-01],\n",
       "          [ 3.6855e-01, -1.1214e+00, -3.9706e-01,  ...,  7.9067e-01,\n",
       "            1.1037e+00, -4.0723e-01],\n",
       "          ...,\n",
       "          [ 9.6589e-02, -1.8708e+00,  7.9793e-02,  ..., -2.4507e-01,\n",
       "            2.2143e-01,  1.5306e-01],\n",
       "          [-1.1074e+00, -2.0089e+00, -1.0068e+00,  ...,  1.4054e+00,\n",
       "           -7.4824e-02,  5.7204e-01],\n",
       "          [ 1.1876e-01,  8.5921e-01, -5.1683e-01,  ...,  3.4444e-01,\n",
       "           -1.1833e-02, -9.5438e-01]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[-3.0007e-03, -1.0269e-02,  2.5252e-02,  ..., -5.8876e-03,\n",
       "           -2.7782e-02,  2.9319e-01],\n",
       "          [ 6.1419e-02,  3.8079e-01,  4.1829e-01,  ...,  2.2550e-01,\n",
       "            4.8459e-01, -1.0755e-01],\n",
       "          [ 8.6920e-01,  1.7722e-01,  2.2370e-01,  ..., -5.8062e-01,\n",
       "            7.7392e-01, -7.0909e-01],\n",
       "          ...,\n",
       "          [ 5.5645e-01, -9.6041e-01, -1.9077e-01,  ..., -3.1962e-01,\n",
       "           -5.0814e-01, -1.0034e+00],\n",
       "          [ 4.2956e-01,  5.9292e-01,  2.7573e-01,  ...,  1.0783e-01,\n",
       "           -1.0791e-01, -1.1829e+00],\n",
       "          [ 3.7429e-01,  4.1114e-01,  4.1482e-01,  ...,  3.7167e-01,\n",
       "           -4.5735e-01, -3.0483e-01]],\n",
       "\n",
       "         [[ 1.4225e-02, -3.2158e-02, -7.4767e-03,  ..., -2.0682e-02,\n",
       "           -1.5941e-02, -6.1626e-03],\n",
       "          [ 6.9079e-01, -4.8276e-02, -8.5209e-01,  ..., -4.5079e-01,\n",
       "            1.3598e+00, -4.5734e-01],\n",
       "          [ 1.5451e+00, -4.0991e-02, -4.8676e-01,  ..., -2.3202e-01,\n",
       "            1.0109e+00,  7.6311e-02],\n",
       "          ...,\n",
       "          [ 6.2795e-01, -3.1951e-01,  1.5598e-01,  ...,  3.8007e-01,\n",
       "            3.0410e-01,  3.3608e-04],\n",
       "          [ 1.7902e-02,  1.6594e-01, -4.6554e-01,  ..., -5.8931e-01,\n",
       "            2.9828e-01, -7.9607e-02],\n",
       "          [-6.7439e-01,  3.5281e-01,  4.6497e-01,  ..., -1.2815e+00,\n",
       "           -6.9689e-01, -1.3630e+00]],\n",
       "\n",
       "         [[-3.3407e-02,  1.9988e-02, -2.0681e-02,  ..., -5.6353e-02,\n",
       "            3.0523e-02, -7.9550e-02],\n",
       "          [-1.0731e-01,  1.5261e-02,  7.2175e-02,  ...,  1.4584e-01,\n",
       "           -2.2800e-01, -1.1277e-01],\n",
       "          [-6.3317e-03,  4.6781e-01, -3.2585e-01,  ..., -3.7369e-01,\n",
       "            5.0738e-01,  2.4008e-01],\n",
       "          ...,\n",
       "          [ 1.1731e+00,  6.9067e-01,  5.7706e-01,  ..., -2.2573e-01,\n",
       "           -7.6317e-01,  2.0210e-01],\n",
       "          [-3.2891e-01, -3.4113e-01,  4.0858e-01,  ..., -1.2164e+00,\n",
       "           -1.9897e-01,  2.8576e-01],\n",
       "          [ 3.8532e-01,  9.8635e-01,  7.8301e-01,  ...,  7.5645e-01,\n",
       "           -1.7149e+00, -3.5381e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.4786e-01, -8.0112e-02, -4.1510e-02,  ..., -4.2204e-01,\n",
       "            1.6747e-01,  6.9607e-02],\n",
       "          [ 7.4160e-01, -9.5208e-01, -6.7841e-02,  ...,  9.8351e-01,\n",
       "            1.3057e-01, -1.1073e+00],\n",
       "          [ 7.1311e-01, -8.9457e-01, -7.6325e-01,  ...,  1.6451e+00,\n",
       "           -2.6021e-01, -4.8010e-01],\n",
       "          ...,\n",
       "          [-1.0487e+00, -9.5320e-01,  8.3795e-01,  ...,  1.6726e-01,\n",
       "            4.3559e-01,  5.2488e-01],\n",
       "          [ 3.1049e-02, -7.6678e-01,  1.4021e+00,  ..., -1.1818e-01,\n",
       "           -1.0887e+00, -1.5078e+00],\n",
       "          [ 8.7805e-01,  6.6784e-01,  4.9668e-01,  ..., -2.6668e-01,\n",
       "            5.5992e-01, -2.1934e+00]],\n",
       "\n",
       "         [[-9.7283e-02, -1.1640e-01, -5.7265e-02,  ..., -1.4053e-01,\n",
       "           -1.1866e-01,  8.5977e-02],\n",
       "          [ 1.5585e-01,  1.4863e-01, -1.2429e-01,  ..., -3.9403e-01,\n",
       "            4.1040e-01,  9.2649e-02],\n",
       "          [ 1.8223e-02,  6.3648e-02, -4.8299e-01,  ..., -3.3920e-01,\n",
       "           -4.1437e-01, -2.5764e-01],\n",
       "          ...,\n",
       "          [ 7.1709e-02, -4.3549e-01,  3.4586e-01,  ...,  8.5039e-01,\n",
       "           -4.7060e-01,  4.8395e-02],\n",
       "          [ 3.2840e-01,  6.3409e-03, -4.6007e-02,  ...,  5.1359e-01,\n",
       "            6.3565e-02, -4.1298e-01],\n",
       "          [-2.6743e-01, -9.2029e-01,  2.0720e-01,  ..., -1.7736e-01,\n",
       "           -2.4991e-01, -1.6023e-01]],\n",
       "\n",
       "         [[-5.1410e-02, -5.0676e-02,  8.0793e-02,  ...,  7.2558e-02,\n",
       "           -2.1244e-02,  1.0650e-02],\n",
       "          [ 3.8632e-01,  2.8314e-01,  5.7158e-01,  ...,  3.3883e-01,\n",
       "            2.3144e-01,  1.5330e-01],\n",
       "          [-1.7825e-01,  4.4261e-01, -5.6225e-01,  ..., -7.0969e-01,\n",
       "            2.8624e-01, -1.7672e-01],\n",
       "          ...,\n",
       "          [ 1.1804e+00, -5.4463e-01, -1.3670e+00,  ...,  1.7909e-01,\n",
       "           -5.1962e-01,  3.3931e-01],\n",
       "          [ 2.3002e+00, -1.6801e+00, -1.4358e+00,  ..., -1.5541e+00,\n",
       "           -4.9502e-01,  1.7225e+00],\n",
       "          [-3.2565e-01, -4.9859e-02, -8.4127e-01,  ...,  4.5712e-01,\n",
       "           -4.3438e-01,  7.7001e-01]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[-2.7507e-01,  6.4022e-01, -2.8222e-01,  ...,  1.0715e+00,\n",
       "           -2.6509e-01,  2.2134e-01],\n",
       "          [-4.0640e-01, -5.3484e+00,  1.9776e-01,  ..., -3.1350e+00,\n",
       "            1.8505e+00,  3.7320e-01],\n",
       "          [ 4.1216e-01, -4.4894e+00, -2.6691e-02,  ..., -2.6544e+00,\n",
       "            1.0043e+00,  1.6130e+00],\n",
       "          ...,\n",
       "          [ 1.7288e-01, -2.6414e+00,  2.1703e+00,  ..., -1.9024e+00,\n",
       "            5.2257e-01,  9.3356e-01],\n",
       "          [ 1.2497e+00, -3.6835e+00,  4.0954e-01,  ..., -2.9921e+00,\n",
       "           -1.5458e-01,  3.7753e-01],\n",
       "          [ 5.9708e-02, -1.8778e+00,  2.2701e+00,  ..., -2.1521e+00,\n",
       "           -9.8841e-01,  1.9011e+00]],\n",
       "\n",
       "         [[-4.2665e-02,  7.6331e-01, -6.3369e-01,  ..., -1.0015e-01,\n",
       "            2.8089e-01, -5.5085e-02],\n",
       "          [ 1.6277e+00,  2.1614e+00, -5.7761e-01,  ...,  1.5745e-01,\n",
       "            7.1634e-01, -9.4698e-01],\n",
       "          [ 6.3507e-01,  1.8688e+00, -1.0399e+00,  ...,  9.5179e-01,\n",
       "            4.5587e-01, -8.2784e-01],\n",
       "          ...,\n",
       "          [-8.2330e-02, -1.1232e+00, -8.5797e-01,  ..., -7.6283e-02,\n",
       "            9.8615e-01, -3.0949e-01],\n",
       "          [-5.9620e-01, -6.8557e-01, -5.6425e-02,  ..., -4.6824e-01,\n",
       "            9.6672e-01, -1.2627e+00],\n",
       "          [-1.9135e-01,  7.7555e-01, -8.9607e-02,  ..., -5.9890e-01,\n",
       "            1.0537e+00, -1.0985e+00]],\n",
       "\n",
       "         [[-2.8718e-01,  1.2457e-01, -8.6505e-01,  ..., -3.1391e-01,\n",
       "            1.8779e-02, -9.7453e-02],\n",
       "          [-6.0182e-01,  6.1755e-01,  3.7309e+00,  ...,  7.4514e-01,\n",
       "            7.5872e-02, -7.7273e-01],\n",
       "          [-2.4125e-01,  1.7412e-01,  2.6763e+00,  ...,  3.8896e-01,\n",
       "           -9.5461e-01,  1.5705e-01],\n",
       "          ...,\n",
       "          [-4.6316e-01,  5.8537e-01,  1.0258e+00,  ...,  4.0486e-01,\n",
       "           -7.5530e-01, -2.7197e-01],\n",
       "          [-1.2144e-01, -6.9627e-01,  6.2906e-01,  ...,  1.3455e+00,\n",
       "           -1.1286e+00,  1.1834e+00],\n",
       "          [ 3.9349e-01,  1.6241e+00,  2.0219e+00,  ...,  7.8529e-01,\n",
       "            9.1349e-01,  1.4555e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.2016e-01,  4.5280e-02, -6.0067e-02,  ...,  3.6574e-02,\n",
       "            1.9019e-01, -2.5614e-02],\n",
       "          [-9.2613e-01,  8.6485e-02, -2.3562e-01,  ..., -7.5047e-01,\n",
       "            4.0712e-01, -2.1066e-01],\n",
       "          [-2.4343e-01, -7.8994e-01, -4.3415e-02,  ..., -7.5071e-01,\n",
       "            6.1958e-02, -6.9401e-01],\n",
       "          ...,\n",
       "          [ 4.0727e-01, -1.1705e+00,  1.6583e+00,  ...,  3.7931e-01,\n",
       "           -8.0390e-01, -3.8224e-02],\n",
       "          [ 1.7190e-01, -5.9297e-01,  8.6100e-01,  ..., -2.2744e-01,\n",
       "            1.6594e-01,  7.8090e-01],\n",
       "          [-4.2068e-01,  5.2060e-01,  1.3777e+00,  ...,  1.3230e+00,\n",
       "            7.7503e-02,  9.6879e-01]],\n",
       "\n",
       "         [[ 2.2049e-01,  8.5001e-02,  2.6589e-01,  ...,  3.2094e-01,\n",
       "            6.0526e-02,  2.3229e-01],\n",
       "          [ 1.2087e+00,  7.9662e-01,  7.4289e-02,  ...,  6.7964e-01,\n",
       "           -8.9217e-01,  2.6535e-01],\n",
       "          [-2.7851e-01,  5.2153e-01,  5.7161e-01,  ..., -3.6024e-01,\n",
       "            8.4129e-02, -2.9692e-01],\n",
       "          ...,\n",
       "          [ 2.3620e-01, -3.3627e-01,  2.4231e-01,  ..., -6.7138e-01,\n",
       "           -1.0179e+00, -1.4965e+00],\n",
       "          [ 2.4293e-02,  1.0921e+00,  4.1701e-01,  ..., -8.1524e-01,\n",
       "            1.9783e-01,  3.3819e-01],\n",
       "          [ 1.1633e+00, -4.8260e-01,  2.3214e-01,  ..., -1.6108e+00,\n",
       "           -7.6200e-01,  6.6906e-01]],\n",
       "\n",
       "         [[-2.7614e+00,  3.7896e-01,  3.9004e-01,  ..., -7.8563e-01,\n",
       "            2.8747e-01,  1.4416e-01],\n",
       "          [ 1.0445e+01, -1.7699e-01, -1.1411e+00,  ...,  4.0690e+00,\n",
       "           -9.0085e-01,  1.7045e+00],\n",
       "          [ 9.7918e+00,  8.0002e-03, -1.8386e+00,  ...,  2.8927e+00,\n",
       "           -8.4133e-01,  2.1277e+00],\n",
       "          ...,\n",
       "          [ 8.0690e+00, -1.0057e+00,  2.8025e-01,  ...,  1.3302e+00,\n",
       "            1.0319e+00, -6.4284e-01],\n",
       "          [ 7.3058e+00, -1.4214e+00, -1.6226e+00,  ...,  2.1555e-01,\n",
       "            1.7112e-01, -1.2057e+00],\n",
       "          [ 6.6788e+00, -7.2899e-01, -5.1488e-01,  ...,  4.7668e-01,\n",
       "           -1.1274e+00, -5.4167e-01]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[-2.0502e-02, -7.2253e-03,  1.5728e-02,  ..., -8.8364e-02,\n",
       "           -3.0822e-02, -1.1890e-01],\n",
       "          [-4.8458e-01, -2.9315e-01, -1.0869e-01,  ...,  4.7950e-02,\n",
       "           -6.8197e-02, -9.9591e-01],\n",
       "          [-1.0591e-01,  1.8328e-01, -4.2269e-01,  ...,  2.4274e-01,\n",
       "           -2.5571e-01, -4.3939e-01],\n",
       "          ...,\n",
       "          [-1.3860e-01,  2.7729e-01, -8.2746e-01,  ..., -6.4335e-03,\n",
       "            5.0687e-01,  2.7192e-01],\n",
       "          [ 2.2718e-01, -1.9320e-01, -4.4630e-01,  ...,  3.5271e-01,\n",
       "           -5.9913e-01,  9.0867e-02],\n",
       "          [-2.3382e-01,  5.3194e-01, -1.4935e-01,  ..., -2.0650e-01,\n",
       "           -7.6206e-01, -9.8652e-01]],\n",
       "\n",
       "         [[ 6.6624e-02, -1.4993e-02,  1.6834e-03,  ..., -3.0188e-02,\n",
       "            2.0378e-02, -6.0369e-03],\n",
       "          [ 3.0436e-02,  3.1926e-01, -4.9895e-01,  ..., -5.2394e-01,\n",
       "           -1.7727e-01, -4.2826e-01],\n",
       "          [ 9.3342e-02,  2.3561e-01, -1.0101e+00,  ...,  7.6194e-01,\n",
       "           -5.9351e-01,  2.9755e-01],\n",
       "          ...,\n",
       "          [ 2.2050e-01,  1.1752e+00, -3.5891e-01,  ...,  7.3674e-01,\n",
       "           -1.1131e+00,  1.1567e-01],\n",
       "          [-1.0246e-01, -5.9956e-01,  3.7127e-01,  ..., -2.8524e-01,\n",
       "            6.0171e-01,  1.2508e-01],\n",
       "          [-7.3710e-01, -6.8684e-01, -1.3423e+00,  ...,  9.5323e-01,\n",
       "            6.0086e-01,  8.4318e-02]],\n",
       "\n",
       "         [[ 6.7167e-02,  2.1480e-02, -1.0381e-02,  ...,  4.9186e-02,\n",
       "            5.7107e-03,  4.1016e-02],\n",
       "          [-2.5147e-01, -1.8193e-01, -5.7122e-01,  ...,  2.7193e-01,\n",
       "            1.4405e+00,  6.8265e-01],\n",
       "          [-5.5509e-01,  1.6786e-01, -4.9883e-01,  ...,  2.9455e-01,\n",
       "           -3.3884e-01,  7.6752e-01],\n",
       "          ...,\n",
       "          [-4.0717e-01, -9.1969e-01,  3.3521e-01,  ..., -6.7300e-02,\n",
       "           -3.1175e-01,  4.9907e-01],\n",
       "          [ 3.1522e-01,  6.1127e-02, -5.9542e-01,  ..., -3.3488e-01,\n",
       "            1.4367e+00, -8.9857e-03],\n",
       "          [-1.4532e+00, -1.2939e+00, -8.8232e-01,  ...,  3.0747e-01,\n",
       "            5.0196e-01,  2.6975e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.3611e-02,  3.8592e-02,  1.3044e-02,  ..., -2.6977e-02,\n",
       "           -2.1484e-02,  1.0393e-02],\n",
       "          [-6.5130e-01,  1.6605e-01,  1.0657e-01,  ...,  2.7835e-01,\n",
       "           -6.9238e-02, -3.0253e-01],\n",
       "          [-5.5479e-01, -5.4661e-01, -1.2732e-01,  ...,  4.4478e-01,\n",
       "           -1.3895e+00,  6.9371e-02],\n",
       "          ...,\n",
       "          [ 7.1077e-03, -2.0203e-01, -1.5514e-01,  ..., -4.3295e-02,\n",
       "           -1.5142e+00,  7.4447e-01],\n",
       "          [ 6.8730e-01,  4.3394e-01,  7.8727e-01,  ...,  3.8452e-01,\n",
       "           -5.5940e-01,  2.6835e-01],\n",
       "          [-3.3768e-01, -7.1513e-01,  5.8005e-01,  ..., -9.3141e-01,\n",
       "            2.1281e+00,  1.7262e-01]],\n",
       "\n",
       "         [[ 6.3200e-02, -1.0620e-02, -1.6518e-02,  ...,  9.4679e-02,\n",
       "           -1.0668e-02,  3.3107e-02],\n",
       "          [ 5.1620e-01, -7.9607e-01, -6.5327e-01,  ...,  7.5826e-02,\n",
       "            2.6742e-01,  7.0262e-01],\n",
       "          [-2.9301e-01,  1.1497e-01,  1.1904e-01,  ..., -5.7305e-01,\n",
       "           -2.3403e-01, -3.7106e-01],\n",
       "          ...,\n",
       "          [-8.5946e-01, -5.4443e-01, -1.4565e-01,  ..., -4.1868e-01,\n",
       "            5.7312e-01,  5.7441e-01],\n",
       "          [ 1.3619e-01, -1.2818e-01,  1.0067e-01,  ..., -1.9136e-01,\n",
       "            1.5723e+00, -7.1590e-01],\n",
       "          [-1.8020e+00,  6.4935e-02,  8.0408e-01,  ...,  1.1006e+00,\n",
       "            7.3148e-01, -8.9776e-01]],\n",
       "\n",
       "         [[ 2.7450e-02, -1.7117e-01, -4.1035e-02,  ..., -6.8331e-02,\n",
       "            1.5973e-01, -1.2446e-02],\n",
       "          [-3.5405e-01, -1.4234e-01, -2.1591e-01,  ..., -7.4673e-01,\n",
       "            2.5460e-02,  5.6931e-01],\n",
       "          [-4.9000e-01,  3.0493e-02, -2.4359e-02,  ..., -1.4033e-01,\n",
       "           -2.5847e-01,  1.9334e-01],\n",
       "          ...,\n",
       "          [ 1.0194e-01,  1.1360e+00,  3.7560e-01,  ..., -1.7933e-01,\n",
       "           -9.7488e-02,  4.8762e-01],\n",
       "          [ 1.5532e-01,  6.6894e-01,  4.3730e-02,  ..., -8.7515e-01,\n",
       "           -2.5893e-01, -6.4448e-01],\n",
       "          [ 5.5215e-01, -5.3483e-01, -2.2079e-01,  ..., -1.5374e+00,\n",
       "           -7.4178e-01, -1.4181e-02]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[ 9.9479e-01, -1.9414e-01, -1.2558e-01,  ...,  5.1885e-01,\n",
       "            6.0851e-01, -1.8959e-01],\n",
       "          [-6.4870e+00, -2.3747e+00, -7.0520e-01,  ...,  6.8807e-02,\n",
       "           -4.7217e+00, -1.2840e-01],\n",
       "          [-5.4583e+00, -1.8097e+00, -3.4476e-01,  ...,  8.4178e-01,\n",
       "           -4.4909e+00, -4.9890e-01],\n",
       "          ...,\n",
       "          [-5.0441e+00, -1.5804e+00, -4.2431e-01,  ...,  2.4251e-01,\n",
       "           -3.3673e+00, -2.8065e-01],\n",
       "          [-3.4643e+00, -8.2889e-01,  3.3777e-02,  ..., -1.0679e+00,\n",
       "           -3.1331e+00, -1.1749e-01],\n",
       "          [-3.2718e+00, -3.1036e+00, -8.0092e-01,  ..., -1.2695e+00,\n",
       "           -2.6305e+00,  8.5056e-01]],\n",
       "\n",
       "         [[-1.5334e-01, -1.2854e-01,  2.2089e-01,  ...,  4.5993e-02,\n",
       "           -8.0182e-01, -1.0308e-01],\n",
       "          [ 5.7813e-01,  3.0842e-02, -1.3740e-01,  ..., -1.1853e+00,\n",
       "           -8.8004e-01,  9.6248e-02],\n",
       "          [-2.6747e-01,  3.0370e-01, -7.9243e-01,  ...,  1.4508e-01,\n",
       "            2.8252e-01,  5.9529e-01],\n",
       "          ...,\n",
       "          [ 3.1740e-01, -3.0217e-01, -1.0712e+00,  ..., -9.6065e-01,\n",
       "           -1.8706e+00,  9.5390e-01],\n",
       "          [-1.4635e+00,  2.6672e-01, -6.0326e-01,  ...,  3.8400e-01,\n",
       "            1.0399e+00,  9.7562e-01],\n",
       "          [-4.9877e-01, -8.5461e-01, -3.5172e-01,  ..., -2.5356e-02,\n",
       "            1.2686e+00, -8.3560e-01]],\n",
       "\n",
       "         [[ 2.7887e-01,  1.7484e-01,  1.0342e+00,  ..., -3.8073e-01,\n",
       "            3.5110e-01, -4.0208e-01],\n",
       "          [-3.4856e-01, -1.5613e-01, -1.2746e+00,  ..., -4.7523e-02,\n",
       "           -5.3294e-01,  1.9315e+00],\n",
       "          [-9.7536e-01, -4.4070e-01, -1.1045e+00,  ..., -7.8743e-01,\n",
       "           -1.4267e+00,  2.1690e+00],\n",
       "          ...,\n",
       "          [ 9.2098e-01, -1.3095e+00, -9.9568e-01,  ...,  2.2007e+00,\n",
       "           -8.6714e-01, -1.2989e+00],\n",
       "          [ 1.1834e+00, -9.3749e-01, -4.6653e-01,  ...,  5.1853e-01,\n",
       "           -5.1408e-01,  1.9486e+00],\n",
       "          [ 7.5667e-01, -4.0592e-01, -2.9426e-01,  ...,  9.7518e-01,\n",
       "            1.7011e+00,  9.2694e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.8243e-01,  2.9479e-02, -1.9406e-01,  ...,  1.0815e-02,\n",
       "            1.1205e-01,  2.1801e-02],\n",
       "          [-1.3697e+00,  4.6499e-01,  7.2391e-01,  ...,  6.2479e-01,\n",
       "           -1.0985e+00,  4.1697e-01],\n",
       "          [-1.6349e+00, -7.1807e-02, -3.4046e-03,  ...,  1.0923e+00,\n",
       "            3.3014e-01, -1.0764e-01],\n",
       "          ...,\n",
       "          [ 2.0497e+00,  7.1454e-01,  1.6261e+00,  ...,  1.3428e+00,\n",
       "            1.3166e+00,  5.7375e-01],\n",
       "          [ 4.9388e-01, -7.0137e-01,  1.0655e+00,  ...,  2.5426e+00,\n",
       "           -4.5952e-01, -9.0583e-01],\n",
       "          [-5.1293e-01,  4.4050e-01, -7.1246e-01,  ...,  2.4626e+00,\n",
       "           -1.8039e+00, -1.4068e+00]],\n",
       "\n",
       "         [[-2.9473e-01, -1.9238e+00,  7.5591e-02,  ..., -7.7601e-02,\n",
       "           -1.1944e-02,  7.4603e-01],\n",
       "          [ 9.4397e-02, -1.7699e-01, -2.6439e-01,  ...,  1.7119e+00,\n",
       "           -6.8571e-01,  1.5071e+00],\n",
       "          [ 7.3983e-02,  1.9254e+00, -1.1640e+00,  ...,  6.6325e-01,\n",
       "           -1.6861e+00,  1.1845e+00],\n",
       "          ...,\n",
       "          [ 1.4900e+00,  4.0860e+00, -2.3482e-01,  ...,  6.8161e-01,\n",
       "           -1.7958e-01,  1.0659e+00],\n",
       "          [ 1.9281e+00,  2.9092e+00, -7.0417e-01,  ...,  1.8595e+00,\n",
       "           -8.2575e-01,  7.9743e-01],\n",
       "          [ 4.4357e-01,  2.7224e+00, -1.8195e+00,  ...,  1.9567e-01,\n",
       "            5.3245e-01,  5.6104e-02]],\n",
       "\n",
       "         [[ 3.3432e-01,  1.0390e-01, -3.5090e-02,  ...,  6.1020e-01,\n",
       "            7.0413e-02,  1.8607e-01],\n",
       "          [ 4.9481e-01, -5.1091e-01, -5.8546e-01,  ...,  7.6237e-04,\n",
       "            8.5323e-01, -9.8859e-01],\n",
       "          [ 5.5508e-01, -5.6845e-01, -6.4282e-01,  ..., -2.9933e-01,\n",
       "            4.5320e-01, -1.1204e+00],\n",
       "          ...,\n",
       "          [-1.2041e+00, -1.3657e+00, -9.1095e-01,  ..., -1.0108e+00,\n",
       "           -1.9571e-01,  7.3557e-01],\n",
       "          [-2.4892e+00, -3.6849e-01, -9.8251e-01,  ...,  5.2286e-01,\n",
       "            9.2830e-01, -1.9107e-01],\n",
       "          [-4.9245e-01,  6.9687e-01,  7.1328e-01,  ..., -1.2302e+00,\n",
       "            1.3787e+00,  4.4085e-01]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[-5.8269e-02,  7.9075e-02, -2.1800e-03,  ..., -5.3603e-03,\n",
       "            1.9098e-02, -1.8329e-03],\n",
       "          [ 6.6435e-01,  2.9061e-01, -3.5737e-01,  ..., -5.3055e-01,\n",
       "           -3.5535e-01,  1.3024e-01],\n",
       "          [ 5.0552e-01,  6.5623e-03,  4.1853e-01,  ...,  2.1469e-01,\n",
       "            8.6897e-03, -1.1240e+00],\n",
       "          ...,\n",
       "          [-1.3074e-01, -4.7285e-01, -8.2047e-01,  ...,  7.2317e-01,\n",
       "           -2.2004e-01, -2.8986e-01],\n",
       "          [-5.8622e-01, -1.1543e+00, -7.5487e-01,  ..., -1.3910e-01,\n",
       "            4.9126e-01,  3.9337e-02],\n",
       "          [ 9.7936e-01,  3.2980e-01,  5.7194e-01,  ..., -2.8916e-02,\n",
       "           -6.7608e-01, -1.3264e-02]],\n",
       "\n",
       "         [[ 4.1871e-02, -3.4714e-02, -6.4294e-02,  ...,  4.4134e-02,\n",
       "           -5.9664e-02,  1.8934e-02],\n",
       "          [ 1.9969e-01, -7.5374e-01,  5.5932e-01,  ...,  1.2155e+00,\n",
       "            3.0278e-01, -2.3196e-01],\n",
       "          [ 4.4199e-01, -4.6059e-01, -5.4278e-01,  ...,  2.6089e-01,\n",
       "           -1.4515e-01, -2.2863e-01],\n",
       "          ...,\n",
       "          [ 4.6902e-01, -3.1878e-02, -1.2724e+00,  ..., -2.0524e-02,\n",
       "           -6.8541e-01, -1.5602e+00],\n",
       "          [-1.4198e-01,  1.8788e-01, -4.6792e-01,  ...,  4.2809e-01,\n",
       "           -7.2574e-01, -2.9631e-01],\n",
       "          [ 4.3750e-01,  8.6597e-02,  5.8160e-01,  ...,  1.0865e+00,\n",
       "           -4.9115e-01, -7.8770e-01]],\n",
       "\n",
       "         [[ 2.5277e-03, -7.7282e-02,  5.5962e-02,  ...,  3.9435e-03,\n",
       "            1.7322e-02, -1.8569e-03],\n",
       "          [ 1.1882e-01, -3.8645e-01,  3.4290e-02,  ...,  3.9168e-01,\n",
       "            3.2247e-01, -8.4531e-01],\n",
       "          [-6.2453e-01,  1.7796e-01,  2.9343e-01,  ...,  8.5606e-01,\n",
       "            1.5518e-01,  1.1123e+00],\n",
       "          ...,\n",
       "          [ 1.0543e+00, -8.5031e-01, -1.5077e-01,  ...,  2.8069e-01,\n",
       "           -1.1114e+00,  9.9831e-01],\n",
       "          [-9.8172e-01, -2.0846e-02,  2.0630e+00,  ..., -1.5524e+00,\n",
       "           -4.0262e-01,  4.6047e-01],\n",
       "          [ 2.2016e+00, -1.3753e-01,  8.5331e-01,  ...,  9.7334e-01,\n",
       "           -1.0878e+00, -1.9967e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.8943e-01,  8.5971e-02,  1.1202e-02,  ...,  2.2126e-02,\n",
       "            6.7317e-02, -1.2352e-01],\n",
       "          [-2.6760e-01,  5.7474e-02,  2.2625e-01,  ..., -2.1064e-01,\n",
       "            1.4632e-01, -5.2240e-03],\n",
       "          [ 4.3437e-01,  6.8842e-02,  3.4234e-01,  ...,  4.5501e-03,\n",
       "           -6.6397e-02,  9.5493e-03],\n",
       "          ...,\n",
       "          [ 2.6096e-02,  3.0867e-01, -5.4878e-01,  ...,  1.2157e+00,\n",
       "           -1.2446e-01, -2.1312e+00],\n",
       "          [ 6.4955e-01, -7.4723e-01, -1.9590e+00,  ..., -2.6645e-01,\n",
       "            3.6911e-01,  6.3399e-01],\n",
       "          [ 1.2305e+00,  1.0732e+00,  2.2029e+00,  ..., -7.1112e-02,\n",
       "            2.4877e+00,  1.2696e+00]],\n",
       "\n",
       "         [[-6.2090e-01, -4.4224e-02,  3.7323e-02,  ..., -9.8202e-03,\n",
       "            3.3941e-02,  1.5782e-02],\n",
       "          [-1.3818e+00, -7.0548e-01, -1.5672e-01,  ..., -2.5114e-02,\n",
       "            1.4072e-01, -4.3044e-03],\n",
       "          [-1.5816e+00,  8.3161e-02, -7.8729e-01,  ...,  1.6745e-01,\n",
       "            6.0404e-01,  8.2122e-01],\n",
       "          ...,\n",
       "          [-6.6020e-01,  4.8764e-01,  4.1053e-01,  ...,  1.7444e-01,\n",
       "           -2.2602e-01,  1.0631e+00],\n",
       "          [-5.2186e-01,  4.1676e-01, -6.9493e-01,  ..., -1.7358e-02,\n",
       "           -1.7737e-01, -5.7582e-01],\n",
       "          [-2.5040e+00, -3.0483e-01,  3.3099e-01,  ...,  2.3339e-01,\n",
       "            7.1812e-01,  3.5100e-01]],\n",
       "\n",
       "         [[ 3.7707e-03,  4.5164e-02,  1.3004e-02,  ...,  5.2309e-02,\n",
       "            4.1151e-02, -4.1251e-02],\n",
       "          [-7.5355e-01, -6.9623e-01, -6.1423e-01,  ..., -7.5540e-01,\n",
       "           -4.1026e-01, -1.3270e-01],\n",
       "          [-1.5002e-01, -1.3822e-01, -4.0623e-01,  ..., -4.1132e-01,\n",
       "           -7.8420e-01,  5.5188e-01],\n",
       "          ...,\n",
       "          [-5.7186e-01, -2.4123e-01, -1.3142e+00,  ..., -6.9304e-01,\n",
       "           -1.6025e+00, -3.9369e-01],\n",
       "          [ 8.9201e-01, -2.5896e-02, -7.6055e-01,  ...,  2.2399e-01,\n",
       "           -1.4211e+00,  2.8828e-01],\n",
       "          [ 1.1539e+00, -1.4886e+00, -2.0009e+00,  ..., -1.4166e+00,\n",
       "           -5.8074e-01,  7.2278e-01]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[ 1.2184e-03, -2.0833e+00,  1.1535e-01,  ..., -3.0240e-01,\n",
       "           -2.6283e-01,  1.1954e-01],\n",
       "          [-6.9394e-01,  3.0267e+00,  4.1918e-01,  ...,  1.0098e-01,\n",
       "           -6.2548e-01,  1.1934e+00],\n",
       "          [-4.3634e-01,  3.5824e+00,  1.1881e+00,  ..., -1.0684e+00,\n",
       "            2.5700e-02,  4.1898e-01],\n",
       "          ...,\n",
       "          [-5.5111e-01,  5.1450e+00,  6.4910e-01,  ..., -1.0215e+00,\n",
       "           -1.9327e+00, -1.7129e-01],\n",
       "          [-4.4773e-01,  4.9171e+00, -3.8925e-01,  ...,  1.2071e+00,\n",
       "           -8.5487e-01,  3.5959e-01],\n",
       "          [-6.1700e-01,  3.1145e+00, -4.0252e-01,  ...,  1.5893e+00,\n",
       "           -1.4454e+00,  3.7237e-01]],\n",
       "\n",
       "         [[-7.7905e-01,  1.6446e-01,  2.5265e-01,  ..., -3.5163e-01,\n",
       "            9.6341e-01,  1.0939e+00],\n",
       "          [ 7.4747e-01, -3.3873e-02,  1.4712e+00,  ...,  4.5877e-01,\n",
       "            1.0041e+00,  6.4554e-01],\n",
       "          [ 1.0080e+00,  6.1670e-01,  9.7308e-01,  ...,  5.3741e-01,\n",
       "            1.2096e+00, -5.6713e-01],\n",
       "          ...,\n",
       "          [-6.8660e-02,  1.2100e+00, -9.5643e-01,  ...,  1.0397e+00,\n",
       "            4.3187e-01, -3.3688e-01],\n",
       "          [-1.3949e+00,  2.2560e-01, -5.2797e-01,  ...,  1.5744e+00,\n",
       "            1.8514e+00, -6.4552e-01],\n",
       "          [-4.0797e-01, -2.7150e-01, -7.2799e-01,  ...,  2.7775e+00,\n",
       "            2.7610e+00, -7.4257e-01]],\n",
       "\n",
       "         [[-7.6268e-01,  4.4276e-01, -9.5781e-02,  ...,  4.8300e-01,\n",
       "           -2.3391e-01,  9.8322e-01],\n",
       "          [ 1.5705e-01, -7.6900e-01,  4.9016e-01,  ...,  1.5090e-01,\n",
       "           -1.4515e-01, -4.4801e-01],\n",
       "          [ 8.7244e-01,  7.1832e-03,  1.2565e-01,  ...,  7.3611e-01,\n",
       "            6.6373e-01, -7.3180e-01],\n",
       "          ...,\n",
       "          [ 5.0680e-01, -3.0503e-01,  5.0514e-01,  ...,  9.9416e-02,\n",
       "            5.2691e-01,  4.0007e-01],\n",
       "          [ 1.0713e+00, -1.1371e-01,  1.0815e+00,  ...,  7.9386e-01,\n",
       "            6.9764e-01, -3.6888e-01],\n",
       "          [ 1.5364e+00, -1.6921e-01, -1.9529e+00,  ...,  1.4523e+00,\n",
       "            8.6944e-01,  4.6636e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.5718e-01, -1.8602e-01,  7.3205e-02,  ...,  8.9509e-02,\n",
       "            1.5443e+00, -2.5225e+00],\n",
       "          [ 7.7794e-02,  3.5895e-01,  9.8278e-01,  ...,  5.5001e-01,\n",
       "           -4.2420e+00,  4.6809e+00],\n",
       "          [ 4.2089e-02,  1.3513e-01,  8.4750e-01,  ..., -1.1967e-01,\n",
       "           -3.9307e+00,  5.1969e+00],\n",
       "          ...,\n",
       "          [-1.0382e-01,  3.5065e-01,  6.0993e-02,  ...,  2.4028e-01,\n",
       "           -3.8434e+00,  5.2682e+00],\n",
       "          [-8.2728e-01, -6.3383e-02, -2.6255e-01,  ..., -8.3399e-02,\n",
       "           -3.0744e+00,  3.7387e+00],\n",
       "          [-2.7687e-01,  8.5504e-01,  1.3464e+00,  ..., -1.1811e+00,\n",
       "           -4.8298e+00,  4.6020e+00]],\n",
       "\n",
       "         [[-5.0916e-03,  2.9697e-01,  1.8534e-01,  ..., -7.7122e-02,\n",
       "            9.4513e-02, -1.0038e-01],\n",
       "          [ 1.0721e-01, -2.1103e-01,  5.4218e-01,  ...,  2.8986e-01,\n",
       "           -1.0361e+00,  1.9597e-01],\n",
       "          [-6.1149e-01, -1.1187e+00,  8.9654e-01,  ..., -1.3778e-01,\n",
       "           -8.6350e-01,  7.0713e-01],\n",
       "          ...,\n",
       "          [-5.4061e-01, -7.0633e-01,  8.4810e-02,  ...,  6.2804e-01,\n",
       "           -1.4455e+00,  1.0842e+00],\n",
       "          [-2.5896e-01,  1.3560e-01,  8.0471e-01,  ...,  5.9688e-01,\n",
       "           -1.9739e+00,  6.8923e-02],\n",
       "          [-5.0205e-01,  5.0282e-02,  1.2287e+00,  ...,  1.1203e+00,\n",
       "           -1.0592e+00, -2.8834e-01]],\n",
       "\n",
       "         [[ 3.6016e-01,  1.0746e-01,  4.9256e-01,  ...,  4.1980e-01,\n",
       "            5.5004e-01, -2.9025e-01],\n",
       "          [ 2.2500e-01,  1.0245e-01, -5.3045e-02,  ..., -2.1573e+00,\n",
       "           -4.5847e+00,  1.4257e-01],\n",
       "          [ 4.2621e-01, -4.9956e-01, -1.4888e-01,  ..., -1.9308e+00,\n",
       "           -4.3484e+00, -8.1245e-01],\n",
       "          ...,\n",
       "          [ 2.6362e-01,  6.4181e-01, -1.9238e+00,  ..., -1.1488e+00,\n",
       "           -3.8448e+00,  8.2864e-01],\n",
       "          [ 5.7864e-01,  2.8646e-01, -7.5498e-01,  ..., -9.5551e-01,\n",
       "           -2.8840e+00, -4.6161e-01],\n",
       "          [ 1.2465e+00, -7.6305e-01, -1.6178e+00,  ..., -7.7838e-01,\n",
       "           -3.0351e+00, -7.8372e-01]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[ 7.4834e-02,  2.7919e-03,  8.8163e-03,  ...,  7.9741e-02,\n",
       "           -6.6632e-02, -3.0930e-03],\n",
       "          [-2.6620e-01,  9.6410e-02,  2.5688e-01,  ..., -4.8931e-01,\n",
       "           -1.1986e-01,  3.8747e-01],\n",
       "          [ 5.2016e-01, -4.4896e-01, -5.2432e-01,  ..., -3.2095e-02,\n",
       "            5.4696e-02, -5.9564e-02],\n",
       "          ...,\n",
       "          [ 9.1947e-01, -5.9997e-01,  3.8508e-01,  ...,  7.2078e-01,\n",
       "            5.6388e-01,  1.3634e+00],\n",
       "          [-8.2009e-01,  1.4632e-01,  1.4504e+00,  ..., -1.0529e+00,\n",
       "           -6.9924e-01,  4.9574e-03],\n",
       "          [ 1.3816e+00,  7.6788e-01,  4.4746e-01,  ..., -5.7217e-01,\n",
       "           -1.6960e+00,  1.1857e+00]],\n",
       "\n",
       "         [[ 3.5484e-02,  4.7282e-02,  3.2800e-02,  ...,  1.9289e-03,\n",
       "           -2.0579e-02, -7.7747e-02],\n",
       "          [ 4.1006e-01,  3.1853e-01,  6.9131e-01,  ...,  5.2548e-01,\n",
       "           -1.7748e-01, -6.8511e-01],\n",
       "          [-6.8207e-01,  3.9662e-01,  7.9579e-01,  ...,  1.6144e+00,\n",
       "           -2.0265e-01,  7.0344e-01],\n",
       "          ...,\n",
       "          [ 1.0498e+00,  2.9903e-01, -6.9823e-01,  ...,  1.9747e-01,\n",
       "            7.8318e-01, -2.0122e-01],\n",
       "          [ 1.1674e+00,  5.1814e-01,  4.6844e-01,  ...,  1.1537e+00,\n",
       "            1.3417e+00, -6.3153e-02],\n",
       "          [ 2.4332e+00,  2.0015e+00,  2.1242e-01,  ...,  1.6590e+00,\n",
       "           -1.2233e+00,  9.6925e-01]],\n",
       "\n",
       "         [[ 4.0498e-02, -5.1324e-02, -8.8137e-03,  ...,  1.4119e-02,\n",
       "           -3.3248e-02, -8.4295e-02],\n",
       "          [ 3.8749e-02, -3.8769e-01, -8.0873e-02,  ...,  5.8763e-01,\n",
       "           -1.6718e-01, -1.5292e-01],\n",
       "          [-2.9367e-01, -3.5884e-01, -9.3030e-02,  ...,  7.7348e-01,\n",
       "            1.6459e-01, -1.9514e-01],\n",
       "          ...,\n",
       "          [ 1.2262e-01,  6.0338e-01,  2.4163e-01,  ...,  3.0874e-01,\n",
       "            2.1477e-01, -3.6240e-01],\n",
       "          [ 2.9407e-01, -4.1585e-01,  1.1182e-01,  ..., -5.7365e-01,\n",
       "           -5.6255e-01, -4.1960e-01],\n",
       "          [-5.4308e-01, -1.2697e-01, -3.8661e-01,  ...,  1.7194e+00,\n",
       "           -7.9439e-01,  5.4347e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-8.5139e-02, -2.5277e-02,  3.4757e-02,  ..., -1.1381e-01,\n",
       "           -5.7558e-03,  2.5408e-02],\n",
       "          [ 8.8222e-01, -2.4795e-01,  5.1234e-01,  ..., -2.7057e-01,\n",
       "           -1.6965e-01, -2.4758e-01],\n",
       "          [ 1.8280e-01,  4.3207e-01,  6.7528e-01,  ...,  2.3622e-01,\n",
       "           -3.4924e-01,  1.3818e-01],\n",
       "          ...,\n",
       "          [-4.1916e-01, -7.4961e-01,  5.0030e-01,  ..., -7.8956e-01,\n",
       "            8.8995e-01, -5.0807e-01],\n",
       "          [-2.3750e-01, -9.5395e-01, -1.4818e+00,  ...,  1.1277e+00,\n",
       "            2.4521e-01, -1.4829e+00],\n",
       "          [ 6.1140e-01,  6.5996e-01,  5.7557e-01,  ...,  3.9986e-01,\n",
       "           -1.3476e+00, -8.2806e-02]],\n",
       "\n",
       "         [[ 1.1130e-01,  4.0168e-02,  1.2024e-01,  ...,  3.3958e-02,\n",
       "            3.0896e-02, -9.6359e-02],\n",
       "          [-2.6191e-01,  2.1796e-01,  4.3853e-01,  ..., -4.8718e-01,\n",
       "            2.8565e-01, -1.4433e-02],\n",
       "          [-6.1816e-01, -4.3221e-01, -1.1778e-01,  ..., -2.4048e-01,\n",
       "            3.0270e-01,  5.5311e-01],\n",
       "          ...,\n",
       "          [-5.9933e-01, -3.7806e-01,  9.6016e-01,  ..., -1.7435e+00,\n",
       "            1.4025e+00, -2.7294e-01],\n",
       "          [-8.1845e-01,  2.6822e-01,  5.2452e-01,  ..., -6.0304e-01,\n",
       "           -5.0351e-01, -1.6386e+00],\n",
       "          [-1.4450e+00, -1.4911e+00, -4.3253e-01,  ..., -1.3040e-01,\n",
       "           -1.5553e+00, -4.3523e-01]],\n",
       "\n",
       "         [[ 6.6786e-02, -3.2479e-02, -9.0227e-02,  ...,  2.5162e-02,\n",
       "            3.0339e-02,  4.8937e-02],\n",
       "          [-2.9442e-01,  1.1041e+00, -2.3202e-02,  ...,  3.6114e-01,\n",
       "            2.8867e-02,  4.1353e-01],\n",
       "          [-7.8311e-02,  2.6655e-01, -7.8538e-02,  ...,  3.5223e-01,\n",
       "           -6.1101e-01,  7.7168e-01],\n",
       "          ...,\n",
       "          [ 2.4466e-02,  8.2577e-01, -5.0679e-02,  ...,  9.9351e-01,\n",
       "            2.7788e-01,  7.3800e-01],\n",
       "          [-3.3863e-01,  1.4988e+00,  5.5973e-01,  ...,  1.3324e+00,\n",
       "            2.4721e-01,  2.2142e-01],\n",
       "          [-2.1820e+00,  2.1276e+00, -8.8676e-02,  ...,  2.0532e+00,\n",
       "            2.4773e-01, -1.0361e+00]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[-2.4552e-02, -2.5609e-01, -6.0953e-01,  ...,  1.2874e-01,\n",
       "            2.5091e-01,  2.8309e-01],\n",
       "          [ 4.3556e-04, -6.5144e-01, -2.2126e+00,  ..., -9.9235e-01,\n",
       "            1.0124e-01,  1.4989e+00],\n",
       "          [ 2.1278e-01, -8.8329e-01, -1.7187e+00,  ..., -1.1004e+00,\n",
       "            5.3343e-01,  2.3500e-01],\n",
       "          ...,\n",
       "          [ 3.1181e-01, -2.3863e-01, -7.5790e-01,  ..., -6.9967e-01,\n",
       "            1.3620e+00, -2.1052e-01],\n",
       "          [ 1.9872e+00, -8.1031e-01, -7.2225e-01,  ...,  1.0388e-01,\n",
       "            7.8025e-01, -1.3313e+00],\n",
       "          [-1.2261e-01, -3.7138e-01, -2.6080e+00,  ..., -7.2437e-01,\n",
       "            2.7752e-01,  2.3769e-01]],\n",
       "\n",
       "         [[-8.5720e-02,  6.6886e-02,  2.1438e-02,  ..., -5.0474e-02,\n",
       "           -9.1062e-01, -4.9872e-02],\n",
       "          [ 1.6242e-01,  1.0454e-01, -1.6625e+00,  ...,  1.1432e+00,\n",
       "           -2.8806e-01,  6.5892e-01],\n",
       "          [-1.1909e-01, -7.1676e-01, -1.2695e+00,  ...,  1.0190e+00,\n",
       "           -8.9100e-01,  8.9781e-01],\n",
       "          ...,\n",
       "          [ 2.4821e-01,  8.1516e-01, -9.3333e-01,  ..., -5.7180e-01,\n",
       "           -1.3130e+00,  1.8800e-01],\n",
       "          [-1.6164e-02,  1.4203e+00, -1.5770e+00,  ..., -9.7311e-01,\n",
       "           -1.0645e+00,  1.8665e-01],\n",
       "          [ 1.0775e-01,  3.8071e-01, -1.1953e+00,  ..., -7.4595e-02,\n",
       "            2.6989e+00,  9.3474e-01]],\n",
       "\n",
       "         [[-1.0835e+00, -2.1533e-01,  5.7668e-01,  ..., -5.8848e-01,\n",
       "            3.1888e-01, -1.5244e-01],\n",
       "          [ 4.8932e-01,  2.0648e+00,  2.8612e-01,  ..., -1.7786e-01,\n",
       "           -4.7479e-01,  2.1718e+00],\n",
       "          [ 6.3288e-01,  1.5237e+00,  2.0409e-01,  ...,  5.0559e-02,\n",
       "           -1.7812e-01,  1.2295e+00],\n",
       "          ...,\n",
       "          [ 1.8686e+00,  1.2863e+00, -2.9339e-01,  ...,  6.9843e-01,\n",
       "           -9.1180e-01,  1.3372e+00],\n",
       "          [ 1.6602e+00,  2.1034e+00, -6.7328e-01,  ...,  5.1011e-01,\n",
       "            1.4908e-01,  6.7414e-01],\n",
       "          [ 1.1078e+00,  6.2377e-01, -4.1099e-01,  ..., -6.5872e-01,\n",
       "           -2.3511e+00, -1.6125e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 8.7414e-01, -8.3196e-01, -5.5562e-01,  ..., -7.0355e-01,\n",
       "           -4.0933e-01,  3.7644e-01],\n",
       "          [ 6.8675e-01, -9.8233e-01, -9.2800e-01,  ..., -7.1730e-01,\n",
       "           -1.4953e+00, -1.3230e+00],\n",
       "          [ 9.1623e-01, -1.9751e+00, -1.7616e+00,  ..., -8.6197e-03,\n",
       "           -9.7587e-01, -2.3569e+00],\n",
       "          ...,\n",
       "          [ 1.9210e-02, -1.2795e+00, -1.3157e-02,  ..., -5.7216e-01,\n",
       "            1.4039e+00, -8.0574e-01],\n",
       "          [ 6.7900e-01,  6.4385e-01, -9.5754e-01,  ..., -1.2473e+00,\n",
       "            4.1568e-02, -1.1206e+00],\n",
       "          [ 9.6710e-01, -6.6789e-01, -7.9581e-01,  ...,  1.7412e+00,\n",
       "            6.7048e-01, -5.2389e-01]],\n",
       "\n",
       "         [[-7.0835e-01,  2.4083e+00,  2.7163e-01,  ...,  2.6945e-01,\n",
       "            1.8442e+00, -3.9787e-01],\n",
       "          [ 1.5706e-01, -3.4948e+00,  4.9121e-01,  ...,  4.1223e-01,\n",
       "           -5.1733e+00,  1.5911e-01],\n",
       "          [ 9.3584e-01, -3.6962e+00,  4.1559e-01,  ...,  2.4091e-01,\n",
       "           -5.3373e+00,  1.0048e-01],\n",
       "          ...,\n",
       "          [ 1.2738e+00, -4.0688e+00,  9.8577e-01,  ..., -7.6206e-01,\n",
       "           -3.3955e+00,  3.8617e-01],\n",
       "          [-4.7824e-01, -4.7798e+00,  8.8071e-01,  ..., -4.9367e-01,\n",
       "           -2.5335e+00, -1.5804e-01],\n",
       "          [ 1.2832e+00, -4.0214e+00,  3.3191e-01,  ...,  1.3804e+00,\n",
       "           -3.3081e+00,  2.3362e-01]],\n",
       "\n",
       "         [[-1.8354e+00, -2.6941e-01, -1.0993e+00,  ..., -4.0523e-01,\n",
       "           -1.8190e-03,  2.9553e-01],\n",
       "          [-2.0828e-01,  3.0981e-01,  9.0816e-01,  ...,  2.8955e-01,\n",
       "            4.7910e-01,  7.8999e-01],\n",
       "          [ 1.4088e+00,  6.2306e-01,  7.9610e-01,  ...,  2.3588e-01,\n",
       "            6.8631e-01,  1.3676e+00],\n",
       "          ...,\n",
       "          [ 1.7083e+00, -1.5953e-01,  4.0742e-01,  ..., -6.2828e-01,\n",
       "            9.3649e-01, -1.2348e-01],\n",
       "          [ 2.3891e+00,  3.4919e-01,  1.4405e+00,  ..., -7.7895e-01,\n",
       "            6.9840e-01, -1.3609e+00],\n",
       "          [ 1.4040e+00,  2.9001e-01,  1.0972e+00,  ..., -7.6860e-01,\n",
       "           -1.0373e+00,  8.7131e-02]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[-0.0190, -0.0765, -0.0424,  ...,  0.1279, -0.0636,  0.0475],\n",
       "          [-0.1790, -0.0087, -0.3183,  ..., -0.0344, -0.2515, -0.0438],\n",
       "          [ 0.0104,  0.1164, -0.1390,  ...,  0.1871, -0.1671, -0.2085],\n",
       "          ...,\n",
       "          [ 0.8608,  0.7115,  0.7698,  ...,  0.4441, -0.0627,  0.7643],\n",
       "          [ 0.5301,  0.8404,  1.5253,  ...,  0.6434, -0.2175,  1.2828],\n",
       "          [ 0.8813,  0.7015,  0.6055,  ...,  0.9393, -0.8441, -0.5704]],\n",
       "\n",
       "         [[ 0.0202,  0.0457, -0.0816,  ...,  0.0678, -0.0060,  0.0267],\n",
       "          [-0.0636,  0.1559, -0.7707,  ...,  0.2351, -0.0729, -0.2515],\n",
       "          [ 0.1258,  0.1419, -0.3094,  ..., -0.1364, -0.2869, -0.3394],\n",
       "          ...,\n",
       "          [ 1.2104,  0.1229,  0.5430,  ..., -0.6587, -0.1250, -0.1446],\n",
       "          [ 0.6810, -1.0165,  0.8062,  ..., -2.5428, -0.7844,  0.5967],\n",
       "          [-0.5965, -1.3648, -2.4881,  ...,  1.1753, -0.9771,  1.5127]],\n",
       "\n",
       "         [[ 0.0768,  0.0236, -0.0593,  ..., -0.0089, -0.1168,  0.0202],\n",
       "          [ 0.1738, -0.3307, -0.0198,  ...,  0.1301, -0.4070,  0.0238],\n",
       "          [-0.2300,  0.0876, -0.2756,  ..., -0.0723, -0.1953, -0.0949],\n",
       "          ...,\n",
       "          [-0.4216, -0.1682,  0.5182,  ..., -0.0506, -0.5898,  0.3809],\n",
       "          [ 0.6983, -0.1807, -1.4435,  ...,  0.8407, -0.2086, -0.7136],\n",
       "          [ 0.7082,  1.3064, -0.0277,  ..., -2.2144,  1.0605, -1.3338]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0360,  0.0060, -0.0194,  ..., -0.0423, -0.0291,  0.0554],\n",
       "          [-0.1718, -0.4975,  0.3018,  ...,  0.0817, -0.1193,  0.0877],\n",
       "          [-0.6367,  0.5010,  0.8512,  ...,  0.7556,  0.1010,  0.6587],\n",
       "          ...,\n",
       "          [ 0.4749,  0.0965,  0.5546,  ..., -0.6786,  0.3054,  0.0695],\n",
       "          [-0.0741, -0.2385, -1.2009,  ..., -0.8113,  0.5280, -0.6684],\n",
       "          [-0.5731,  0.3547,  0.7614,  ..., -1.5478,  0.6221,  0.1204]],\n",
       "\n",
       "         [[-0.0585, -0.0177,  0.0134,  ...,  0.0672, -0.0722, -0.0751],\n",
       "          [-0.7060, -0.1354,  0.5487,  ..., -0.0961,  0.5358,  0.8762],\n",
       "          [-0.0720,  0.0891,  0.6421,  ..., -0.3245, -0.1857,  0.7516],\n",
       "          ...,\n",
       "          [-0.8501,  0.1307, -0.5797,  ...,  0.0457,  0.8882, -0.1287],\n",
       "          [-0.5179, -0.5108, -0.1249,  ..., -0.5509,  0.9103,  0.7736],\n",
       "          [-0.3450, -0.9507,  0.3352,  ...,  0.6453,  0.6853,  0.6491]],\n",
       "\n",
       "         [[-0.0179, -0.0472, -0.0579,  ..., -0.0164,  0.0320,  0.0696],\n",
       "          [ 0.0058, -0.2948, -0.3967,  ..., -0.1686,  0.6218, -0.1383],\n",
       "          [ 0.1773, -0.1753, -0.7094,  ...,  0.0066, -0.6143, -0.8782],\n",
       "          ...,\n",
       "          [ 0.2534,  0.0761,  1.3683,  ..., -0.4279, -0.0707, -0.7469],\n",
       "          [-0.8193,  0.0640,  0.2136,  ...,  0.4242,  0.2451,  1.7876],\n",
       "          [-0.7359, -1.2512, -2.6274,  ...,  0.7690, -0.1927, -0.1254]]]],\n",
       "       device='cuda:0', grad_fn=<PermuteBackward0>)), (tensor([[[[-4.2833e-01,  4.0119e-01, -7.1688e-01,  ..., -8.9434e-01,\n",
       "           -1.0990e+00,  2.5194e-01],\n",
       "          [ 1.1638e-01,  6.1153e-01, -8.7752e-01,  ...,  2.1436e+00,\n",
       "            1.2091e-01, -4.8563e-01],\n",
       "          [ 2.6422e-01,  6.8506e-01,  3.6102e-01,  ...,  2.6777e+00,\n",
       "            1.2344e+00, -1.9305e+00],\n",
       "          ...,\n",
       "          [ 8.8586e-01, -6.7127e-02,  7.5867e-01,  ...,  2.0382e+00,\n",
       "            1.9679e+00, -1.0005e+00],\n",
       "          [ 9.2929e-02,  3.0962e-02, -1.7749e-01,  ...,  1.3384e+00,\n",
       "           -5.5362e-01,  2.0228e-01],\n",
       "          [ 1.7251e+00, -4.5761e-01, -6.7784e-01,  ...,  1.7714e-01,\n",
       "            7.1203e-01,  8.1319e-01]],\n",
       "\n",
       "         [[ 5.6335e-01, -1.9005e+00,  5.1516e-02,  ...,  1.8932e-01,\n",
       "           -2.2772e+00, -4.4409e-01],\n",
       "          [ 6.8211e-01,  5.0421e-02,  1.7744e-01,  ...,  1.3284e+00,\n",
       "           -8.3552e-01, -1.3756e+00],\n",
       "          [ 1.7001e+00,  7.4201e-01, -3.0304e-01,  ...,  1.4023e+00,\n",
       "           -1.6894e-01, -4.0719e-01],\n",
       "          ...,\n",
       "          [ 1.0599e+00,  9.7945e-01,  4.8775e-02,  ..., -1.3906e-01,\n",
       "            2.9569e+00,  5.5176e-01],\n",
       "          [ 7.0662e-01,  1.3404e+00,  8.4498e-03,  ...,  1.3618e+00,\n",
       "            1.5988e+00, -1.3686e+00],\n",
       "          [ 1.2476e+00,  1.6749e+00,  4.7190e-03,  ..., -2.2534e+00,\n",
       "            2.3903e+00, -6.0317e-01]],\n",
       "\n",
       "         [[ 7.5612e-01,  3.8158e-01, -8.4937e-02,  ..., -8.7823e-01,\n",
       "           -1.2418e+00, -3.6199e-01],\n",
       "          [ 1.5409e-01, -9.1625e-02,  3.2694e-03,  ..., -9.9949e-01,\n",
       "           -1.8939e+00, -4.6256e-01],\n",
       "          [ 1.8810e-01, -3.5437e-01, -3.9867e-01,  ...,  6.8521e-02,\n",
       "           -1.3506e+00, -1.1289e+00],\n",
       "          ...,\n",
       "          [-4.2985e-01, -7.1551e-02, -9.1017e-01,  ...,  6.3849e-01,\n",
       "            5.2949e-01, -7.9018e-01],\n",
       "          [-8.4678e-02, -2.7761e-01, -6.8256e-02,  ...,  1.8074e+00,\n",
       "           -3.1844e-01,  1.4833e-02],\n",
       "          [ 3.7730e-02, -1.9163e+00,  1.2448e+00,  ...,  1.2232e-01,\n",
       "            3.5409e-01,  4.9997e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.9584e-01, -3.3335e-01,  4.9308e-01,  ..., -5.7565e-01,\n",
       "            9.5598e-01,  2.0867e-01],\n",
       "          [-7.6755e-01,  8.3844e-01, -1.4696e+00,  ..., -3.6185e+00,\n",
       "            7.7263e-01,  8.5823e-01],\n",
       "          [-9.4201e-01,  9.2409e-01, -1.8947e+00,  ..., -3.9799e+00,\n",
       "            5.2653e-02,  2.3416e-01],\n",
       "          ...,\n",
       "          [-2.5086e+00,  2.0617e+00, -4.2726e-01,  ..., -1.1746e+00,\n",
       "            9.2659e-01,  5.7983e-01],\n",
       "          [-3.7109e+00,  1.0691e+00,  2.5062e-01,  ..., -1.2587e+00,\n",
       "           -2.9028e+00,  1.8281e+00],\n",
       "          [-1.0435e+00, -2.7766e-01, -9.8826e-01,  ..., -4.3700e+00,\n",
       "           -1.3780e+00, -6.3088e-01]],\n",
       "\n",
       "         [[ 1.0397e-02,  3.7879e-01,  3.1131e-01,  ...,  4.2854e-01,\n",
       "            3.7295e-02,  6.1596e-01],\n",
       "          [ 5.7676e-01,  1.2840e+00,  1.0258e+00,  ...,  5.0608e-01,\n",
       "            7.9394e-01,  1.0510e+00],\n",
       "          [-7.6680e-02,  2.1751e+00,  5.1605e-01,  ..., -9.7608e-01,\n",
       "            2.2116e-01,  8.6639e-01],\n",
       "          ...,\n",
       "          [ 6.8581e-01,  9.5732e-01, -1.4903e+00,  ..., -1.4521e+00,\n",
       "           -8.9020e-01, -1.6430e+00],\n",
       "          [ 2.2314e-01, -1.4309e+00, -8.0343e-01,  ...,  4.3502e-01,\n",
       "            4.5748e-02, -1.2316e+00],\n",
       "          [-1.5136e-01, -1.9652e+00, -1.5761e-01,  ...,  9.4936e-01,\n",
       "            1.3235e+00,  4.6285e-01]],\n",
       "\n",
       "         [[-5.1308e-01,  1.4424e-01, -1.3822e+00,  ..., -3.1163e-01,\n",
       "            2.3875e-01, -1.3048e+00],\n",
       "          [-4.4983e-01, -6.6438e-01,  2.1105e-01,  ...,  1.0483e+00,\n",
       "            9.5588e-01, -1.2768e+00],\n",
       "          [-9.4926e-01,  4.8960e-02, -1.5164e+00,  ...,  6.2954e-01,\n",
       "            1.4325e+00, -5.4650e-01],\n",
       "          ...,\n",
       "          [ 8.2360e-01,  2.3695e+00,  2.0068e+00,  ...,  1.2966e-01,\n",
       "           -2.7034e-01,  3.4984e-01],\n",
       "          [ 9.8558e-01,  8.3916e-02,  5.3647e-01,  ...,  1.2984e+00,\n",
       "           -1.4363e+00,  2.7236e+00],\n",
       "          [-2.3753e+00, -1.7018e+00,  4.5031e-01,  ...,  2.6782e+00,\n",
       "           -8.6351e-01, -5.1981e-01]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[-3.7526e-02,  2.7923e-02, -5.2675e-02,  ..., -2.2516e-03,\n",
       "           -5.4810e-02, -2.7626e-02],\n",
       "          [ 2.3330e-01, -1.4482e-01,  7.3012e-01,  ..., -2.5168e-01,\n",
       "           -3.6763e-01,  5.2084e-01],\n",
       "          [-4.3621e-01, -3.9911e-01,  5.2653e-03,  ...,  2.0098e-01,\n",
       "            4.8707e-01, -3.4185e-01],\n",
       "          ...,\n",
       "          [ 7.0236e-01,  2.2150e-01, -2.9017e-01,  ..., -2.0959e-01,\n",
       "            3.5382e-02, -8.9983e-02],\n",
       "          [ 1.0080e+00,  3.6086e-02, -2.4421e+00,  ...,  2.0403e-01,\n",
       "           -9.2016e-01, -9.2373e-01],\n",
       "          [ 7.7469e-01,  1.0134e+00, -1.9460e-01,  ..., -1.3042e-01,\n",
       "            1.0256e+00, -3.2485e-01]],\n",
       "\n",
       "         [[-6.9995e-03,  1.6803e-02,  4.6388e-02,  ..., -1.9624e-02,\n",
       "           -8.5326e-03, -3.6014e-02],\n",
       "          [-2.1148e-01,  3.8860e-01,  1.9330e-01,  ...,  2.2063e-01,\n",
       "           -2.8770e-01,  9.5667e-02],\n",
       "          [-1.5418e-01,  4.2292e-01,  3.5209e-01,  ...,  3.4114e-01,\n",
       "            9.0835e-03,  3.3256e-01],\n",
       "          ...,\n",
       "          [ 2.5614e-01,  1.0447e+00,  1.0071e-01,  ..., -1.3430e+00,\n",
       "            2.5056e-01, -6.6234e-01],\n",
       "          [ 5.4001e-02, -1.3128e+00,  9.6416e-01,  ..., -1.0019e+00,\n",
       "           -1.8363e-01, -7.6541e-01],\n",
       "          [ 1.5871e+00, -4.3698e+00,  1.4128e+00,  ..., -2.4644e+00,\n",
       "           -1.0057e+00,  1.6049e+00]],\n",
       "\n",
       "         [[ 4.8382e-02, -4.5176e-03, -9.5268e-02,  ..., -2.9838e-02,\n",
       "            5.3437e-02,  1.0858e-02],\n",
       "          [ 3.3203e-01,  2.0448e-01,  2.9551e-01,  ..., -4.5296e-02,\n",
       "            4.2294e-01, -2.5559e-01],\n",
       "          [-2.1841e-01, -2.0459e-02,  2.0897e-01,  ...,  2.2263e-01,\n",
       "           -7.7524e-01,  6.2625e-02],\n",
       "          ...,\n",
       "          [-4.9797e-01, -2.3504e-01,  2.8933e-01,  ...,  3.1015e-01,\n",
       "           -1.0535e-01, -2.0000e-01],\n",
       "          [-1.3433e+00,  2.5012e-01, -6.0040e-01,  ..., -1.3830e-01,\n",
       "            5.3113e-01, -6.0073e-02],\n",
       "          [ 1.7485e-01, -8.0855e-01,  8.6254e-01,  ..., -9.7438e-01,\n",
       "            1.0562e-01, -5.0944e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.1053e-01, -2.7636e-02,  1.4724e-02,  ..., -1.0697e-01,\n",
       "           -7.7417e-02, -1.1279e-02],\n",
       "          [-1.0301e-01,  7.0053e-02,  3.0764e-01,  ..., -7.2358e-01,\n",
       "           -1.1502e+00,  1.6529e-01],\n",
       "          [ 3.5984e-01,  3.8626e-02,  7.4935e-01,  ...,  9.7463e-02,\n",
       "           -5.9644e-01,  1.4069e-01],\n",
       "          ...,\n",
       "          [-4.9541e-01,  2.3009e-01, -6.6513e-01,  ...,  3.9666e-01,\n",
       "            7.3364e-01,  2.7093e-01],\n",
       "          [ 5.6509e-01, -5.2380e-01, -8.8856e-01,  ..., -6.1650e-01,\n",
       "           -6.3938e-01,  2.5930e-01],\n",
       "          [-4.9213e-01,  4.8602e-01, -6.9618e-02,  ..., -7.3391e-01,\n",
       "           -4.1955e-01, -3.7190e-01]],\n",
       "\n",
       "         [[ 9.6703e-02, -6.4121e-02,  1.1108e-01,  ...,  5.8712e-02,\n",
       "           -1.7044e-02,  6.2150e-02],\n",
       "          [ 2.2069e-01,  5.3800e-01,  1.2339e+00,  ...,  2.1216e-01,\n",
       "            6.0625e-01,  1.1651e-01],\n",
       "          [-4.2379e-01,  4.8064e-02,  9.6946e-01,  ...,  3.9437e-01,\n",
       "            1.3823e+00, -1.0728e+00],\n",
       "          ...,\n",
       "          [ 2.1293e-01,  9.2398e-01,  6.8560e-01,  ..., -9.3987e-02,\n",
       "            3.6338e-01, -6.2850e-01],\n",
       "          [ 2.0134e-01, -6.1853e-01, -5.1163e-01,  ..., -3.7742e-01,\n",
       "            9.4697e-01,  1.3415e+00],\n",
       "          [ 1.2218e+00,  2.7610e-01,  3.0190e+00,  ...,  2.6295e+00,\n",
       "            3.9637e+00,  1.7359e+00]],\n",
       "\n",
       "         [[-1.0726e-01,  4.1451e-02, -6.5714e-02,  ..., -1.0736e-01,\n",
       "            2.5596e-01,  6.3685e-02],\n",
       "          [-5.0980e-01,  2.5806e-01, -2.7699e-01,  ..., -2.9918e-01,\n",
       "            2.0003e-01,  3.9059e-01],\n",
       "          [-2.3359e-01,  5.0709e-01, -4.8002e-01,  ...,  2.4822e-02,\n",
       "            5.4253e-01, -4.8311e-01],\n",
       "          ...,\n",
       "          [ 4.9087e-01,  2.8361e-01,  3.0637e-01,  ...,  1.5158e-01,\n",
       "           -1.1434e+00,  1.5296e-01],\n",
       "          [ 6.7631e-01,  1.8988e-01, -6.5552e-01,  ..., -1.7095e-01,\n",
       "           -2.5397e-01,  6.2007e-01],\n",
       "          [-2.0218e-01,  6.0629e-01, -3.6095e-01,  ..., -1.8175e-01,\n",
       "           -1.4935e+00,  6.3679e-01]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[-1.5048, -0.3655, -0.3176,  ...,  0.2945,  0.4740, -0.4216],\n",
       "          [ 1.7445, -0.9015, -0.9502,  ...,  0.6803, -0.7974,  0.0727],\n",
       "          [ 0.8478, -1.4312, -0.2897,  ...,  1.2900, -0.8248, -0.0814],\n",
       "          ...,\n",
       "          [ 0.9461, -0.1709, -0.2567,  ...,  0.5853,  0.4585,  0.3012],\n",
       "          [ 1.9240,  0.3753, -1.1677,  ...,  0.6261, -1.0396,  0.3416],\n",
       "          [ 1.6134, -0.0935,  0.5670,  ..., -0.8710, -2.0859, -0.7878]],\n",
       "\n",
       "         [[ 0.2264, -0.3188,  1.9831,  ...,  0.2838, -0.0204, -0.1733],\n",
       "          [ 0.9626, -0.9672, -0.7345,  ...,  0.3543, -0.4477, -0.9536],\n",
       "          [ 0.7963, -1.2603, -1.7316,  ...,  0.5586, -0.6859, -0.7541],\n",
       "          ...,\n",
       "          [ 0.2094, -0.6958, -1.1682,  ..., -0.3977, -0.8803, -0.3158],\n",
       "          [ 0.6769, -1.4065, -0.7633,  ..., -0.3663, -0.4704, -0.7464],\n",
       "          [ 0.8182, -0.2300, -0.7829,  ..., -1.1434, -0.3024, -0.6757]],\n",
       "\n",
       "         [[ 0.0299,  1.0962,  0.3237,  ..., -0.5227,  0.4827, -0.1406],\n",
       "          [-0.0820,  1.0275,  0.4286,  ...,  1.4535,  0.9308, -0.5109],\n",
       "          [-0.5877,  0.4889,  0.7799,  ...,  1.5119,  1.1832,  0.0445],\n",
       "          ...,\n",
       "          [-0.8966, -0.4631, -0.2403,  ...,  0.8140, -0.0962, -0.5373],\n",
       "          [-1.0091,  0.3007, -0.0166,  ..., -0.5937,  1.3064, -0.1100],\n",
       "          [ 0.8368,  0.1835, -0.4055,  ...,  1.4378,  0.5481, -0.4359]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.6139,  0.9203, -0.7404,  ..., -0.7381,  0.7569,  0.8474],\n",
       "          [ 0.5317,  0.5609, -0.5017,  ..., -0.6295,  0.4701,  0.7266],\n",
       "          [-0.0836,  0.1750, -0.3670,  ..., -0.8601,  0.5581, -0.3255],\n",
       "          ...,\n",
       "          [-1.0329,  0.9417,  1.4676,  ..., -0.1111, -0.5468, -1.3466],\n",
       "          [ 0.1309,  1.0380,  0.3225,  ..., -0.6756,  0.7887, -0.5205],\n",
       "          [-2.7255, -0.9396, -1.0175,  ...,  0.9740, -0.9082,  0.0586]],\n",
       "\n",
       "         [[-0.4332,  0.4827,  0.2152,  ...,  0.3254, -0.1317, -0.2257],\n",
       "          [-1.2258,  1.3802, -1.9712,  ...,  0.0138, -0.8335, -0.7315],\n",
       "          [-1.1823,  1.2860, -0.9657,  ...,  0.8041, -1.2825, -0.6479],\n",
       "          ...,\n",
       "          [-1.4934,  0.2745, -0.6567,  ..., -0.5868, -1.6948, -0.1512],\n",
       "          [-0.7967, -0.1291, -0.2830,  ..., -0.1884, -1.5578, -0.6648],\n",
       "          [ 0.2441, -1.4639, -1.0149,  ...,  0.1597, -1.1423,  0.5776]],\n",
       "\n",
       "         [[-0.8536, -0.6226,  0.7523,  ...,  0.4060,  0.5306,  0.1347],\n",
       "          [-1.1564, -2.9920,  3.4981,  ...,  2.2504,  1.6697,  1.1044],\n",
       "          [-0.8049, -0.9299,  1.3115,  ...,  0.4833, -0.9292,  0.9483],\n",
       "          ...,\n",
       "          [-0.1148, -1.4088,  1.5591,  ..., -1.0088, -0.8051,  0.3165],\n",
       "          [ 0.5216, -0.5913,  1.8569,  ..., -0.0347, -0.6184,  0.3831],\n",
       "          [ 0.4885, -1.2989,  3.0939,  ...,  0.9915,  0.8954, -0.0272]]]],\n",
       "       device='cuda:0', grad_fn=<PermuteBackward0>), tensor([[[[-9.2268e-02,  4.0138e-02, -2.2460e-01,  ..., -3.1631e-01,\n",
       "            2.9635e-01, -9.7802e-02],\n",
       "          [-7.4926e-01, -2.0352e-01,  4.9592e-01,  ...,  1.0409e+00,\n",
       "            1.4757e-01,  7.7034e-01],\n",
       "          [ 3.5785e-01,  2.2947e-01,  6.9549e-01,  ...,  1.8727e+00,\n",
       "           -5.3698e-01,  1.4875e+00],\n",
       "          ...,\n",
       "          [ 1.9701e+00, -5.0417e-01, -4.0414e-01,  ..., -7.0796e-02,\n",
       "           -1.4605e+00,  1.6840e+00],\n",
       "          [ 1.0876e+00, -1.5279e+00,  7.3467e-01,  ...,  6.8719e-01,\n",
       "            4.7327e-01,  1.4645e-01],\n",
       "          [-5.5603e-01,  3.7557e-01, -4.4664e+00,  ...,  1.9154e+00,\n",
       "           -2.2398e+00,  2.5600e+00]],\n",
       "\n",
       "         [[ 5.2639e-02,  1.1032e-01, -1.5635e-01,  ..., -3.0815e-02,\n",
       "           -1.2518e-01,  2.3706e-01],\n",
       "          [-2.9925e-01,  3.8152e-01, -4.5563e-01,  ...,  1.1521e-01,\n",
       "           -2.9767e-01,  3.7977e-01],\n",
       "          [-9.3882e-01,  3.5888e-01,  2.0390e-02,  ..., -3.5800e-01,\n",
       "           -4.1639e-01,  6.9946e-01],\n",
       "          ...,\n",
       "          [ 1.0691e-01,  2.4415e-01,  3.9023e-01,  ...,  2.0034e-01,\n",
       "            9.5098e-02,  5.4304e-01],\n",
       "          [-7.0797e-02, -5.8903e-01, -1.5210e+00,  ...,  5.2678e-01,\n",
       "            8.1986e-01,  4.2475e-01],\n",
       "          [-1.9166e+00, -1.4382e-02, -3.8578e-01,  ...,  2.0354e+00,\n",
       "           -1.2715e+00, -4.7379e-01]],\n",
       "\n",
       "         [[ 8.4900e-02,  4.7989e-02,  4.3692e-02,  ...,  1.2683e-01,\n",
       "            4.4727e-02,  8.5139e-02],\n",
       "          [ 2.4059e-01, -1.8757e-01,  4.3986e-01,  ...,  9.5578e-01,\n",
       "           -1.2711e-01,  2.1678e-01],\n",
       "          [-7.2067e-01, -6.4289e-02,  1.3092e-01,  ..., -4.8219e-01,\n",
       "            4.1917e-01, -1.6609e-01],\n",
       "          ...,\n",
       "          [-8.7433e-01,  2.4720e-01, -9.9506e-01,  ..., -2.4358e-01,\n",
       "           -2.1130e-01, -4.9095e-01],\n",
       "          [ 7.5933e-02, -1.3066e+00,  3.9015e-01,  ...,  1.4342e-01,\n",
       "           -1.2999e+00, -1.9982e+00],\n",
       "          [-1.6529e+00,  9.8755e-01,  4.3088e-01,  ..., -4.1497e+00,\n",
       "           -1.8465e+00, -4.5113e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 4.0527e-02,  8.6179e-02,  9.1670e-03,  ...,  5.5687e-02,\n",
       "           -3.9958e-03,  2.8480e-03],\n",
       "          [ 6.5457e-02,  5.4259e-01,  5.3600e-01,  ...,  1.1442e-01,\n",
       "            3.7120e-02,  1.2222e-01],\n",
       "          [-3.4592e-01,  7.0790e-01, -3.0636e-01,  ...,  1.3374e-01,\n",
       "            3.7890e-01,  4.0651e-01],\n",
       "          ...,\n",
       "          [-5.8367e-01,  2.0491e-01, -8.4521e-01,  ...,  1.5429e+00,\n",
       "           -4.7018e-01,  3.9475e-01],\n",
       "          [-3.7567e-01, -4.6717e-02, -2.1022e-01,  ...,  4.5731e-01,\n",
       "            6.6336e-03, -1.6766e+00],\n",
       "          [ 3.8326e-01,  3.2322e-02, -7.5032e-01,  ...,  2.0903e+00,\n",
       "            1.1470e+00,  1.5780e+00]],\n",
       "\n",
       "         [[ 1.5685e-02, -8.0025e-02,  2.6944e-02,  ..., -9.7456e-02,\n",
       "            6.2074e-02, -8.1147e-02],\n",
       "          [-5.0784e-01, -9.5583e-02,  6.8213e-01,  ...,  7.2852e-02,\n",
       "           -1.4960e-02, -6.5167e-02],\n",
       "          [ 4.2610e-02, -1.0781e-02,  1.7646e-01,  ...,  1.9041e-01,\n",
       "            8.3044e-01, -6.9885e-02],\n",
       "          ...,\n",
       "          [-5.2934e-01,  3.5324e-01,  2.4530e-01,  ...,  4.1069e-01,\n",
       "           -1.4655e-01, -5.5327e-01],\n",
       "          [-4.9828e-01,  7.2298e-01,  4.1905e-01,  ...,  1.7218e+00,\n",
       "           -7.4260e-01,  8.6987e-01],\n",
       "          [-2.5850e-01, -5.1415e-01, -2.9700e-01,  ..., -5.1235e-01,\n",
       "            3.0946e-02, -4.1542e-01]],\n",
       "\n",
       "         [[ 2.2753e-01,  5.2361e-02, -2.6776e-01,  ...,  3.7044e-01,\n",
       "            1.7803e-01,  6.4308e-02],\n",
       "          [ 9.3284e-01,  1.3933e+00, -3.0063e+00,  ...,  3.4657e+00,\n",
       "            1.9156e+00,  7.2947e-01],\n",
       "          [-2.5834e-02, -1.7672e-01, -5.9644e-01,  ..., -1.6570e-01,\n",
       "            2.7773e-01,  4.0972e-01],\n",
       "          ...,\n",
       "          [ 1.0988e+00,  1.0014e+00,  7.6467e-01,  ...,  1.1725e-01,\n",
       "            1.1107e-01, -1.6653e-01],\n",
       "          [ 1.5394e-01, -6.9176e-01,  5.3755e-02,  ..., -1.5934e-01,\n",
       "            2.2135e-01,  9.4580e-01],\n",
       "          [ 4.8940e-01,  2.1415e+00, -1.5182e-01,  ...,  1.9921e+00,\n",
       "            4.0293e+00,  5.8001e-01]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>))), decoder_hidden_states=None, decoder_attentions=None, cross_attentions=None, encoder_last_hidden_state=tensor([[[-0.2607,  0.0198,  0.4755,  ..., -0.0941, -0.0225, -0.3256],\n",
       "         [-0.0041, -0.0816,  0.2196,  ...,  0.2457, -0.3431,  0.1485],\n",
       "         [ 0.3718, -0.6029, -0.0986,  ..., -0.0779, -0.3115, -0.4040],\n",
       "         ...,\n",
       "         [-0.4011,  0.0278,  0.4655,  ..., -0.1463, -0.0469, -0.1834],\n",
       "         [-0.3879, -0.2103, -0.5007,  ...,  0.1551, -0.2414, -0.0241],\n",
       "         [-0.2757, -0.2442,  0.2686,  ..., -0.1122,  0.4609,  0.2692]]],\n",
       "       device='cuda:0', grad_fn=<CopySlices>), encoder_hidden_states=None, encoder_attentions=None)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(pixel_values, labels=output_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "cf1479fa-ffb0-44a6-886b-20963f3ea668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_attentions <class 'bool'>\n",
      "output_hidden_states <class 'bool'>\n",
      "return_dict <class 'bool'>\n",
      "pixel_values <class 'torch.Tensor'>\n",
      "---- RETURN VAL ---\n",
      "<class 'transformers.modeling_outputs.BaseModelOutputWithPooling'>\n",
      "last_hidden_state torch.Size([1, 197, 768])\n",
      "pooler_output torch.Size([1, 768])\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'a person standing next to a pile of luggage'"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_ids = model.generate(pixel_values, **gen_kwargs)\n",
    "tokenizer.batch_decode(output_ids, skip_special_tokens=True)[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8e72e194-3bce-4915-9055-634d59eb4b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "handle.remove()\n",
    "def hook(m, input, output):\n",
    "    print(type(m))\n",
    "    print('Input shapes', type(input), len(input))\n",
    "    \n",
    "    if isinstance(input, tuple):\n",
    "        for x in input:\n",
    "            print(type(x))\n",
    "    print('Output shapes')\n",
    "    \n",
    "    print(type(output))\n",
    "    \n",
    "    \n",
    "    print(output.shape)\n",
    "\n",
    "handle = model.decoder.register_forward_hook(hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "759fdb7c-65ac-408a-aad0-112be5d43220",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "image_path = 'croissant.jpg'\n",
    "image = Image.open(image_path)\n",
    "if image.mode != \"RGB\":\n",
    "    image = image.convert(mode=\"RGB\")\n",
    "pixel_values = feature_extractor(images=[image], return_tensors=\"pt\").pixel_values.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tp2",
   "language": "python",
   "name": "tp2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
