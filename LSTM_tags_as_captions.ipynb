{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UQV_srHuyd5m"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import string\n",
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import pandas as pd\n",
        "import torch.nn as nn \n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from pathlib import Path\n",
        "import json\n",
        "import tqdm\n",
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "import warnings\n",
        "# UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() \n",
        "# or sourceTensor.clone().detach().requires_grad_(True) rather than torch.tensor(sourceTensor)\n",
        "warnings.simplefilter(\"ignore\", category=UserWarning)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuWy0Yr2YhF6",
        "outputId": "73ccb47e-5dde-4120-9197-e3fc445679bd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data loading and cleanup"
      ],
      "metadata": {
        "id": "6A5MREmEh5R-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jn1cBOr-ygSc"
      },
      "outputs": [],
      "source": [
        "JAMENDO_TAGS = np.array(['genre---alternative','genre---ambient','genre---atmospheric','genre---chillout','genre---classical','genre---dance','genre---downtempo','genre---easylistening','genre---electronic','genre---experimental','genre---folk','genre---funk','genre---hiphop','genre---house','genre---indie','genre---instrumentalpop','genre---jazz','genre---lounge','genre---metal','genre---newage','genre---orchestral','genre---pop','genre---popfolk','genre---poprock','genre---reggae','genre---rock','genre---soundtrack','genre---techno','genre---trance','genre---triphop','genre---world','instrument---acousticguitar','instrument---bass','instrument---computer','instrument---drummachine','instrument---drums','instrument---electricguitar','instrument---electricpiano','instrument---guitar','instrument---keyboard','instrument---piano','instrument---strings','instrument---synthesizer','instrument---violin','instrument---voice','mood/theme---emotional','mood/theme---energetic','mood/theme---film','mood/theme---happy','mood/theme---relaxing'])\n",
        "\n",
        "def get_top_tags(scores, k=3, threshold=.4):\n",
        "    assert scores.shape == (2, 50)\n",
        "    scores = (scores[0]+scores[1])/2\n",
        "    indices = np.where(scores>threshold)[0]\n",
        "    sorted_indices = indices[np.argsort(-scores[indices])[:k]]\n",
        "    return JAMENDO_TAGS[sorted_indices]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "fWxKJWy6YUmV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jam_tags = {}\n",
        "jam_pred_tags = {}\n",
        "jam_embeddings = {}\n",
        "jam_scores = {}\n",
        "\n",
        "jam_embeddings_dir = Path('/content/drive/MyDrive/jam_embeddings')\n",
        "\n",
        "for i in tdqm.tqdm(range(100)):\n",
        "    try:\n",
        "        with open(jam_embeddings_dir / f'tags_{i:02d}.json') as f:\n",
        "            jam_tags.update(json.load(f))\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        continue\n",
        "    data_dict = np.load(jam_embeddings_dir / f'embeddings_{i:02d}.npy', allow_pickle=True)\n",
        "    jam_embeddings.update(data_dict.item())\n",
        "    data_dict = np.load(jam_embeddings_dir / f'tag_scores_{i:02d}.npy', allow_pickle=True)\n",
        "    jam_scores.update(data_dict.item())\n",
        "    \n",
        "for k, v in jam_scores.items():\n",
        "    jam_pred_tags[k] = get_top_tags(v, k=3, threshold=0.4)\n",
        "    \n",
        "pred_tag_counts = np.array([len(v) for v in jam_pred_tags.values()])\n",
        "print(f'avg number of pred tags = {(pred_tag_counts).mean()}, fraction of samples with 0 pred tags = {(pred_tag_counts==0).mean()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmsfUKARYbkB",
        "outputId": "8536b5ff-65fc-4c8c-dd63-30749e84b5b9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/jam_embeddings/tags_35.json'\n",
            "avg number of pred tags = 1.1215934627170583, fraction of samples with 0 pred tags = 0.21151453245426688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cleaning_text(caption):\n",
        "    table = str.maketrans('','',string.punctuation)\n",
        "    caption = caption.replace(\"---\",\" \")\n",
        "    #caption = caption.replace(\"---\",\": \")\n",
        "    # split the sentences into words\n",
        "    desc = caption.split()\n",
        "    #converts to lower case\n",
        "    desc = [word.lower() for word in desc]\n",
        "    #remove punctuation from each token\n",
        "    desc = [word.translate(table) for word in desc]\n",
        "    #remove hanging 's and a \n",
        "    desc = [word for word in desc if(len(word)>1)]\n",
        "    #remove tokens with numbers in them\n",
        "    desc = [word for word in desc if(word.isalpha())]\n",
        "    #convert back to string\n",
        "    caption = ' '.join(desc)\n",
        "\n",
        "    return caption\n",
        "\n",
        "def preprocess_captions(captions):\n",
        "    preprocessed_captions = {}\n",
        "    for audio_file in tqdm.tqdm(captions):\n",
        "      text_caption = \", \".join(captions[audio_file])\n",
        "      preprocessed_captions[audio_file] = cleaning_text(text_caption)\n",
        "            \n",
        "    return preprocessed_captions\n",
        "\n",
        "#captions = dict(zip(df.ytid,df.caption))\n",
        "jam_tags_processed = preprocess_captions(jam_tags)\n",
        "jam_pred_tags_processed = preprocess_captions(jam_pred_tags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NG6W6sPQaEl-",
        "outputId": "1a376a49-102a-4f71-d03a-d0d7701561b0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 269225/269225 [00:04<00:00, 56426.28it/s]\n",
            "100%|██████████| 269225/269225 [00:02<00:00, 107242.46it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define a vocabulary\n",
        "def text_vocabulary(descriptions):\n",
        "    captions = list(descriptions.values())\n",
        "    vocab = set(['<start>', '<end>', ':', ',', ';'])\n",
        "    for caption in captions:\n",
        "        for token in caption.strip().split():\n",
        "            vocab.add(token)\n",
        "    return vocab\n",
        "\n",
        "# force <pad> to have idx 0 (convention)\n",
        "vocab = ['<pad>'] + list(text_vocabulary(jam_pred_tags_processed)) + list(text_vocabulary(jam_tags_processed))\n",
        "\n",
        "word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
        "idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n",
        "\n",
        "def tokenize(caption):\n",
        "    caption = cleaning_text(caption)\n",
        "    token_list = []\n",
        "    # Add <start> to the beginning and <end> to the end of each caption\n",
        "    caption_list = [\"<start>\"] + caption.split() + [\"<end>\"]\n",
        "    token_list = [word_to_idx[word] for word in caption_list]\n",
        "    return token_list \n"
      ],
      "metadata": {
        "id": "5JRvYRpODyuc"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the audio captioning dataset\n",
        "class JamendoTagDataset(Dataset):\n",
        "    def __init__(self, jam_tags, jam_pred_tags, jam_embeddings):\n",
        "        \n",
        "        self.keys = sorted(jam_tags.keys())\n",
        "        self.jam_tags = jam_tags\n",
        "        self.jam_pred_tags = jam_pred_tags\n",
        "        self.jam_embeddings = jam_embeddings\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.jam_tags)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        id = self.keys[idx]\n",
        "        \n",
        "        tags = self.jam_tags[id]\n",
        "        categories = defaultdict(set)\n",
        "        for t in tags:\n",
        "            assert '---' in t\n",
        "            categories[t[:t.find('---')]].add(t[t.find('---')+3:])\n",
        "            \n",
        "        result = []\n",
        "        for k in sorted(categories.keys()):\n",
        "            cat_tags = list(categories[k])\n",
        "            result.append(k + ': ' + ', '.join(random.sample(cat_tags, len(cat_tags))))\n",
        "        tags_cap = '; '.join(result)\n",
        "            \n",
        "        #tags = [t.replace('---', ': ') for t in tags]\n",
        "        #tags = [t[t.find('---')+3:] if '---' in t else t for t in tags]\n",
        "        #random.shuffle(tags)\n",
        "        #tags_cap = ', '.join(tags)\n",
        "        \n",
        "        emb = self.jam_embeddings[id]\n",
        "        assert emb.shape == (2, 256)\n",
        "        emb = np.concatenate([emb[0],emb[1]])\n",
        "        assert emb.shape == (512,)\n",
        "        \n",
        "        return {\"song_id\": id.split(\"_\")[0], \"start_timestep\": id.split(\"_\")[1], \"caption\": tags_cap, \"tokenized_caption\":tokenize(tags_cap), \"embedding\":torch.from_numpy(emb).to(device)}\n",
        "      "
      ],
      "metadata": {
        "id": "UJjE6vT-ctgd"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_frac = 0.8\n",
        "song_ids = list(set([x.split(\"_\")[0] for x in jam_tags]))\n",
        "# split efficiently dicts!\n",
        "train_mask = random.choices([True, False], weights=[0.8, 0.2], k=len(song_ids))\n",
        "song_is_train = {}\n",
        "for i, song in enumerate(song_ids):\n",
        "  song_is_train[song] = train_mask[i]\n",
        "\n",
        "train_jam_tags = {x: jam_tags[x] for x in jam_tags if song_is_train[x.split(\"_\")[0]]}\n",
        "test_jam_tags = {x: jam_tags[x] for x in jam_tags if not song_is_train[x.split(\"_\")[0]]}\n",
        "train_jam_pred_tags = {x: jam_pred_tags[x] for x in jam_pred_tags if song_is_train[x.split(\"_\")[0]]}\n",
        "test_jam_pred_tags = {x: jam_pred_tags[x] for x in jam_pred_tags if not song_is_train[x.split(\"_\")[0]]}\n",
        "train_jam_embeddings = {x: jam_embeddings[x] for x in jam_embeddings if song_is_train[x.split(\"_\")[0]]}\n",
        "test_jam_embeddings = {x: jam_embeddings[x] for x in jam_embeddings if not song_is_train[x.split(\"_\")[0]]}\n",
        "\n",
        "training_data = JamendoTagDataset(train_jam_tags, train_jam_pred_tags, train_jam_embeddings)\n",
        "test_data = JamendoTagDataset(test_jam_tags, test_jam_pred_tags, test_jam_embeddings)\n",
        "\n",
        "print(len(training_data), len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QY_NIrVWPjKk",
        "outputId": "6860a8cd-f649-49f7-b76d-a6852ed5de2f"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "215270 53955\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "id": "3bxXFD39yrop"
      },
      "outputs": [],
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers=1, dropout=0.4):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "        self.embedding.weight.data.uniform_(-0.1, 0.1)\n",
        "        self.fc.weight.data.uniform_(-0.1, 0.1)\n",
        "        self.fc.bias.data.fill_(0)\n",
        "\n",
        "    def forward(self, input, features):\n",
        "        embedded = self.embedding(input)\n",
        "        embedded = self.dropout(embedded)\n",
        "        # concatenate audio features and input embedding\n",
        "        inputs = torch.cat((features.unsqueeze(1), embedded), dim=1)\n",
        "        output, hidden = self.lstm(inputs)\n",
        "        output = self.fc(output)[:,1:,:]\n",
        "\n",
        "        return output, hidden\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model training"
      ],
      "metadata": {
        "id": "OyEupqq4h1ef"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "id": "XdgSIIL_ywb7"
      },
      "outputs": [],
      "source": [
        "# Instantiate the model\n",
        "vocab_size = len(vocab)\n",
        "input_size = vocab_size\n",
        "hidden_size = 512\n",
        "output_size = vocab_size\n",
        "num_layers = 2\n",
        "model = LSTMModel(input_size, hidden_size, output_size, num_layers)\n",
        "\n",
        "\n",
        "# Train the model\n",
        "lr = 5e-4\n",
        "batch_size = 512\n",
        "num_epochs = 20\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=word_to_idx['<pad>'])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "scheduler = StepLR(optimizer, step_size=10, gamma=0.5)\n",
        "loss_fn = nn.CrossEntropyLoss(ignore_index=word_to_idx['<pad>'])\n",
        "\n",
        "# Define the collate function for the audio captioning dataset\n",
        "def collate_fn_try(batch):\n",
        "    embeddings = []\n",
        "    captions = []\n",
        "    for b in batch:\n",
        "        embeddings.append(b['embedding'])\n",
        "        captions.append(torch.tensor(b['tokenized_caption']))\n",
        "    padded_embeddings = nn.utils.rnn.pad_sequence(embeddings, batch_first=True)\n",
        "    padded_captions = nn.utils.rnn.pad_sequence(captions, batch_first=True, padding_value=word_to_idx[\"<pad>\"])  # Use the <pad> index for padding\n",
        "    return padded_embeddings.to(device, dtype=torch.float), padded_captions.to(device, dtype=torch.long)\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size, shuffle=True, collate_fn=collate_fn_try)\n",
        "eval_train_dataloader = DataLoader(training_data, batch_size, shuffle=True, collate_fn=collate_fn_try)\n",
        "eval_test_dataloader = DataLoader(test_data, batch_size, shuffle=True, collate_fn=collate_fn_try)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpK5VM4Byy9I",
        "outputId": "8ea78819-285c-4b03-83c5-8502b9ea5753"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings batch, shape=torch.Size([512, 512])\n",
            "Captions batch, shape=torch.Size([512, 36])\n"
          ]
        }
      ],
      "source": [
        "# load a batch\n",
        "batch = next(iter(train_dataloader))\n",
        "print(f\"Embeddings batch, shape={batch[0].shape}\")\n",
        "print(f\"Captions batch, shape={batch[1].shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_caption(idx, train, max_caption_length=64, show_true_caption=True, show_ytid=True):\n",
        "\n",
        "  if train:\n",
        "    true_tags = training_data[idx][\"caption\"]\n",
        "    embedding = training_data[idx][\"embedding\"]\n",
        "  else:\n",
        "    true_tags = test_data[idx][\"caption\"]\n",
        "    embedding = test_data[idx][\"embedding\"]\n",
        "\n",
        "  x = embedding.unsqueeze(0).to(device, dtype=torch.float)\n",
        "  model.eval()\n",
        "  # breaks if starting sequence is only one token (?)\n",
        "  caption = torch.tensor([word_to_idx[word] for word in ['<pad>', '<start>']]).unsqueeze(0).to(device)\n",
        "\n",
        "  # Generate the caption word by word\n",
        "  with torch.no_grad():\n",
        "      while caption[0][-1] != word_to_idx['<end>'] and len(caption[0]) < max_caption_length:\n",
        "          logits, hidden = model(caption[:, :-1], x)\n",
        "          predicted_word_index = logits.argmax(-1)[:, -1].item()\n",
        "          predicted_word = idx_to_word[predicted_word_index]\n",
        "          caption = torch.cat([caption, torch.tensor([[predicted_word_index]], dtype=torch.long).to(device)], dim=1)\n",
        "\n",
        "  predicted_caption = ' '.join([idx_to_word[word_idx] for word_idx in caption[0].tolist()][2:-1])\n",
        "\n",
        "  if show_true_caption: \n",
        "    print(f\"True tags: {true_tags} \")\n",
        "  print(f\"Predicted tags: {predicted_caption}\\n\")\n",
        "  "
      ],
      "metadata": {
        "id": "6skuxHE6dzfQ"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LhF1r_rLQxC",
        "outputId": "fe8f9c75-1c30-4f2e-db54-00bb4a907266"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "421"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "pbar = tqdm.tqdm(range(num_epochs))\n",
        "pbar.set_description(f\"Epoch 1\")\n",
        "for epoch in pbar:\n",
        "    model.train()  # set model to train mode\n",
        "    for i, (x, captions) in enumerate(train_dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        logits, hidden = model(captions[:, :-1], x)\n",
        "        loss = loss_fn(logits.reshape(-1, vocab_size), captions[:, 1:].reshape(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pbar.set_description(f\"Epoch {epoch+1} | Train batch {i}/{len(train_dataloader)}\")\n",
        "    scheduler.step()\n",
        "\n",
        "    model.eval()  # set model to eval mode\n",
        "    eval_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (x, captions) in enumerate(eval_test_dataloader):\n",
        "            x = x.to(device, dtype=torch.float)\n",
        "            captions = captions.to(device, dtype=torch.long)\n",
        "            logits, hidden = model(captions[:, :-1], x)\n",
        "            loss = loss_fn(logits.reshape(-1, vocab_size), captions[:, 1:].reshape(-1))\n",
        "            eval_loss += loss.item() * x.size(0)  # accumulate loss for entire eval dataset\n",
        "            pbar.set_description(f\"Epoch {epoch+1} | Eval batch {i}/{len(eval_test_dataloader)}\")\n",
        "        eval_loss /= len(eval_test_dataloader.dataset)  # compute average eval loss\n",
        "        \n",
        "    \n",
        "    pbar.set_description(f\"Epoch {epoch+1}, train loss {loss.item():.4f}, eval loss {eval_loss:.4f}\")\n",
        "    train_ids, test_ids = np.random.randint(len(training_data), size=2), np.random.randint(len(test_data), size=2)\n",
        "    print(\"\\n(train)\")\n",
        "    generate_caption(train_ids[0], train=True, show_true_caption=True) \n",
        "    generate_caption(train_ids[1], train=True, show_true_caption=True) \n",
        "    print(\"(eval)\")\n",
        "    generate_caption(test_ids[0], train=False, show_true_caption=True)\n",
        "    generate_caption(test_ids[1], train=False, show_true_caption=True)\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mEYH9JMMc1Z",
        "outputId": "e4109250-5b65-426c-b48c-e9db4f409111"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1, train loss 2.3914, eval loss 2.4226:   5%|▌         | 1/20 [01:26<27:26, 86.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "(train)\n",
            "True tags: genre: classical, soundtrack; instrument: piano; mood/theme: sentimental, wedding, romantic \n",
            "Predicted tags: genre classical classical instrument instrument piano piano moodtheme moodtheme relaxing christmas\n",
            "\n",
            "True tags: genre: rnb, hiphop, rap \n",
            "Predicted tags: genre electronic electronic\n",
            "\n",
            "(eval)\n",
            "True tags: genre: easylistening, trance, atmospheric; instrument: guitar, drums, bass, harp \n",
            "Predicted tags: genre ambient ambient instrument instrument synthesizer synthesizer synthesizer moodtheme moodtheme meditative meditative\n",
            "\n",
            "True tags: genre: 80s, acidrock, world; instrument: bass \n",
            "Predicted tags: genre rock rock\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2, train loss 2.2446, eval loss 2.2896:  10%|█         | 2/20 [02:58<26:57, 89.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "(train)\n",
            "True tags: genre: electronic, dance, electropop, electronica \n",
            "Predicted tags: genre dance pop pop instrument instrument drums synthesizer synthesizer bass moodtheme moodtheme energetic happy\n",
            "\n",
            "True tags: genre: grunge, bluesrock, rock, indie; instrument: electricguitar, drums, bass, slideguitar \n",
            "Predicted tags: genre rock funk\n",
            "\n",
            "(eval)\n",
            "True tags: genre: chillout, atmospheric, ambient; mood/theme: love \n",
            "Predicted tags: genre ambient ambient instrument instrument synthesizer synthesizer moodtheme moodtheme relaxing relaxing\n",
            "\n",
            "True tags: genre: electronic, downtempo, chillout; mood/theme: peaceful \n",
            "Predicted tags: genre chillout lounge lounge instrument instrument piano synthesizer\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3, train loss 2.1987, eval loss 2.2073:  15%|█▌        | 3/20 [04:32<25:54, 91.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "(train)\n",
            "True tags: genre: techno, electronic, soundtrack; instrument: synthesizer \n",
            "Predicted tags: genre electronic soundtrack\n",
            "\n",
            "True tags: genre: electronic, club, dance, trance, techno \n",
            "Predicted tags: genre electronic electronic\n",
            "\n",
            "(eval)\n",
            "True tags: genre: rockfrancais, rock, ska; instrument: electricguitar, bass, voice, keyboard, drums; mood/theme: energetic \n",
            "Predicted tags: genre rock rock\n",
            "\n",
            "True tags: genre: punkrock, rock, rocknroll, poprock, indie \n",
            "Predicted tags: genre rock rock\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4, train loss 2.1421, eval loss 2.1502:  20%|██        | 4/20 [06:05<24:36, 92.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "(train)\n",
            "True tags: genre: electronic, edm, soundtrack, ambient, dance; instrument: drums, synthesizer, electricguitar, drummachine, violin, pipeorgan, acousticguitar, sampler; mood/theme: energetic, driving, advertising, dark, urban, angry \n",
            "Predicted tags: genre electronic electronic\n",
            "\n",
            "True tags: genre: dance, electropop, pop; instrument: synthesizer, drums, bass; mood/theme: crazy, fun, energetic, party \n",
            "Predicted tags: genre hiphop hiphop instrument instrument beat beat\n",
            "\n",
            "(eval)\n",
            "True tags: genre: ambient, chillout, lounge; instrument: drummachine \n",
            "Predicted tags: genre chillout easylistening lounge instrument instrument bass synthesizer synthesizer moodtheme moodtheme relaxing relaxing\n",
            "\n",
            "True tags: genre: contemporary, classical \n",
            "Predicted tags: genre pop pop\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5, train loss 2.0083, eval loss 2.1088:  25%|██▌       | 5/20 [07:39<23:13, 92.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "(train)\n",
            "True tags: genre: triphop, hiphop, downtempo; instrument: guitar, drums, bass; mood/theme: dark, upbeat \n",
            "Predicted tags: genre hiphop hiphop rap instrument instrument beat synthesizer moodtheme moodtheme conscient energetic\n",
            "\n",
            "True tags: genre: soundtrack \n",
            "Predicted tags: genre ambient ambient instrument instrument synthesizer synthesizer\n",
            "\n",
            "(eval)\n",
            "True tags: genre: lounge, easylistening, chillout \n",
            "Predicted tags: genre chillout easylistening lounge instrument instrument piano synthesizer moodtheme moodtheme relaxing inspiring\n",
            "\n",
            "True tags: genre: classical, contemporary \n",
            "Predicted tags: genre classical classical instrument instrument piano piano moodtheme moodtheme emotional emotional\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6, train loss 2.1110, eval loss 2.0751:  30%|███       | 6/20 [09:13<21:44, 93.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "(train)\n",
            "True tags: genre: hiphop, electronic, 90s \n",
            "Predicted tags: genre lounge hiphop easylistening instrument instrument bass synthesizer synthesizer piano piano moodtheme moodtheme background deep\n",
            "\n",
            "True tags: genre: pop, ambient, soundtrack, latin, experimental; instrument: synthesizer, percussion; mood/theme: documentary, children, society, advertising, comedy \n",
            "Predicted tags: genre reggae dub dub instrument instrument bass electricguitar electricguitar electricpiano electricpiano\n",
            "\n",
            "(eval)\n",
            "True tags: genre: dance, trance, trancemelodique \n",
            "Predicted tags: genre trance trance\n",
            "\n",
            "True tags: genre: hiphop, downtempo, triphop; instrument: synthesizer, bass, drums, guitar \n",
            "Predicted tags: genre hiphop hiphop rap instrument moodtheme beat youtube\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7, train loss 2.1490, eval loss 2.0510:  35%|███▌      | 7/20 [10:48<20:18, 93.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "(train)\n",
            "True tags: genre: club, chillout, electronic; instrument: bass \n",
            "Predicted tags: genre electronic electronic instrument instrument synthesizer synthesizer\n",
            "\n",
            "True tags: genre: soul, latin, bossanova \n",
            "Predicted tags: genre electronic pop\n",
            "\n",
            "(eval)\n",
            "True tags: genre: progressive, electronic; mood/theme: aggressive \n",
            "Predicted tags: genre electronic electronic\n",
            "\n",
            "True tags: genre: pop, waltz, cabaret \n",
            "Predicted tags: genre reggae pop instrument instrument guitar guitar moodtheme\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8, train loss 2.0950, eval loss 2.0325:  40%|████      | 8/20 [12:22<18:46, 93.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "(train)\n",
            "True tags: genre: rockfrancais, rock, bluesrock; instrument: electricguitar, voice, bass, drums, harmonica \n",
            "Predicted tags: genre funk funk rnb instrument instrument bass bass electricguitar electricguitar drums drums\n",
            "\n",
            "True tags: genre: minimal; instrument: guitar, classicalguitar \n",
            "Predicted tags: genre classical pop instrument instrument guitar piano\n",
            "\n",
            "(eval)\n",
            "True tags: genre: instrumentalpop, easylistening \n",
            "Predicted tags: genre rock pop instrument instrument guitar guitar bass bass\n",
            "\n",
            "True tags: genre: orchestral, easylistening, ambient; instrument: piano; mood/theme: sweet, motivational, soft, inspiring \n",
            "Predicted tags: genre classical classical instrument instrument piano piano\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 | Train batch 0/421:  45%|████▌     | 9/20 [13:57<17:15, 94.11s/it]                "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "(train)\n",
            "True tags: genre: rap, hiphop, pop, rock \n",
            "Predicted tags: genre electronic electronic\n",
            "\n",
            "True tags: genre: industrial, ebm, electronic; mood/theme: dark \n",
            "Predicted tags: genre electronic electronic\n",
            "\n",
            "(eval)\n",
            "True tags: genre: soundtrack, darkambient, ambient; mood/theme: thriller, dark, horror \n",
            "Predicted tags: genre soundtrack soundtrack classical moodtheme moodtheme epic epic\n",
            "\n",
            "True tags: genre: electronic, popfolk, folk; instrument: synthesizer, guitar; mood/theme: fast \n",
            "Predicted tags: genre electronic pop pop instrument instrument synthesizer synthesizer\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10, train loss 2.1471, eval loss 2.0113:  50%|█████     | 10/20 [15:32<15:45, 94.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "(train)\n",
            "True tags: genre: dance, electronic; instrument: drummachine, sampler, synthesizer; mood/theme: bright, energetic, retro \n",
            "Predicted tags: genre electronic dance dance instrument instrument synthesizer synthesizer computer computer moodtheme\n",
            "\n",
            "True tags: genre: electronic \n",
            "Predicted tags: genre electronic electronic\n",
            "\n",
            "(eval)\n",
            "True tags: genre: rock, progressiverock, hardrock; instrument: bassguitar, drums, guitar \n",
            "Predicted tags: genre rock rock instrument instrument guitar guitar bass bass drums drums\n",
            "\n",
            "True tags: genre: orchestral, experimental, ambient, electronic; instrument: electricguitar, computer \n",
            "Predicted tags: genre electronic electronic ambient instrument instrument synthesizer synthesizer piano piano moodtheme moodtheme emotional emotional inspiring\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11, train loss 1.8643, eval loss 1.9941:  55%|█████▌    | 11/20 [17:09<14:16, 95.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "(train)\n",
            "True tags: genre: soundtrack, orchestral; instrument: choir, strings; mood/theme: epic, emotional, drama \n",
            "Predicted tags: genre orchestral soundtrack soundtrack moodtheme instrument film film\n",
            "\n",
            "True tags: genre: poprock, powerpop, rock \n",
            "Predicted tags: genre rock rock pop instrument instrument guitar voice voice bass bass\n",
            "\n",
            "(eval)\n",
            "True tags: genre: ambient, soundtrack; instrument: piano, synthesizer; mood/theme: thoughtful, peaceful \n",
            "Predicted tags: genre ambient ambient soundtrack instrument instrument piano synthesizer synthesizer moodtheme\n",
            "\n",
            "True tags: genre: experimental, idm, ambient, electronic, downtempo; mood/theme: dream \n",
            "Predicted tags: genre electronic electronic ambient instrument instrument synthesizer synthesizer computer moodtheme moodtheme emotional adventure\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12, train loss 2.1304, eval loss 1.9922:  60%|██████    | 12/20 [18:44<12:42, 95.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "(train)\n",
            "True tags: genre: 70s, blues, ambient \n",
            "Predicted tags: genre rock pop pop instrument instrument guitar guitar\n",
            "\n",
            "True tags: genre: classical, soundtrack; instrument: electricpiano, piano; mood/theme: melodic, reflective \n",
            "Predicted tags: genre classical classical instrument instrument piano piano\n",
            "\n",
            "(eval)\n",
            "True tags: genre: ambient \n",
            "Predicted tags: genre ambient soundtrack soundtrack instrument instrument strings synthesizer piano piano\n",
            "\n",
            "True tags: genre: hardrock, rock, indie, instrumentalrock; instrument: bass, drums, synthesizer, electricguitar \n",
            "Predicted tags: genre rock metal hardrock punkrock instrument instrument electricguitar electricguitar bass bass drums drums\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13, train loss 1.9733, eval loss 1.9906:  65%|██████▌   | 13/20 [20:18<11:03, 94.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "(train)\n",
            "True tags: genre: electronic \n",
            "Predicted tags: genre electronic trance trance moodtheme instrument uplifting space\n",
            "\n",
            "True tags: genre: techno, trance; instrument: accordion, computer, keyboard \n",
            "Predicted tags: genre electronic electronic\n",
            "\n",
            "(eval)\n",
            "True tags: genre: alternative, pop, indie \n",
            "Predicted tags: genre pop pop rock instrument instrument drums synthesizer piano piano bass\n",
            "\n",
            "True tags: genre: world, soundtrack, jazz; instrument: saxophone, hang; mood/theme: society \n",
            "Predicted tags: genre ambient ambient atmospheric instrument instrument synthesizer synthesizer\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14, train loss 2.2170, eval loss 1.9941:  70%|███████   | 14/20 [21:52<09:27, 94.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "(train)\n",
            "True tags: genre: orchestral, soundtrack, classical; mood/theme: dark, epic, film \n",
            "Predicted tags: genre soundtrack classical classical moodtheme instrument adventure adventure film action action documentary\n",
            "\n",
            "True tags: genre: poprock, rock \n",
            "Predicted tags: genre pop pop instrument instrument keyboard synthesizer synthesizer piano piano acousticguitar\n",
            "\n",
            "(eval)\n",
            "True tags: genre: electronic; instrument: beat, synthesizer; mood/theme: drive, energetic \n",
            "Predicted tags: genre electronic electronic soundtrack instrument instrument synthesizer synthesizer\n",
            "\n",
            "True tags: genre: classical; instrument: piano, violin, oboe, drums; mood/theme: christmas \n",
            "Predicted tags: genre pop pop rock instrument instrument drums synthesizer piano piano guitar\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15 | Train batch 58/421:  70%|███████   | 14/20 [22:04<09:27, 94.61s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "digAAMbIVcmQ"
      },
      "source": [
        "### Model assessment\n",
        "Predict with the trained LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_idx, test_idx = np.random.randint(len(training_data)), np.random.randint(len(test_data))\n",
        "print(\"\\n(train)\")\n",
        "generate_caption(train_idx, train=True, show_true_caption=True) \n",
        "print(\"(eval)\")\n",
        "generate_caption(test_idx, train=False, show_true_caption=True)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "id": "bHUgSukjjALd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_idx, test_idx = np.random.randint(len(training_data)), np.random.randint(len(test_data))\n",
        "print(\"\\n(train)\")\n",
        "generate_caption(train_idx, train=True, show_true_caption=True) \n",
        "print(\"(eval)\")\n",
        "generate_caption(test_idx, train=False, show_true_caption=True)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "id": "p2yESO4UNRYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bvtLfmosNker"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}