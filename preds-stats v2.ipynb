{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9f106bd-eec0-4ab2-a587-c07668c197ac",
   "metadata": {},
   "source": [
    "# Preds analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c85d9c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (2.10.0)\n",
      "Requirement already satisfied: xxhash in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: responses<0.19 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets) (0.12.1)\n",
      "Requirement already satisfied: packaging in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets) (22.0)\n",
      "Requirement already satisfied: pandas in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets) (1.2.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets) (1.22.4)\n",
      "Requirement already satisfied: aiohttp in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: multiprocess in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets) (2.28.1)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets) (2023.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: filelock in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from pandas->datasets) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: evaluate in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (0.4.0)\n",
      "Requirement already satisfied: responses<0.19 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: packaging in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from evaluate) (22.0)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from evaluate) (2.10.0)\n",
      "Requirement already satisfied: multiprocess in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from evaluate) (0.70.14)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from evaluate) (2.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from evaluate) (1.22.4)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from evaluate) (2023.1.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from evaluate) (4.64.1)\n",
      "Requirement already satisfied: pandas in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from evaluate) (1.2.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from evaluate) (0.12.1)\n",
      "Requirement already satisfied: dill in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from evaluate) (0.3.6)\n",
      "Requirement already satisfied: xxhash in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from evaluate) (3.2.0)\n",
      "Requirement already satisfied: aiohttp in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (3.8.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (11.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.4.0)\n",
      "Requirement already satisfied: filelock in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.9.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (1.26.14)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from pandas->evaluate) (2022.7)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2aa47ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rouge_score in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (0.1.2)\n",
      "Requirement already satisfied: six>=1.14.0 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: nltk in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from rouge_score) (3.7)\n",
      "Requirement already satisfied: numpy in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from rouge_score) (1.22.4)\n",
      "Requirement already satisfied: absl-py in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: joblib in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from nltk->rouge_score) (1.1.1)\n",
      "Requirement already satisfied: tqdm in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from nltk->rouge_score) (4.64.1)\n",
      "Requirement already satisfied: click in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from nltk->rouge_score) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from nltk->rouge_score) (2022.7.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7dec07c-f447-4c9a-868b-22e873c1b4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import evaluate\n",
    "from collections import defaultdict, Counter\n",
    "from tqdm import tqdm as tqdm\n",
    "from musiccaps import load_musiccaps\n",
    "import string\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed7035f-1ca7-4913-b7b3-d4af47b89c0d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2483bbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/corinacaraconcea/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/corinacaraconcea/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/corinacaraconcea/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "meteor = evaluate.load('meteor')\n",
    "google_bleu = evaluate.load('google_bleu')\n",
    "rouge = evaluate.load('rouge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8953ddb0-d512-46c9-b6b8-cd53be484247",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/Users/corinacaraconcea/.cache/huggingface/datasets/google___csv/google--MusicCaps-bedc2a0fd7888f2f/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ds = load_musiccaps(\n",
    "    \"./music_data\",\n",
    "    sampling_rate=16000,\n",
    "    limit=None,\n",
    "    num_proc=8,\n",
    "    writer_batch_size=1000,\n",
    "    return_without_audio=True,\n",
    ")\n",
    "\n",
    "def clean_text_for_aspect_metrics(caption):\n",
    "    table = str.maketrans('','', string.punctuation)\n",
    "    caption.replace(\"-\",\" \")\n",
    "    # split the sentences into words\n",
    "    desc = caption.split()\n",
    "    #converts to lower case\n",
    "    desc = [word.lower() for word in desc]\n",
    "    #remove punctuation from each token\n",
    "    desc = [word.translate(table) for word in desc]\n",
    "    #remove hanging 's and a \n",
    "    #desc = [word for word in desc if(len(word)>1)]\n",
    "    #remove tokens with numbers in them\n",
    "    #desc = [word for word in desc if(word.isalpha())]\n",
    "    #convert back to string\n",
    "    caption = ' '.join(desc)\n",
    "    return caption\n",
    "\n",
    "def preprocessing_remove_unk(text_input):\n",
    "    # remove punctuations\n",
    "    desc = re.sub(r'[^\\w\\s]',' ',text_input)\n",
    "    table = str.maketrans('','',string.punctuation)\n",
    "\n",
    "    # turn uppercase letters into lowercase ones\n",
    "    desc = text_input.lower()\n",
    "\n",
    "    # split into words\n",
    "    desc = desc.split(' ')\n",
    "    \n",
    "    try: \n",
    "        # remove <unk> tokens\n",
    "        desc.remove(\"<unk>\")\n",
    "    except ValueError:\n",
    "        desc = desc\n",
    "    try: \n",
    "        # remove <unk> tokens\n",
    "        desc.remove(\"unk\")\n",
    "    except ValueError:\n",
    "        desc = desc\n",
    "        \n",
    "    # remove the punctuations\n",
    "    text_no_punctuation = [word.translate(table) for word in desc]\n",
    "\n",
    "    # join the caption words\n",
    "    caption = ' '.join(text_no_punctuation)\n",
    "    \n",
    "    return caption\n",
    "\n",
    "# get a list of music-related words to use for evaluation\n",
    "aspects = set()\n",
    "for x in ds:\n",
    "    aspect_str = x[\"aspect_list\"]\n",
    "    for t in \"[]\\\"'\":\n",
    "        aspect_str = aspect_str.replace(t, \"\")\n",
    "    aspects.update(aspect_str.split(\", \"))\n",
    "# clean aspects\n",
    "aspects = {clean_text_for_aspect_metrics(a) for a in aspects if len(a) > 2}\n",
    "    \n",
    "def wrap_in_space(s):\n",
    "    return ' ' + s + ' '\n",
    "    \n",
    "# filter\n",
    "all_captions = clean_text_for_aspect_metrics(' '.join(ds[i]['caption'] for i in range(len(ds))))\n",
    "aspect_counts = {a: all_captions.count(wrap_in_space(a)) for a in aspects}\n",
    "aspects = {a for a in aspects if aspect_counts[a] > 10}\n",
    "aspects -= {'the'}\n",
    "\n",
    "def compute_aspects_metric(true, pred):\n",
    "    true = wrap_in_space(clean_text_for_aspect_metrics(true))\n",
    "    pred = wrap_in_space(clean_text_for_aspect_metrics(pred))\n",
    "    \n",
    "    aspects_in_true = {a for a in aspects if wrap_in_space(a) in true}\n",
    "    aspects_in_pred = {a for a in aspects if wrap_in_space(a) in pred}\n",
    "    \n",
    "    #print(aspects_in_true)\n",
    "    #print(aspects_in_pred)\n",
    "    \n",
    "    precision = len(aspects_in_true&aspects_in_pred)/np.maximum(len(aspects_in_pred),1)\n",
    "    recall = len(aspects_in_true&aspects_in_pred)/np.maximum(len(aspects_in_true), 1)\n",
    "    \n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e2b1b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_outputs(data_path):\n",
    "    \n",
    "    with open(data_path) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # multiple references for one captions\n",
    "    true_captions = data['eval_true_captions']\n",
    "    # single prediction\n",
    "    predicted_captions = data['eval_pred_captions']\n",
    "\n",
    "    return true_captions,predicted_captions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "53916323",
   "metadata": {},
   "source": [
    "# Compute metrics for the non-summarized dataset (noaug + chataug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "301d7607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(true_captions,predicted_captions):\n",
    "    true_clean = []\n",
    "    pred_clean = []\n",
    "    for i, (true, pred) in tqdm(enumerate(zip(true_captions, predicted_captions))):\n",
    "        # preprocess captions and predictions to remove punctuations and <unk> tokens\n",
    "        true = preprocessing_remove_unk(true)\n",
    "        true_clean.append(true)\n",
    "        pred = preprocessing_remove_unk(pred)\n",
    "        pred_clean.append(pred)\n",
    "\n",
    "    total_google_bleu = google_bleu.compute(predictions = pred_clean,references = true_clean)\n",
    "    total_rouge = rouge.compute(predictions = pred_clean,references = true_clean)\n",
    "    total_meteor = meteor.compute(predictions = pred_clean,references = true_clean)\n",
    "    \n",
    "    return total_google_bleu, total_rouge, total_meteor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4de9dddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(data_paths,methods):\n",
    "    for i, (data_path, method) in enumerate(zip(data_paths,methods)):\n",
    "       true_captions,predicted_captions = import_outputs(data_path)\n",
    "       google_bleu_score, rouge_score, meteor_score, = compute_metrics(true_captions,predicted_captions)\n",
    "\n",
    "       print(method,\"test GLEU score:\",str(np.round(google_bleu_score[\"google_bleu\"],3)))\n",
    "       print(method,\"test google ROUGE score:\",str(np.round(rouge_score[\"rouge1\"],3)))\n",
    "       print(method,\"test google METEOR score:\",str(np.round(meteor_score[\"meteor\"],3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c5f209e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = [\"outputs/preds_gpt2_enc_noaug.json\",\n",
    "              \"outputs/preds_gpt2_enc_chataug.json\",\n",
    "              \"outputs/preds_lstm_noattn_noaug.json\",\n",
    "              \"outputs/preds_lstm_attn_noaug.json\"]\n",
    "\n",
    "\n",
    "methods = [\"GPT-2 fine-tuned encoder no aug\",\n",
    "           \"GPT-2 fine-tuned encoder with ChatAug\",\n",
    "           \"LSTM no attention no aug\",\n",
    "           \"LSTM attention no aug\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d96f53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "549it [00:00, 15937.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2 fine-tuned encoder no aug test GLEU score: 0.091\n",
      "GPT-2 fine-tuned encoder no aug test google ROUGE score: 0.287\n",
      "GPT-2 fine-tuned encoder no aug test google METEOR score: 0.208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "549it [00:00, 20248.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2 fine-tuned encoder with ChatAug test GLEU score: 0.093\n",
      "GPT-2 fine-tuned encoder with ChatAug test google ROUGE score: 0.302\n",
      "GPT-2 fine-tuned encoder with ChatAug test google METEOR score: 0.213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "549it [00:00, 24083.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM no attention no aug test GLEU score: 0.084\n",
      "LSTM no attention no aug test google ROUGE score: 0.276\n",
      "LSTM no attention no aug test google METEOR score: 0.185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "549it [00:00, 24687.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM attention no aug test GLEU score: 0.083\n",
      "LSTM attention no aug test google ROUGE score: 0.276\n",
      "LSTM attention no aug test google METEOR score: 0.184\n"
     ]
    }
   ],
   "source": [
    "print_metrics(data_paths,methods)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "62ab8dde",
   "metadata": {},
   "source": [
    "# Compute metrics for the summarized dataset (noaug + chataug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f1e520fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_summaries_gpt2(true_captions,predicted_captions):\n",
    "    true_clean = []\n",
    "    pred_clean = []\n",
    "    for i, (true, pred) in tqdm(enumerate(zip(true_captions, predicted_captions))):\n",
    "        # preprocess captions and predictions to remove punctuations and <unk> tokens\n",
    "        if isinstance(true, list):\n",
    "            true = [preprocessing_remove_unk(caption) for caption in true]\n",
    "        else:\n",
    "            true = preprocessing_remove_unk(true)\n",
    "        true_clean.append(true)\n",
    "        pred = preprocessing_remove_unk(pred)\n",
    "        pred_clean.append(pred)\n",
    "\n",
    "    print(pred_clean[:2])\n",
    "    print(true_clean[:2])\n",
    "    total_google_bleu = google_bleu.compute(predictions = pred_clean,references = true_clean)\n",
    "    total_rouge = rouge.compute(predictions = pred_clean,references = true_clean)\n",
    "    total_meteor = meteor.compute(predictions = pred_clean,references = true_clean)\n",
    "    \n",
    "    return total_google_bleu, total_rouge, total_meteor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d6fa65a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths_summarized_gpt2= [\"outputs/preds_gpt2_enc_summarized.json\"]\n",
    "\n",
    "methods_summarized_gpt2 = [\"GPT-2 fine-tuned encoder and summarized dataset\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4a6a5431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics2(data_paths,methods):\n",
    "    for i, (data_path, method) in enumerate(zip(data_paths,methods)):\n",
    "       true_captions,predicted_captions = import_outputs(data_path)\n",
    "       google_bleu_score, rouge_score, meteor_score, = compute_metrics_summaries_gpt2(true_captions,predicted_captions)\n",
    "\n",
    "       print(method,\"test GLEU score:\",str(np.round(google_bleu_score[\"google_bleu\"],3)))\n",
    "       print(method,\"test google ROUGE score:\",str(np.round(rouge_score[\"rouge1\"],3)))\n",
    "       print(method,\"test google METEOR score:\",str(np.round(meteor_score[\"meteor\"],3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "40c8cacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "549it [00:00, 13365.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the music has a mellow electric guitar melody bass guitar shimmering cymbals and punchy kick and snare hits the recording quality is low but the overall vibe is relaxed and easygoing', 'the recording has a distorted electric guitar melody with background noise it is in mono and sounds like it was recorded with a phone']\n",
      "[['the song has an electric guitar as the main instrument playing a descending run arpeggiated chord double stop hammer and descending slide followed by a chord run the percussion uses rim shots and plays a simple beat in common time the bass plays only one note on the first count of each bar while the piano provides backing chords there are no vocals and the mood is relaxing', 'this is a laidback instrumental piece featuring an electric guitar percussion bass and piano the guitar opens with a descending run and goes on to play arpeggiated chords with hammerons and slides while the percussion keeps a simple beat the bass plays just one note at the beginning of each bar and the piano backs it all up with chords the song has no vocals and creates a relaxing mood', 'this instrumental song features an electric guitar percussion bass and piano the guitar has a descending run at the beginning followed by chords and a slide the percussion provides a simple common time beat with rim shots the bass plays one note per bar the piano plays backing chords the mood is relaxing'], ['the audio is from a live performance and has a lowfidelity quality it features a solo direct input acoustic guitar playing airy suspended open chords there are occasional ambient sounds possibly of papers being shuffled', 'this is a live performance of a solo acoustic guitar the audio has a low fidelity quality and features airy suspended open chords there are occasional ambient sounds such as papers being shuffled', 'the music is a live acoustic guitar solo with a lowfi quality the guitarist plays open chords that create a bright floating sound there are also occasional background noises like paper shuffling']]\n",
      "GPT-2 fine-tuned encoder and summarized dataset test GLEU score: 0.104\n",
      "GPT-2 fine-tuned encoder and summarized dataset test google ROUGE score: 0.339\n",
      "GPT-2 fine-tuned encoder and summarized dataset test google METEOR score: 0.248\n"
     ]
    }
   ],
   "source": [
    "print_metrics2(data_paths_summarized_gpt2,methods_summarized_gpt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "382aff16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_summaries_lstm(true_captions,predicted_captions):\n",
    "    true_clean = []\n",
    "    pred_clean = []\n",
    "    for i, (true, pred) in tqdm(enumerate(zip(true_captions, predicted_captions))):\n",
    "        # preprocess captions and predictions to remove punctuations and <unk> tokens\n",
    "        true = preprocessing_remove_unk(true)\n",
    "        true_clean.append(true)\n",
    "        # the model outputs 3 identical predictions so we need to only append one\n",
    "        if i%3==0 :\n",
    "            pred = preprocessing_remove_unk(pred)\n",
    "            pred_clean.append(pred)\n",
    "\n",
    "    nested_summarized_true_captions = []\n",
    "    nested_summarized_true_captions = [[true_clean[i], true_clean[i+1], true_clean[i+2]] for i in range(0, len(true_clean), 3)]\n",
    "\n",
    "    total_google_bleu = google_bleu.compute(predictions = pred_clean,references = nested_summarized_true_captions)\n",
    "    total_rouge = rouge.compute(predictions = pred_clean,references = nested_summarized_true_captions)\n",
    "    total_meteor = meteor.compute(predictions = pred_clean,references = nested_summarized_true_captions)\n",
    "    \n",
    "    return total_google_bleu, total_rouge, total_meteor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c8030d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths_summarized_lstm= [\"outputs/preds_lstm_noattn_summaries.json\",\n",
    "                        \"outputs/preds_lstm_attn_summaries.json\"]\n",
    "\n",
    "methods_summarized_lstm = [\"LSTM no attention and summarized dataset\",\n",
    "                           \"LSTM with attention and summarized dataset\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d2f72937",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics3(data_paths,methods):\n",
    "    for i, (data_path, method) in enumerate(zip(data_paths,methods)):\n",
    "       true_captions,predicted_captions = import_outputs(data_path)\n",
    "       google_bleu_score, rouge_score, meteor_score, = compute_metrics_summaries_lstm(true_captions,predicted_captions)\n",
    "\n",
    "       print(method,\"test GLEU score:\",str(np.round(google_bleu_score[\"google_bleu\"],3)))\n",
    "       print(method,\"test google ROUGE score:\",str(np.round(rouge_score[\"rouge1\"],3)))\n",
    "       print(method,\"test google METEOR score:\",str(np.round(meteor_score[\"meteor\"],3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7d8c5187",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1647it [00:00, 37369.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM no attention and summarized dataset test GLEU score: 0.111\n",
      "LSTM no attention and summarized dataset test google ROUGE score: 0.354\n",
      "LSTM no attention and summarized dataset test google METEOR score: 0.246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1647it [00:00, 44781.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM with attention and summarized dataset test GLEU score: 0.107\n",
      "LSTM with attention and summarized dataset test google ROUGE score: 0.346\n",
      "LSTM with attention and summarized dataset test google METEOR score: 0.243\n"
     ]
    }
   ],
   "source": [
    "print_metrics3(data_paths_summarized_lstm,methods_summarized_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d98b449c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], [4, 5, 6]]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_clean = [1,2,3,4,5,6]\n",
    "[[true_clean[i], true_clean[i+1], true_clean[i+2]] for i in range(0, len(true_clean), 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854792d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UCL1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "c9151f2c10dd9c04d670c6ab9407273fd33ff73d6858514519ebe1bfa000ee63"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
