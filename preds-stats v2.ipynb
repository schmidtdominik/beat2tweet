{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9f106bd-eec0-4ab2-a587-c07668c197ac",
   "metadata": {},
   "source": [
    "# Preds analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c85d9c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (2.10.0)\n",
      "Requirement already satisfied: aiohttp in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: pandas in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets) (1.2.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets) (2.28.1)\n",
      "Requirement already satisfied: packaging in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets) (22.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets) (2023.1.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: xxhash in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: responses<0.19 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets) (1.22.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets) (0.12.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: filelock in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from pandas->datasets) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n",
      "Collecting evaluate\n",
      "  Using cached evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
      "Requirement already satisfied: xxhash in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from evaluate) (3.2.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from evaluate) (2023.1.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from evaluate) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from evaluate) (4.64.1)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from evaluate) (2.10.0)\n",
      "Requirement already satisfied: dill in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from evaluate) (0.3.6)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from evaluate) (0.12.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from evaluate) (1.22.4)\n",
      "Requirement already satisfied: packaging in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from evaluate) (22.0)\n",
      "Requirement already satisfied: responses<0.19 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: pandas in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from evaluate) (1.2.4)\n",
      "Requirement already satisfied: multiprocess in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from evaluate) (0.70.14)\n",
      "Requirement already satisfied: aiohttp in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (3.8.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (11.0.0)\n",
      "Requirement already satisfied: filelock in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.4.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from pandas->evaluate) (2022.7)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.16.0)\n",
      "Installing collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2aa47ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting absl-py\n",
      "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Requirement already satisfied: nltk in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from rouge_score) (3.7)\n",
      "Requirement already satisfied: numpy in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from rouge_score) (1.22.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: joblib in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from nltk->rouge_score) (1.1.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from nltk->rouge_score) (2022.7.9)\n",
      "Requirement already satisfied: click in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from nltk->rouge_score) (8.0.4)\n",
      "Requirement already satisfied: tqdm in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from nltk->rouge_score) (4.64.1)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24936 sha256=916455fe14c84c8b5b5217b4edf2041c22209e93f15ac491a1a3e5763bb2c049\n",
      "  Stored in directory: /Users/corinacaraconcea/Library/Caches/pip/wheels/b0/3f/ac/cc3bc304f50c77ef38d79d8e4e2684313de39af543cb4eb3da\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: absl-py, rouge_score\n",
      "Successfully installed absl-py-1.4.0 rouge_score-0.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b7dec07c-f447-4c9a-868b-22e873c1b4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import evaluate\n",
    "from collections import defaultdict, Counter\n",
    "from tqdm import tqdm as tqdm\n",
    "from musiccaps import load_musiccaps\n",
    "import string\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed7035f-1ca7-4913-b7b3-d4af47b89c0d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8953ddb0-d512-46c9-b6b8-cd53be484247",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/corinacaraconcea/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/corinacaraconcea/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/corinacaraconcea/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "WARNING:datasets.builder:Found cached dataset csv (/Users/corinacaraconcea/.cache/huggingface/datasets/google___csv/google--MusicCaps-bedc2a0fd7888f2f/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    }
   ],
   "source": [
    "meteor = evaluate.load('meteor')\n",
    "google_bleu = evaluate.load('google_bleu')\n",
    "rouge = evaluate.load('rouge')\n",
    "\n",
    "ds = load_musiccaps(\n",
    "    \"./music_data\",\n",
    "    sampling_rate=16000,\n",
    "    limit=None,\n",
    "    num_proc=8,\n",
    "    writer_batch_size=1000,\n",
    "    return_without_audio=True,\n",
    ")\n",
    "\n",
    "def clean_text_for_aspect_metrics(caption):\n",
    "    table = str.maketrans('','', string.punctuation)\n",
    "    caption.replace(\"-\",\" \")\n",
    "    # split the sentences into words\n",
    "    desc = caption.split()\n",
    "    #converts to lower case\n",
    "    desc = [word.lower() for word in desc]\n",
    "    #remove punctuation from each token\n",
    "    desc = [word.translate(table) for word in desc]\n",
    "    #remove hanging 's and a \n",
    "    #desc = [word for word in desc if(len(word)>1)]\n",
    "    #remove tokens with numbers in them\n",
    "    #desc = [word for word in desc if(word.isalpha())]\n",
    "    #convert back to string\n",
    "    caption = ' '.join(desc)\n",
    "    return caption\n",
    "\n",
    "def preprocessing_remove_unk(text_input):\n",
    "    # remove punctuations\n",
    "    desc = re.sub(r'[^\\w\\s]',' ',text_input)\n",
    "    table = str.maketrans('','',string.punctuation)\n",
    "\n",
    "    # turn uppercase letters into lowercase ones\n",
    "    desc = text_input.lower()\n",
    "\n",
    "    # split into words\n",
    "    desc = desc.split(' ')\n",
    "    \n",
    "    try: \n",
    "        # remove <unk> tokens\n",
    "        desc.remove(\"<unk>\")\n",
    "    except ValueError:\n",
    "        desc = desc\n",
    "    try: \n",
    "        # remove <unk> tokens\n",
    "        desc.remove(\"unk\")\n",
    "    except ValueError:\n",
    "        desc = desc\n",
    "        \n",
    "    # remove the punctuations\n",
    "    text_no_punctuation = [word.translate(table) for word in desc]\n",
    "\n",
    "    # join the caption words\n",
    "    caption = ' '.join(desc)\n",
    "    \n",
    "    return caption\n",
    "\n",
    "# get a list of music-related words to use for evaluation\n",
    "aspects = set()\n",
    "for x in ds:\n",
    "    aspect_str = x[\"aspect_list\"]\n",
    "    for t in \"[]\\\"'\":\n",
    "        aspect_str = aspect_str.replace(t, \"\")\n",
    "    aspects.update(aspect_str.split(\", \"))\n",
    "# clean aspects\n",
    "aspects = {clean_text_for_aspect_metrics(a) for a in aspects if len(a) > 2}\n",
    "    \n",
    "def wrap_in_space(s):\n",
    "    return ' ' + s + ' '\n",
    "    \n",
    "# filter\n",
    "all_captions = clean_text_for_aspect_metrics(' '.join(ds[i]['caption'] for i in range(len(ds))))\n",
    "aspect_counts = {a: all_captions.count(wrap_in_space(a)) for a in aspects}\n",
    "aspects = {a for a in aspects if aspect_counts[a] > 10}\n",
    "aspects -= {'the'}\n",
    "\n",
    "def compute_aspects_metric(true, pred):\n",
    "    true = wrap_in_space(clean_text_for_aspect_metrics(true))\n",
    "    pred = wrap_in_space(clean_text_for_aspect_metrics(pred))\n",
    "    \n",
    "    aspects_in_true = {a for a in aspects if wrap_in_space(a) in true}\n",
    "    aspects_in_pred = {a for a in aspects if wrap_in_space(a) in pred}\n",
    "    \n",
    "    #print(aspects_in_true)\n",
    "    #print(aspects_in_pred)\n",
    "    \n",
    "    precision = len(aspects_in_true&aspects_in_pred)/np.maximum(len(aspects_in_pred),1)\n",
    "    recall = len(aspects_in_true&aspects_in_pred)/np.maximum(len(aspects_in_true), 1)\n",
    "    \n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7e2b1b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_outputs(data_path):\n",
    "    \n",
    "    with open(data_path) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # multiple references for one captions\n",
    "    true_captions = data['eval_true_captions']\n",
    "    if isinstance(true_captions, list) and any(isinstance(item, list) for item in true_captions):\n",
    "        true_captions = list(itertools.chain(*true_captions))\n",
    "    # single prediction\n",
    "    predicted_captions = data['eval_pred_captions']\n",
    "    if isinstance(predicted_captions, list) and any(isinstance(item, list) for item in predicted_captions):\n",
    "        predicted_captions = list(itertools.chain(*predicted_captions))\n",
    "\n",
    "\n",
    "    return true_captions,predicted_captions,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "301d7607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(true_captions,predicted_captions):\n",
    "    true_clean = []\n",
    "    pred_clean = []\n",
    "    for i, (true, pred) in tqdm(enumerate(zip(true_captions, predicted_captions))):\n",
    "        # preprocess captions and predictions to remove punctuations and <unk> tokens\n",
    "        true = preprocessing_remove_unk(true)\n",
    "        true_clean.append(true)\n",
    "        pred = preprocessing_remove_unk(pred)\n",
    "        pred_clean.append(pred)\n",
    "        with open('clean_pred.txt','w') as f:\n",
    "            for i in range(len(pred_clean)):\n",
    "                f.write(pred_clean[i]+'\\n')\n",
    "        with open('clean_caption.txt','w') as f:\n",
    "            for i in range(len(true_clean)):\n",
    "                f.write(true_clean[i]+'\\n')\n",
    "\n",
    "    total_google_bleu = google_bleu.compute(predictions = pred_clean,references = true_clean)\n",
    "    total_rouge = rouge.compute(predictions = pred_clean,references = true_clean)\n",
    "    total_meteor = meteor.compute(predictions = pred_clean,references = true_clean)\n",
    "    \n",
    "    return total_google_bleu, total_rouge, total_meteor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "4de9dddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(data_paths,methods):\n",
    "    for i, (data_path, method) in enumerate(zip(data_paths,methods)):\n",
    "       true_captions,predicted_captions = import_outputs(data_path)\n",
    "       google_bleu_score, rouge_score, meteor_score = compute_metrics(true_captions,predicted_captions)\n",
    "\n",
    "       print(method,\"test google BLEU score:\",str(np.round(google_bleu_score[\"google_bleu\"],3)))\n",
    "       print(method,\"test google ROUGE score:\",str(np.round(rouge_score[\"rouge1\"],3)))\n",
    "       print(method,\"test google METEOR score:\",str(np.round(meteor_score[\"meteor\"],3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "4c5f209e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = [\"outputs/preds_lstm_attn_summaries.json\",\n",
    "              \"outputs/preds_lstm_no_attn_summaries.json\",\n",
    "              \"outputs/preds_lstm_attn_no_tag_no_aug.json\",\n",
    "              \"outputs/preds_lstm_no_attn_no_tag_no_aug.json\",\n",
    "              \"outputs/preds_gpt2_summarized_notag_noaug.json\",\n",
    "              \"outputs/preds_gpt2_summarized.json\",\n",
    "              \"outputs/preds_gpt2_notag_chataug.json\",\n",
    "              \"outputs/preds_gpt2_notag_noaug.json\"]\n",
    "\n",
    "methods = [\"LSTM with attention and summarized dataset\",\n",
    "           \"LSTM without attention and summarized dataset\",\n",
    "           \"LSTM with attention no ChatAug\",\n",
    "           \"LSTM no attention no ChatAug\",\n",
    "           \"GPT-2 no tag no aug summarized dataset\",\n",
    "           \"GPT-2 ?? summarized\",\n",
    "           \"GPT-2 no tag ChatAug\",\n",
    "           \"GPT-2 no tag no ChatAug\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1d96f53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1647it [00:00, 1810.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM with attention and summarized dataset test google BLEU score: 0.089\n",
      "LSTM with attention and summarized dataset google ROUGE score: 0.305\n",
      "LSTM with attention and summarized dataset google METEOR score: 0.205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1647it [00:00, 1895.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM without attention and summarized dataset test google BLEU score: 0.092\n",
      "LSTM without attention and summarized dataset google ROUGE score: 0.312\n",
      "LSTM without attention and summarized dataset google METEOR score: 0.207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "549it [00:00, 3212.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM with attention no ChatAug test google BLEU score: 0.083\n",
      "LSTM with attention no ChatAug google ROUGE score: 0.275\n",
      "LSTM with attention no ChatAug google METEOR score: 0.183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "549it [00:00, 3139.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM no attention no ChatAug test google BLEU score: 0.084\n",
      "LSTM no attention no ChatAug google ROUGE score: 0.276\n",
      "LSTM no attention no ChatAug google METEOR score: 0.185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "550it [00:00, 3473.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2 no tag no aug summarized dataset test google BLEU score: 0.087\n",
      "GPT-2 no tag no aug summarized dataset google ROUGE score: 0.267\n",
      "GPT-2 no tag no aug summarized dataset google METEOR score: 0.205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "550it [00:00, 3365.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2 ?? summarized test google BLEU score: 0.086\n",
      "GPT-2 ?? summarized google ROUGE score: 0.267\n",
      "GPT-2 ?? summarized google METEOR score: 0.202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "550it [00:00, 3072.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2 no tag ChatAug test google BLEU score: 0.097\n",
      "GPT-2 no tag ChatAug google ROUGE score: 0.282\n",
      "GPT-2 no tag ChatAug google METEOR score: 0.221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "550it [00:00, 3019.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2 no tag no ChatAug test google BLEU score: 0.091\n",
      "GPT-2 no tag no ChatAug google ROUGE score: 0.273\n",
      "GPT-2 no tag no ChatAug google METEOR score: 0.21\n"
     ]
    }
   ],
   "source": [
    "print_metrics(data_paths,methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ac436e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e520fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fa65a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c8cacf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4674dc0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4bd68b5d-078a-42f7-ae87-4aa6e9278621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(data_true, data_pred):\n",
    "\n",
    "    N = len(data_true)\n",
    "    \n",
    "    assert len(data_pred) == N\n",
    "\n",
    "    average_len_true, average_len_pred = 0, 0\n",
    "    word_count_true, word_count_pred = defaultdict(int), defaultdict(int)\n",
    "    low_quality_true, low_quality_pred = 0, 0\n",
    "    total_male, total_female = 0, 0\n",
    "    male_female_confound, female_male_confound  = 0, 0\n",
    "    max_score, min_score, max_id, min_id = 0, 2, 0, 0\n",
    "    f2w_true, f2w_pred = [], []\n",
    "    total_gleu_score, total_meteor_score = 0, 0\n",
    "    aspect_precision, aspect_recall = [], []\n",
    "\n",
    "    for i, (true, pred) in tqdm(enumerate(zip(data_true, data_pred))):\n",
    "\n",
    "        # vocabulary\n",
    "        sptrue, sppred = true.split(), pred.split()\n",
    "        for w in sptrue:\n",
    "            word_count_true[w] += 1\n",
    "        for w in sppred:\n",
    "            word_count_pred[w] += 1\n",
    "\n",
    "        f2w_true.append(\" \".join(sptrue[:2]))\n",
    "        f2w_pred.append(\" \".join(sppred[:2]))\n",
    "\n",
    "        # average length\n",
    "        average_len_true += (1./N)*len(true)\n",
    "        average_len_pred += (1./N)*len(pred)\n",
    "\n",
    "        # count captions that start with \"low quality recording\" \n",
    "        low_quality_true += (true[1:25]==\"he low quality recording\")\n",
    "        low_quality_pred += (pred[1:25]==\"he low quality recording\")\n",
    "\n",
    "        # male / female\n",
    "        male_in_true = any(\"male\"==word for word in sptrue)\n",
    "        female_in_true = any(\"female\"==word for word in sptrue)\n",
    "        total_male += male_in_true\n",
    "        total_female += female_in_true\n",
    "        if (not male_in_true) and female_in_true:\n",
    "            male_female_confound += any(\"male\"==word for word in sppred)\n",
    "        elif (not female_in_true) and male_in_true:\n",
    "            female_male_confound += any(\"female\"==word for word in sppred)\n",
    "\n",
    "        # metrics\n",
    "        gleu_score = google_bleu.compute(predictions=[pred], references=[true])['google_bleu']\n",
    "        meteor_score = meteor.compute(predictions=[pred], references=[true])['meteor']\n",
    "\n",
    "        if gleu_score+meteor_score < min_score:\n",
    "            min_score = gleu_score+meteor_score\n",
    "            min_id = i\n",
    "\n",
    "        if gleu_score+meteor_score > max_score:\n",
    "            max_score = gleu_score+meteor_score\n",
    "            max_id = i\n",
    "            \n",
    "        precision, recall = compute_aspects_metric(true, pred)\n",
    "        aspect_precision.append(precision)\n",
    "        aspect_recall.append(recall)\n",
    "        \n",
    "    aspect_precision, aspect_recall = np.array(aspect_precision), np.array(aspect_recall)\n",
    "\n",
    "    top_n = 10\n",
    "    most_common_true = {k: v for k, v in sorted(word_count_true.items(), key=lambda item: -item[1])[:top_n]}\n",
    "    most_common_true_string = \", \".join([f\"{key}: {value}\" for key, value in most_common_true.items()])\n",
    "    most_common_pred = {k: v for k, v in sorted(word_count_pred.items(), key=lambda item: -item[1])[:top_n]}\n",
    "    most_common_pred_string = \", \".join([f\"{key}: {value}\" for key, value in most_common_pred.items()])\n",
    "    \n",
    "    total_gleu_score = google_bleu.compute(predictions=data_pred, references=data_true)['google_bleu']\n",
    "    total_meteor_score = meteor.compute(predictions=data_pred, references=data_true)['meteor']\n",
    "\n",
    "    n_shuffles = 10\n",
    "    shuffled_gleu_score, shuffled_meteor_score = 0, 0\n",
    "    for _ in tqdm(range(n_shuffles)):\n",
    "        data_true_shuffled = sorted(data_true, key=lambda k: random.random())\n",
    "        shuffled_gleu_score += 1./n_shuffles * google_bleu.compute(predictions=data_pred, references=data_true_shuffled)['google_bleu']\n",
    "        shuffled_meteor_score += 1./n_shuffles * meteor.compute(predictions=data_pred, references=data_true_shuffled)['meteor']\n",
    "    spec_meteor = total_meteor_score-shuffled_meteor_score\n",
    "    spec_gleu = total_gleu_score-shuffled_gleu_score\n",
    "\n",
    "    print(\"\\n Pred vs. true stats\\n\",\"-\"*50,\"\\n\")\n",
    "    \n",
    "    print(f\"Test GLEU score: {total_gleu_score:.4f}\")\n",
    "    print(f\"Test METEOR score: {total_meteor_score:.4f}\")\n",
    "    print(f\"Shuffled test GLEU score: {shuffled_gleu_score:.4f}\")\n",
    "    print(f\"Shuffled test METEOR score: {shuffled_meteor_score:.4f}\")\n",
    "    print(f\"Test Spec-GLEU score: {spec_gleu:.4f}\")\n",
    "    print(f\"Test Spec-METEOR score: {spec_meteor:.4f}\")\n",
    "    \n",
    "    print(f\"Aspect precision: {aspect_precision.mean():.3f}±{aspect_precision.std():.3f}\")\n",
    "    print(f\"Aspect recall: {aspect_recall.mean():.3f}±{aspect_recall.std():.3f}\")\n",
    "\n",
    "    print(f\"Average length true captions: {average_len_true:.3f}\")\n",
    "    print(f\"Average length pred captions: {average_len_pred:.3f}\\n\")\n",
    "\n",
    "    print(f\"Vocabulary true captions: {len(word_count_true)}\")\n",
    "    print(f\"Vocabulary pred captions: {len(word_count_pred)}\\n\")\n",
    "\n",
    "    print(f\"{top_n} most common words true:\\n {most_common_true_string}\")\n",
    "    print(f\"{top_n} most common words pred:\\n {most_common_pred_string}\\n\")\n",
    "\n",
    "    f2wc_true, f2wc_pred  = Counter(f2w_true), Counter(f2w_pred)\n",
    "    print(f\"{top_n} most common first two words true:\\n {f2wc_true.most_common(top_n)}\")\n",
    "    print(f\"{top_n} most common first two words pred:\\n {f2wc_pred.most_common(top_n)}\\n\")\n",
    "\n",
    "    print(f\"{low_quality_true} true captions start with 'the low quality recording'\")\n",
    "    print(f\"{low_quality_pred} predicted captions start with 'the low quality recording'\\n\")\n",
    "\n",
    "    print(f\"Captions with 'male': {total_male}\")\n",
    "    print(f\"Captions with 'female': {total_female}\")\n",
    "    print(f\"Captions where true was male but predicted female: {female_male_confound}\")\n",
    "    print(f\"Captions where true was female but predicted male: {male_female_confound}\\n\")\n",
    "\n",
    "    print(f\"Best prediction (score sum {max_score:.2f})\")\n",
    "    print(f\"TRUE: {data_true[max_id]}\")\n",
    "    print(f\"PRED: {data_pred[max_id]}\\n\")\n",
    "\n",
    "    print(f\"Worst prediction (score sum {min_score:.2f})\")\n",
    "    print(f\"TRUE: {data_true[min_id]}\")\n",
    "    print(f\"PRED: {data_pred[min_id]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc9c517-93c3-4370-b3f5-446fe7e0973f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fe452fd-5bee-448d-98de-ec8088508f0c",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32fe37f8-ed39-4ebc-8545-0128888bc2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "550it [00:04, 137.49it/s]\n",
      "100%|██████████| 25/25 [00:32<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Pred vs. true stats\n",
      " -------------------------------------------------- \n",
      "\n",
      "Test GLEU score: 0.0930\n",
      "Test METEOR score: 0.2209\n",
      "Shuffled test GLEU score: 0.0773\n",
      "Shuffled test METEOR score: 0.1898\n",
      "Test Spec-GLEU score: 0.0157\n",
      "Test Spec-METEOR score: 0.0311\n",
      "Aspect precision: 0.154±0.152\n",
      "Aspect recall: 0.181±0.165\n",
      "Average length true captions: 287.156\n",
      "Average length pred captions: 259.371\n",
      "\n",
      "Vocabulary true captions: 3140\n",
      "Vocabulary pred captions: 1457\n",
      "\n",
      "10 most common words true:\n",
      " a: 1576, is: 1216, the: 926, and: 882, The: 832, song: 550, This: 536, in: 530, of: 496, with: 422\n",
      "10 most common words pred:\n",
      " and: 1161, a: 1148, The: 927, is: 745, recording: 612, song: 577, the: 536, of: 509, quality: 460, features: 445\n",
      "\n",
      "10 most common first two words true:\n",
      " [('The low', 115), ('This is', 113), ('This song', 46), ('A male', 33), ('The song', 31), ('This music', 24), ('This audio', 22), ('A female', 19), ('Someone is', 14), ('This clip', 10)]\n",
      "10 most common first two words pred:\n",
      " [('The low', 412), ('The song', 72), ('This is', 23), ('This song', 10), ('The Electro', 7), ('This music', 6), ('A male', 5), ('This audio', 5), ('The track', 4), ('The Rock', 3)]\n",
      "\n",
      "114 true captions start with 'the low quality recording'\n",
      "412 predicted captions start with 'the low quality recording'\n",
      "\n",
      "Captions with 'male': 182\n",
      "Captions with 'female': 86\n",
      "Captions where true was male but predicted female: 30\n",
      "Captions where true was female but predicted male: 31\n",
      "\n",
      "Best prediction (score sum 1.16)\n",
      "TRUE: The low quality recording features an arpeggiated theremin melody being played. The recording is noisy, in mono and it sounds weird and gives off some spacey vibes.\n",
      "PRED: The low quality recording features a bagpipes melody played while soldiers are marching. The recording is noisy, in mono and it sounds prideful, soulful and powerful.\n",
      "\n",
      "Worst prediction (score sum 0.09)\n",
      "TRUE: This pop song is sung by a female children's choir. The voices are soprano and alto. The soprano voice sings high pitch notes in vocals. The alto voices sing the words in parts. This is accompanied by the bass playing the root notes of the chords. A piano plays arpeggiated chords. The mood of this song is sad. This song can be played in a movie scene about reminiscing the past.\n",
      "PRED: The low quality recording features a live performance of a classical song that consists of sustained strings, woodwinds melody, aggressive strings lick, wooden percussion and repetitive violin melody. It sounds suspenseful and intense.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = 'outputs/preds_gpt2_notag_chataug.json'\n",
    "\n",
    "with open(data_path) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print_stats(data['eval_true_captions'], data['eval_pred_captions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "908cf93a-ef1d-4697-b19d-31b98a00907d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "550it [00:03, 139.40it/s]\n",
      "100%|██████████| 25/25 [00:31<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Pred vs. true stats\n",
      " -------------------------------------------------- \n",
      "\n",
      "Test GLEU score: 0.0874\n",
      "Test METEOR score: 0.2095\n",
      "Shuffled test GLEU score: 0.0760\n",
      "Shuffled test METEOR score: 0.1821\n",
      "Test Spec-GLEU score: 0.0114\n",
      "Test Spec-METEOR score: 0.0274\n",
      "Aspect precision: 0.147±0.148\n",
      "Aspect recall: 0.164±0.155\n",
      "Average length true captions: 287.156\n",
      "Average length pred captions: 256.922\n",
      "\n",
      "Vocabulary true captions: 3140\n",
      "Vocabulary pred captions: 1911\n",
      "\n",
      "10 most common words true:\n",
      " a: 1576, is: 1216, the: 926, and: 882, The: 832, song: 550, This: 536, in: 530, of: 496, with: 422\n",
      "10 most common words pred:\n",
      " a: 1257, and: 1001, is: 804, The: 770, the: 641, of: 537, recording: 469, song: 391, features: 382, quality: 352\n",
      "\n",
      "10 most common first two words true:\n",
      " [('The low', 115), ('This is', 113), ('This song', 46), ('A male', 33), ('The song', 31), ('This music', 24), ('This audio', 22), ('A female', 19), ('Someone is', 14), ('This clip', 10)]\n",
      "10 most common first two words pred:\n",
      " [('The low', 320), ('This is', 84), ('This music', 37), ('This song', 28), ('The song', 20), ('This audio', 14), ('The Electro', 14), ('A male', 11), ('The Rock', 4), ('This clip', 4)]\n",
      "\n",
      "114 true captions start with 'the low quality recording'\n",
      "320 predicted captions start with 'the low quality recording'\n",
      "\n",
      "Captions with 'male': 182\n",
      "Captions with 'female': 86\n",
      "Captions where true was male but predicted female: 30\n",
      "Captions where true was female but predicted male: 22\n",
      "\n",
      "Best prediction (score sum 1.52)\n",
      "TRUE: The low quality recording features an electric guitar melody played with a chorus effect on. The recording is noisy and in mono.\n",
      "PRED: The low quality recording features a clean arpeggiated electric guitar melody with an aggressive echoing effect on. The recording is noisy and in mono.\n",
      "\n",
      "Worst prediction (score sum 0.09)\n",
      "TRUE: This folk song starts off with a female voice singing the main melody. The voice has the added effect of autotune. This is accompanied by a rebab or a bowed instrument playing the same melody as the voice. Another stringed instrument is plucked, playing the same melody as the voice. The bass plays the root notes of the chords. The voice rests and other instruments come in. A clarinet plays a descending fill. Koboro percussion is played giving this song a middle-eastern feel. This song has a happy feel. It is a fusion between a folk song and a more modern beat. This song can be played as a party song.\n",
      "PRED: The low quality recording features a passionate female vocal, alongside harmonizing background vocals, singing over wide wooden percussion, groovy bass and shimmering shakers. It sounds joyful, emotional and passionate.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = 'outputs/preds_gpt2_notag_noaug.json'\n",
    "\n",
    "with open(data_path) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print_stats(data['eval_true_captions'], data['eval_pred_captions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24bdce7f-af7f-4d50-a5e0-14e6eea11752",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "87984499-e3c1-4e00-a541-3a54c53814b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'outputs/preds_gpt2_notag_chataug.json'\n",
    "\n",
    "with open(data_path) as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "data['tracks_ids'] = [x[1:] for x in data['tracks_ids']]\n",
    "\n",
    "json.dump(dict(\n",
    "    data\n",
    "), open(data_path, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "47881135-f544-479e-a857-cc97c65bb7fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['predictions', 'true_captions', 'audio_paths'])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33a70c23-0b77-4969-9248-9ea0180a7f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "549it [00:03, 144.04it/s]\n",
      "100%|██████████| 10/10 [00:10<00:00,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Pred vs. true stats\n",
      " -------------------------------------------------- \n",
      "\n",
      "Test GLEU score: 0.0649\n",
      "Test METEOR score: 0.1638\n",
      "Shuffled test GLEU score: 0.0592\n",
      "Shuffled test METEOR score: 0.1518\n",
      "Test Spec-GLEU score: 0.0056\n",
      "Test Spec-METEOR score: 0.0120\n",
      "Aspect precision: 0.152±0.152\n",
      "Aspect recall: 0.162±0.145\n",
      "Average length true captions: 287.148\n",
      "Average length pred captions: 210.716\n",
      "\n",
      "Vocabulary true captions: 3139\n",
      "Vocabulary pred captions: 216\n",
      "\n",
      "10 most common words true:\n",
      " a: 1574, is: 1215, the: 925, and: 879, The: 831, song: 549, This: 536, in: 529, of: 494, with: 422\n",
      "10 most common words pred:\n",
      " the: 1395, and: 1231, is: 1047, a: 1012, song: 671, of: 551, guitar: 417, bass: 397, quality: 392, recording: 386\n",
      "\n",
      "10 most common first two words true:\n",
      " [('The low', 114), ('This is', 113), ('This song', 46), ('A male', 33), ('The song', 31), ('This music', 24), ('This audio', 22), ('A female', 19), ('Someone is', 14), ('This clip', 10)]\n",
      "10 most common first two words pred:\n",
      " [('the low', 284), ('the song', 105), ('this music', 89), ('this song', 38), ('this is', 25), ('a male', 6), ('this audio', 1), ('this low', 1)]\n",
      "\n",
      "114 true captions start with 'the low quality recording'\n",
      "284 predicted captions start with 'the low quality recording'\n",
      "\n",
      "Captions with 'male': 182\n",
      "Captions with 'female': 86\n",
      "Captions where true was male but predicted female: 0\n",
      "Captions where true was female but predicted male: 59\n",
      "\n",
      "Best prediction (score sum 1.01)\n",
      "TRUE: The low quality recording features a pop song that consists of harmonizing vocals singing over punchy snare and kick hits and shimmering cymbals. It sounds energetic and exciting.\n",
      "PRED: the low quality recording features a hip hop song that consists of a flat male vocal singing over groovy bass punchy kick and snare hits shimmering hi hats and punchy kick hits it sounds energetic and energetic\n",
      "\n",
      "Worst prediction (score sum 0.03)\n",
      "TRUE: Audio of an artificial solo guitar tuning two single notes, Ab and Db, one note at a time. No other instrumentation. For guitar tuning.\n",
      "PRED: the low quality recording features a mellow synth melody played in the background the recording is noisy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = 'outputs/preds_lstm_notag_noaug.json'\n",
    "\n",
    "with open(data_path) as f:\n",
    "    lstm_data = json.load(f)\n",
    "\n",
    "# 340 is missing in lstm and also cleaning for <sos> and <eos>\n",
    "print_stats(data['eval_true_captions'][:339]+data['eval_true_captions'][340:], \n",
    "            [re.sub(r'[^\\w\\s]','',c[6:-6]).lower() for c in lstm_data['predictions']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d6a60bed-ddac-4899-9f38-41cd7e75ef92",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_nounk, pred_nounk = [], []\n",
    "for true, pred in zip(data['eval_true_captions'][:339]+data['eval_true_captions'][340:], \n",
    "            [c[6:-6] for c in lstm_data['predictions']]):\n",
    "    if not \"<unk>\" in pred:\n",
    "        true_nounk.append(re.sub(r'[^\\w\\s]','',true).lower())\n",
    "        pred_nounk.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd29bbbe-5cb5-48a7-b161-11a1bace9f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "483"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_nounk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "18075094-9426-48ff-a697-b8f9f86a46d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "483it [00:03, 146.93it/s]\n",
      "100%|██████████| 10/10 [00:07<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Pred vs. true stats\n",
      " -------------------------------------------------- \n",
      "\n",
      "Test GLEU score: 0.0841\n",
      "Test METEOR score: 0.1865\n",
      "Shuffled test GLEU score: 0.0758\n",
      "Shuffled test METEOR score: 0.1702\n",
      "Test Spec-GLEU score: 0.0084\n",
      "Test Spec-METEOR score: 0.0163\n",
      "Aspect precision: 0.155±0.154\n",
      "Aspect recall: 0.167±0.148\n",
      "Average length true captions: 281.199\n",
      "Average length pred captions: 210.284\n",
      "\n",
      "Vocabulary true captions: 2083\n",
      "Vocabulary pred captions: 205\n",
      "\n",
      "10 most common words true:\n",
      " a: 1545, the: 1534, is: 1076, and: 787, song: 576, this: 573, in: 473, of: 429, with: 386, playing: 360\n",
      "10 most common words pred:\n",
      " the: 1123, and: 1122, a: 888, is: 794, song: 612, of: 478, quality: 384, recording: 383, passionate: 374, bass: 368\n",
      "\n",
      "10 most common first two words true:\n",
      " [('the low', 103), ('this is', 97), ('this song', 41), ('a male', 32), ('the song', 28), ('this music', 20), ('a female', 19), ('this audio', 17), ('someone is', 12), ('this clip', 9)]\n",
      "10 most common first two words pred:\n",
      " [('the low', 284), ('the song', 92), ('this music', 54), ('this song', 32), ('this is', 13), ('a male', 6), ('this audio', 1), ('this low', 1)]\n",
      "\n",
      "102 true captions start with 'the low quality recording'\n",
      "284 predicted captions start with 'the low quality recording'\n",
      "\n",
      "Captions with 'male': 177\n",
      "Captions with 'female': 85\n",
      "Captions where true was male but predicted female: 0\n",
      "Captions where true was female but predicted male: 57\n",
      "\n",
      "Best prediction (score sum 1.19)\n",
      "TRUE: the song is an instrumental the song is in slow tempo with a theremin playing a melancholic melody with a guitar accompaniment the song is emotional and lilting the audio quality is poor\n",
      "PRED: the song is an instrumental the song is medium tempo with an electric guitar playing melody with no other instrumentation the song is emotional and emotional the audio quality is poor\n",
      "\n",
      "Worst prediction (score sum 0.03)\n",
      "TRUE: audio of an artificial solo guitar tuning two single notes ab and db one note at a time no other instrumentation for guitar tuning\n",
      "PRED: the low quality recording features a mellow synth melody played in the background the recording is noisy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print_stats(true_nounk, pred_nounk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4fbd64-1129-4f13-9dd9-21b3540ffd80",
   "metadata": {},
   "source": [
    "## ChatAug data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f2c8a56-98dd-4831-9a35-50d74d23e565",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_data_path = 'chataug.json'\n",
    "with open(aug_data_path) as f:\n",
    "    aug_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cae30162-3912-423b-b9f4-d02a42ba59c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4417 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 16\u001b[0m\n\u001b[1;32m     11\u001b[0m top_n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m aug \u001b[38;5;129;01min\u001b[39;00m tqdm(aug_data\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m     14\u001b[0m     \n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# vocabulary\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     spaug \u001b[38;5;241m=\u001b[39m \u001b[43maug\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m()\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m spaug:\n\u001b[1;32m     18\u001b[0m         word_count_aug[w] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "with open('musiccaps_split.json', 'r') as fp:\n",
    "    musiccaps_split = json.load(fp)\n",
    "    \n",
    "aug_data = {k: v for k, v in aug_data.items() if k in musiccaps_split['train']}\n",
    "N = len(aug_data)\n",
    "\n",
    "average_len_aug = 0\n",
    "word_count_aug = defaultdict(int)\n",
    "low_quality_aug = 0\n",
    "f2w_aug = []\n",
    "top_n = 10\n",
    "\n",
    "for aug in tqdm(aug_data.values()):\n",
    "    \n",
    "    # vocabulary\n",
    "    spaug = aug.split()\n",
    "    for w in spaug:\n",
    "        word_count_aug[w] += 1\n",
    "        \n",
    "    f2w_aug.append(\" \".join(spaug[:2]))\n",
    "    \n",
    "    # average length\n",
    "    average_len_aug += (1./N)*len(aug)\n",
    "    \n",
    "most_common_aug = {k: v for k, v in sorted(word_count_aug.items(), key=lambda item: -item[1])[:top_n]}\n",
    "most_common_aug_string = \", \".join([f\"{key}: {value}\" for key, value in most_common_aug.items()])\n",
    "f2wc_aug = Counter(f2w_aug)\n",
    "\n",
    "print(f\"Average length ChatAug captions: {average_len_aug:.3f}\\n\")\n",
    "print(f\"Vocabulary ChatAug captions: {len(word_count_aug)}\\n\")\n",
    "print(f\"{top_n} most common words pred:\\n {most_common_aug_string}\\n\")\n",
    "print(f\"{top_n} most common first two words ChatAug:\\n {f2wc_aug.most_common(top_n)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f92194-13ad-4d88-bbf4-65a6166e59bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85918ed-da45-46a9-a7db-496a31cf14c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UCL1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "c9151f2c10dd9c04d670c6ab9407273fd33ff73d6858514519ebe1bfa000ee63"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
