{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9f106bd-eec0-4ab2-a587-c07668c197ac",
   "metadata": {},
   "source": [
    "# Preds analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c85d9c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (2.10.0)\n",
      "Requirement already satisfied: aiohttp in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: pandas in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets) (1.2.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets) (2.28.1)\n",
      "Requirement already satisfied: packaging in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets) (22.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets) (2023.1.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: xxhash in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: responses<0.19 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets) (1.22.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets) (0.12.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: filelock in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from pandas->datasets) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n",
      "Collecting evaluate\n",
      "  Using cached evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
      "Requirement already satisfied: xxhash in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from evaluate) (3.2.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from evaluate) (2023.1.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from evaluate) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from evaluate) (4.64.1)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from evaluate) (2.10.0)\n",
      "Requirement already satisfied: dill in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from evaluate) (0.3.6)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from evaluate) (0.12.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from evaluate) (1.22.4)\n",
      "Requirement already satisfied: packaging in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from evaluate) (22.0)\n",
      "Requirement already satisfied: responses<0.19 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: pandas in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from evaluate) (1.2.4)\n",
      "Requirement already satisfied: multiprocess in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from evaluate) (0.70.14)\n",
      "Requirement already satisfied: aiohttp in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (3.8.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (11.0.0)\n",
      "Requirement already satisfied: filelock in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.4.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from pandas->evaluate) (2022.7)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.16.0)\n",
      "Installing collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2aa47ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting absl-py\n",
      "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Requirement already satisfied: nltk in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from rouge_score) (3.7)\n",
      "Requirement already satisfied: numpy in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from rouge_score) (1.22.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: joblib in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from nltk->rouge_score) (1.1.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from nltk->rouge_score) (2022.7.9)\n",
      "Requirement already satisfied: click in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from nltk->rouge_score) (8.0.4)\n",
      "Requirement already satisfied: tqdm in /Users/corinacaraconcea/opt/anaconda3/envs/UCL1/lib/python3.9/site-packages (from nltk->rouge_score) (4.64.1)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24936 sha256=916455fe14c84c8b5b5217b4edf2041c22209e93f15ac491a1a3e5763bb2c049\n",
      "  Stored in directory: /Users/corinacaraconcea/Library/Caches/pip/wheels/b0/3f/ac/cc3bc304f50c77ef38d79d8e4e2684313de39af543cb4eb3da\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: absl-py, rouge_score\n",
      "Successfully installed absl-py-1.4.0 rouge_score-0.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b7dec07c-f447-4c9a-868b-22e873c1b4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import evaluate\n",
    "from collections import defaultdict, Counter\n",
    "from tqdm import tqdm as tqdm\n",
    "from musiccaps import load_musiccaps\n",
    "import string\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed7035f-1ca7-4913-b7b3-d4af47b89c0d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8953ddb0-d512-46c9-b6b8-cd53be484247",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/corinacaraconcea/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/corinacaraconcea/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/corinacaraconcea/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "WARNING:datasets.builder:Found cached dataset csv (/Users/corinacaraconcea/.cache/huggingface/datasets/google___csv/google--MusicCaps-bedc2a0fd7888f2f/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    }
   ],
   "source": [
    "meteor = evaluate.load('meteor')\n",
    "google_bleu = evaluate.load('google_bleu')\n",
    "rouge = evaluate.load('rouge')\n",
    "\n",
    "ds = load_musiccaps(\n",
    "    \"./music_data\",\n",
    "    sampling_rate=16000,\n",
    "    limit=None,\n",
    "    num_proc=8,\n",
    "    writer_batch_size=1000,\n",
    "    return_without_audio=True,\n",
    ")\n",
    "\n",
    "def clean_text_for_aspect_metrics(caption):\n",
    "    table = str.maketrans('','', string.punctuation)\n",
    "    caption.replace(\"-\",\" \")\n",
    "    # split the sentences into words\n",
    "    desc = caption.split()\n",
    "    #converts to lower case\n",
    "    desc = [word.lower() for word in desc]\n",
    "    #remove punctuation from each token\n",
    "    desc = [word.translate(table) for word in desc]\n",
    "    #remove hanging 's and a \n",
    "    #desc = [word for word in desc if(len(word)>1)]\n",
    "    #remove tokens with numbers in them\n",
    "    #desc = [word for word in desc if(word.isalpha())]\n",
    "    #convert back to string\n",
    "    caption = ' '.join(desc)\n",
    "    return caption\n",
    "\n",
    "def preprocessing_remove_unk(text_input):\n",
    "    # remove punctuations\n",
    "    desc = re.sub(r'[^\\w\\s]',' ',text_input)\n",
    "    table = str.maketrans('','',string.punctuation)\n",
    "\n",
    "    # turn uppercase letters into lowercase ones\n",
    "    desc = text_input.lower()\n",
    "\n",
    "    # split into words\n",
    "    desc = desc.split(' ')\n",
    "    \n",
    "    try: \n",
    "        # remove <unk> tokens\n",
    "        desc.remove(\"<unk>\")\n",
    "    except ValueError:\n",
    "        desc = desc\n",
    "    try: \n",
    "        # remove <unk> tokens\n",
    "        desc.remove(\"unk\")\n",
    "    except ValueError:\n",
    "        desc = desc\n",
    "        \n",
    "    # remove the punctuations\n",
    "    text_no_punctuation = [word.translate(table) for word in desc]\n",
    "\n",
    "    # join the caption words\n",
    "    caption = ' '.join(desc)\n",
    "    \n",
    "    return caption\n",
    "\n",
    "# get a list of music-related words to use for evaluation\n",
    "aspects = set()\n",
    "for x in ds:\n",
    "    aspect_str = x[\"aspect_list\"]\n",
    "    for t in \"[]\\\"'\":\n",
    "        aspect_str = aspect_str.replace(t, \"\")\n",
    "    aspects.update(aspect_str.split(\", \"))\n",
    "# clean aspects\n",
    "aspects = {clean_text_for_aspect_metrics(a) for a in aspects if len(a) > 2}\n",
    "    \n",
    "def wrap_in_space(s):\n",
    "    return ' ' + s + ' '\n",
    "    \n",
    "# filter\n",
    "all_captions = clean_text_for_aspect_metrics(' '.join(ds[i]['caption'] for i in range(len(ds))))\n",
    "aspect_counts = {a: all_captions.count(wrap_in_space(a)) for a in aspects}\n",
    "aspects = {a for a in aspects if aspect_counts[a] > 10}\n",
    "aspects -= {'the'}\n",
    "\n",
    "def compute_aspects_metric(true, pred):\n",
    "    true = wrap_in_space(clean_text_for_aspect_metrics(true))\n",
    "    pred = wrap_in_space(clean_text_for_aspect_metrics(pred))\n",
    "    \n",
    "    aspects_in_true = {a for a in aspects if wrap_in_space(a) in true}\n",
    "    aspects_in_pred = {a for a in aspects if wrap_in_space(a) in pred}\n",
    "    \n",
    "    #print(aspects_in_true)\n",
    "    #print(aspects_in_pred)\n",
    "    \n",
    "    precision = len(aspects_in_true&aspects_in_pred)/np.maximum(len(aspects_in_pred),1)\n",
    "    recall = len(aspects_in_true&aspects_in_pred)/np.maximum(len(aspects_in_true), 1)\n",
    "    \n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7e2b1b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_outputs(data_path):\n",
    "    \n",
    "    with open(data_path) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # multiple references for one captions\n",
    "    true_captions = data['eval_true_captions']\n",
    "    if isinstance(true_captions, list) and any(isinstance(item, list) for item in true_captions):\n",
    "        true_captions = list(itertools.chain(*true_captions))\n",
    "    # single prediction\n",
    "    predicted_captions = data['eval_pred_captions']\n",
    "    if isinstance(predicted_captions, list) and any(isinstance(item, list) for item in predicted_captions):\n",
    "        predicted_captions = list(itertools.chain(*predicted_captions))\n",
    "\n",
    "\n",
    "    return true_captions,predicted_captions,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "301d7607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(true_captions,predicted_captions):\n",
    "    true_clean = []\n",
    "    pred_clean = []\n",
    "    for i, (true, pred) in tqdm(enumerate(zip(true_captions, predicted_captions))):\n",
    "        # preprocess captions and predictions to remove punctuations and <unk> tokens\n",
    "        true = preprocessing_remove_unk(true)\n",
    "        true_clean.append(true)\n",
    "        pred = preprocessing_remove_unk(pred)\n",
    "        pred_clean.append(pred)\n",
    "        with open('clean_pred.txt','w') as f:\n",
    "            for i in range(len(pred_clean)):\n",
    "                f.write(pred_clean[i]+'\\n')\n",
    "        with open('clean_caption.txt','w') as f:\n",
    "            for i in range(len(true_clean)):\n",
    "                f.write(true_clean[i]+'\\n')\n",
    "\n",
    "    total_google_bleu = google_bleu.compute(predictions = pred_clean,references = true_clean)\n",
    "    total_rouge = rouge.compute(predictions = pred_clean,references = true_clean)\n",
    "    total_meteor = meteor.compute(predictions = pred_clean,references = true_clean)\n",
    "    \n",
    "    return total_google_bleu, total_rouge, total_meteor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "4de9dddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(data_paths,methods):\n",
    "    for i, (data_path, method) in enumerate(zip(data_paths,methods)):\n",
    "       true_captions,predicted_captions = import_outputs(data_path)\n",
    "       google_bleu_score, rouge_score, meteor_score = compute_metrics(true_captions,predicted_captions)\n",
    "\n",
    "       print(method,\"test google BLEU score:\",str(np.round(google_bleu_score[\"google_bleu\"],3)))\n",
    "       print(method,\"test google ROUGE score:\",str(np.round(rouge_score[\"rouge1\"],3)))\n",
    "       print(method,\"test google METEOR score:\",str(np.round(meteor_score[\"meteor\"],3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "4c5f209e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = [\"outputs/preds_lstm_attn_summaries.json\",\n",
    "              \"outputs/preds_lstm_no_attn_summaries.json\",\n",
    "              \"outputs/preds_lstm_attn_no_tag_no_aug.json\",\n",
    "              \"outputs/preds_lstm_no_attn_no_tag_no_aug.json\",\n",
    "              \"outputs/preds_gpt2_summarized_notag_noaug.json\",\n",
    "              \"outputs/preds_gpt2_summarized.json\",\n",
    "              \"outputs/preds_gpt2_notag_chataug.json\",\n",
    "              \"outputs/preds_gpt2_notag_noaug.json\"]\n",
    "\n",
    "methods = [\"LSTM with attention and summarized dataset\",\n",
    "           \"LSTM without attention and summarized dataset\",\n",
    "           \"LSTM with attention no ChatAug\",\n",
    "           \"LSTM no attention no ChatAug\",\n",
    "           \"GPT-2 no tag no aug summarized dataset\",\n",
    "           \"GPT-2 ?? summarized\",\n",
    "           \"GPT-2 no tag ChatAug\",\n",
    "           \"GPT-2 no tag no ChatAug\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1d96f53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1647it [00:00, 1810.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM with attention and summarized dataset test google BLEU score: 0.089\n",
      "LSTM with attention and summarized dataset google ROUGE score: 0.305\n",
      "LSTM with attention and summarized dataset google METEOR score: 0.205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1647it [00:00, 1895.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM without attention and summarized dataset test google BLEU score: 0.092\n",
      "LSTM without attention and summarized dataset google ROUGE score: 0.312\n",
      "LSTM without attention and summarized dataset google METEOR score: 0.207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "549it [00:00, 3212.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM with attention no ChatAug test google BLEU score: 0.083\n",
      "LSTM with attention no ChatAug google ROUGE score: 0.275\n",
      "LSTM with attention no ChatAug google METEOR score: 0.183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "549it [00:00, 3139.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM no attention no ChatAug test google BLEU score: 0.084\n",
      "LSTM no attention no ChatAug google ROUGE score: 0.276\n",
      "LSTM no attention no ChatAug google METEOR score: 0.185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "550it [00:00, 3473.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2 no tag no aug summarized dataset test google BLEU score: 0.087\n",
      "GPT-2 no tag no aug summarized dataset google ROUGE score: 0.267\n",
      "GPT-2 no tag no aug summarized dataset google METEOR score: 0.205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "550it [00:00, 3365.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2 ?? summarized test google BLEU score: 0.086\n",
      "GPT-2 ?? summarized google ROUGE score: 0.267\n",
      "GPT-2 ?? summarized google METEOR score: 0.202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "550it [00:00, 3072.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2 no tag ChatAug test google BLEU score: 0.097\n",
      "GPT-2 no tag ChatAug google ROUGE score: 0.282\n",
      "GPT-2 no tag ChatAug google METEOR score: 0.221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "550it [00:00, 3019.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2 no tag no ChatAug test google BLEU score: 0.091\n",
      "GPT-2 no tag no ChatAug google ROUGE score: 0.273\n",
      "GPT-2 no tag no ChatAug google METEOR score: 0.21\n"
     ]
    }
   ],
   "source": [
    "print_metrics(data_paths,methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ac436e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e520fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fa65a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c8cacf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4674dc0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UCL1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16 (main, Jan 11 2023, 10:02:19) \n[Clang 14.0.6 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "c9151f2c10dd9c04d670c6ab9407273fd33ff73d6858514519ebe1bfa000ee63"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
